{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FORECASTING_LSTM_0.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_xPf94oz-lco"},"source":["# LSTM Model \n","\n","This model uses a pregenerated feature vector with LSTM neural net."]},{"cell_type":"markdown","metadata":{"id":"2blBbh8spNKs"},"source":["## Load data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WhATTYLO-k09","executionInfo":{"status":"ok","timestamp":1622448520865,"user_tz":-120,"elapsed":938,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"22e1e41d-acc5-4e94-b5e1-e9e0076d255e"},"source":["import pandas as pd \n","import requests\n","import io\n","url=\"https://gitlab.com/ivan.jesus.torres/pmrl-tesla/-/raw/main/Datasets/Generated%20datasets/df_ann.csv\"\n","df_ann = pd.read_csv(url)\n","print(df_ann.head(5))"],"execution_count":1,"outputs":[{"output_type":"stream","text":["    feature_0   feature_1   feature_2  ...  feature_598  feature_599      target\n","0  119.842941  121.000000  116.158646  ...          0.0         47.0  146.540009\n","1  146.417999  148.376007  138.731995  ...          0.0         46.0  146.540009\n","2  147.850006  150.501999  145.328003  ...          0.0         60.0  146.024002\n","3  145.347992  145.543991  141.685059  ...          0.0         62.0  141.483978\n","4  152.406006  154.428009  151.183990  ...          0.0         60.0  145.519989\n","\n","[5 rows x 601 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3LfEjFhupdyW"},"source":["## Checking variables"]},{"cell_type":"code","metadata":{"id":"wB7P1NTPXGAZ"},"source":["time_vector = list(df_ann.index.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8k0xLflCQKI","executionInfo":{"status":"ok","timestamp":1622388521254,"user_tz":-120,"elapsed":15,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"f15c2af7-81f6-4d1f-af61-5f9fcaf9de4f"},"source":["df_ann.shape[1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["601"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"cbCF-HpaDefl","executionInfo":{"status":"ok","timestamp":1622388521255,"user_tz":-120,"elapsed":13,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"5edd3ad8-8801-41c7-a9db-093b1da2ae87"},"source":["df_ann.head(1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature_0</th>\n","      <th>feature_1</th>\n","      <th>feature_2</th>\n","      <th>feature_3</th>\n","      <th>feature_4</th>\n","      <th>feature_5</th>\n","      <th>feature_6</th>\n","      <th>feature_7</th>\n","      <th>feature_8</th>\n","      <th>feature_9</th>\n","      <th>feature_10</th>\n","      <th>feature_11</th>\n","      <th>feature_12</th>\n","      <th>feature_13</th>\n","      <th>feature_14</th>\n","      <th>feature_15</th>\n","      <th>feature_16</th>\n","      <th>feature_17</th>\n","      <th>feature_18</th>\n","      <th>feature_19</th>\n","      <th>feature_20</th>\n","      <th>feature_21</th>\n","      <th>feature_22</th>\n","      <th>feature_23</th>\n","      <th>feature_24</th>\n","      <th>feature_25</th>\n","      <th>feature_26</th>\n","      <th>feature_27</th>\n","      <th>feature_28</th>\n","      <th>feature_29</th>\n","      <th>feature_30</th>\n","      <th>feature_31</th>\n","      <th>feature_32</th>\n","      <th>feature_33</th>\n","      <th>feature_34</th>\n","      <th>feature_35</th>\n","      <th>feature_36</th>\n","      <th>feature_37</th>\n","      <th>feature_38</th>\n","      <th>feature_39</th>\n","      <th>...</th>\n","      <th>feature_561</th>\n","      <th>feature_562</th>\n","      <th>feature_563</th>\n","      <th>feature_564</th>\n","      <th>feature_565</th>\n","      <th>feature_566</th>\n","      <th>feature_567</th>\n","      <th>feature_568</th>\n","      <th>feature_569</th>\n","      <th>feature_570</th>\n","      <th>feature_571</th>\n","      <th>feature_572</th>\n","      <th>feature_573</th>\n","      <th>feature_574</th>\n","      <th>feature_575</th>\n","      <th>feature_576</th>\n","      <th>feature_577</th>\n","      <th>feature_578</th>\n","      <th>feature_579</th>\n","      <th>feature_580</th>\n","      <th>feature_581</th>\n","      <th>feature_582</th>\n","      <th>feature_583</th>\n","      <th>feature_584</th>\n","      <th>feature_585</th>\n","      <th>feature_586</th>\n","      <th>feature_587</th>\n","      <th>feature_588</th>\n","      <th>feature_589</th>\n","      <th>feature_590</th>\n","      <th>feature_591</th>\n","      <th>feature_592</th>\n","      <th>feature_593</th>\n","      <th>feature_594</th>\n","      <th>feature_595</th>\n","      <th>feature_596</th>\n","      <th>feature_597</th>\n","      <th>feature_598</th>\n","      <th>feature_599</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>119.842941</td>\n","      <td>121.0</td>\n","      <td>116.158646</td>\n","      <td>5253733.0</td>\n","      <td>61.0</td>\n","      <td>122.199997</td>\n","      <td>122.323997</td>\n","      <td>119.207993</td>\n","      <td>2763665.0</td>\n","      <td>67.0</td>\n","      <td>124.880386</td>\n","      <td>127.0</td>\n","      <td>121.407997</td>\n","      <td>4404805.0</td>\n","      <td>72.0</td>\n","      <td>125.144272</td>\n","      <td>126.157997</td>\n","      <td>124.234718</td>\n","      <td>2001751.0</td>\n","      <td>77.0</td>\n","      <td>127.587997</td>\n","      <td>128.259995</td>\n","      <td>125.042007</td>\n","      <td>2403777.0</td>\n","      <td>75.0</td>\n","      <td>128.042007</td>\n","      <td>129.195999</td>\n","      <td>127.126465</td>\n","      <td>2332085.0</td>\n","      <td>81.0</td>\n","      <td>130.197983</td>\n","      <td>130.399994</td>\n","      <td>127.909996</td>\n","      <td>2376099.0</td>\n","      <td>86.0</td>\n","      <td>139.793991</td>\n","      <td>139.793991</td>\n","      <td>139.793991</td>\n","      <td>0.0</td>\n","      <td>95.0</td>\n","      <td>...</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>0.0</td>\n","      <td>52.0</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>0.0</td>\n","      <td>49.0</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>0.0</td>\n","      <td>48.0</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>0.0</td>\n","      <td>45.0</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>0.0</td>\n","      <td>46.0</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>0.0</td>\n","      <td>46.0</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>0.0</td>\n","      <td>46.0</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>146.540009</td>\n","      <td>0.0</td>\n","      <td>47.0</td>\n","      <td>146.540009</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1 rows Ã— 601 columns</p>\n","</div>"],"text/plain":["    feature_0  feature_1   feature_2  ...  feature_598  feature_599      target\n","0  119.842941      121.0  116.158646  ...          0.0         47.0  146.540009\n","\n","[1 rows x 601 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sdijqrOFdDl","executionInfo":{"status":"ok","timestamp":1622388521255,"user_tz":-120,"elapsed":11,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"f28fe06a-a590-434b-b014-01ec5135e673"},"source":["# Get values of the dataframe\n","final_dataset = df_ann.values\n","print(final_dataset)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[119.84294128 121.         116.15864563 ...   0.          47.\n","  146.54000854]\n"," [146.41799927 148.37600708 138.73199463 ...   0.          46.\n","  146.54000854]\n"," [147.8500061  150.5019989  145.32800293 ...   0.          60.\n","  146.02400208]\n"," ...\n"," [705.13000488 705.13000488 705.13000488 ...   0.          62.\n","  676.        ]\n"," [705.13000488 705.13000488 705.13000488 ...   0.          63.\n","  677.77001953]\n"," [705.13000488 705.13000488 705.13000488 ...   0.          58.\n","  677.02001953]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8Yh4SCVkqBrP"},"source":["## Scaling data\n","\n","This case the MinMaxScaler will be used."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qq_n7U1rLmhd","executionInfo":{"status":"ok","timestamp":1622388521493,"user_tz":-120,"elapsed":247,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"1a7d590d-bd38-4cec-d2fb-7c590a58051b"},"source":["# Scaling data (normalize features)\n","from pandas import Series, DataFrame\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import LabelEncoder\n","\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","scaled_data = scaler.fit_transform(final_dataset)\n","print(scaled_data)\n","print(scaled_data.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.         0.         0.         ... 0.         0.45333333 0.00853   ]\n"," [0.03444431 0.03553572 0.02911858 ... 0.         0.44       0.00853   ]\n"," [0.03630035 0.03829539 0.03762713 ... 0.         0.62666667 0.00783576]\n"," ...\n"," [0.75859877 0.7582362  0.75974604 ... 0.         0.65333333 0.72087827]\n"," [0.75859877 0.7582362  0.75974604 ... 0.         0.66666667 0.7232597 ]\n"," [0.75859877 0.7582362  0.75974604 ... 0.         0.6        0.72225063]]\n","(357, 601)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t14CiP4LqjAq"},"source":["## Get train and test data"]},{"cell_type":"code","metadata":{"id":"DUwJ7-WNFQcZ"},"source":["# Getting training and test sets\n","X = scaled_data[:,0:-1]\n","y = scaled_data[:,-1]\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False) "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bGUZ1n0Hqqhx"},"source":["## Reshape data\n","\n","The desired shape would be [samples, 1, features]"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iol15F5KG8iV","executionInfo":{"status":"ok","timestamp":1622388521495,"user_tz":-120,"elapsed":7,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"925a4471-a895-4fb2-cde8-915bc8df22d6"},"source":["# Reshape input to be 3D [samples, 1, features]\n","x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n","x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n","print(x_train.shape,y_train.shape, x_test.shape, y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(267, 1, 600) (267,) (90, 1, 600) (90,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4Fc22WoSsYmS"},"source":["## Build and Train model\n","\n","In this approach a simple network will be trained."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"q0F3jd1MHdic","executionInfo":{"status":"ok","timestamp":1622388739444,"user_tz":-120,"elapsed":217656,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"59e2ea21-261b-45b6-cee8-d6456bd98147"},"source":["import matplotlib.pyplot as plt\n","import keras\n","import keras.models as models\n","from keras.models import Sequential\n","from keras.layers import LSTM,Dropout,Dense\n","import pandas as pd\n","import numpy as np\n","import keras.layers.core as core\n","import keras.layers.convolutional as conv\n","import keras.models as models\n","import keras.utils.np_utils as kutils\n","# Defining and fitting LSTM model\n","    # We will use the Mean Squared Error (MSE) loss function \n","    # and the efficient Adam version of stochastic gradient descent.\n","learning_rate = 0.0000001\n","batch_size = 1\n","epochs = 50000\n","inputs = keras.layers.Input(shape=(1, df_ann.shape[1]-1))\n","lstm_out = keras.layers.LSTM(50)(inputs)#32\n","outputs = keras.layers.Dense(1)(lstm_out)\n","\n","#lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","#    initial_learning_rate=learning_rate,\n","#    decay_steps=100,\n","#    decay_rate=0.9)\n","\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n","model.summary()\n","\n","\n","\n","path_checkpoint = \"model_checkpoint.h5\"\n","es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0.000000002, patience=25)\n","\n","modelckpt_callback = keras.callbacks.ModelCheckpoint(\n","    monitor=\"val_loss\",\n","    filepath=path_checkpoint,\n","    verbose=1,\n","    save_weights_only=True,\n","    save_best_only=True,\n",")\n","\n","history = model.fit(\n","    x_train, y_train,\n","    epochs=epochs,\n","    validation_data=(x_test,y_test),\n","    callbacks=[es_callback, modelckpt_callback],\n",")\n","def visualize_loss(history, title):\n","    loss = history.history[\"loss\"]\n","    val_loss = history.history[\"val_loss\"]\n","    epochs = range(len(loss))\n","    plt.figure()\n","    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n","    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n","    plt.title(title)\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    plt.show()\n","\n","\n","visualize_loss(history, \"Training and Validation Loss\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mSe han truncado las Ãºltimas 5000 lÃ­neas del flujo de salida.\u001b[0m\n","Epoch 1292/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.1113\n","\n","Epoch 01292: val_loss improved from 0.11168 to 0.11133, saving model to model_checkpoint.h5\n","Epoch 1293/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0254 - val_loss: 0.1110\n","\n","Epoch 01293: val_loss improved from 0.11133 to 0.11099, saving model to model_checkpoint.h5\n","Epoch 1294/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.1107\n","\n","Epoch 01294: val_loss improved from 0.11099 to 0.11066, saving model to model_checkpoint.h5\n","Epoch 1295/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0240 - val_loss: 0.1103\n","\n","Epoch 01295: val_loss improved from 0.11066 to 0.11033, saving model to model_checkpoint.h5\n","Epoch 1296/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0238 - val_loss: 0.1100\n","\n","Epoch 01296: val_loss improved from 0.11033 to 0.10998, saving model to model_checkpoint.h5\n","Epoch 1297/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.1096\n","\n","Epoch 01297: val_loss improved from 0.10998 to 0.10963, saving model to model_checkpoint.h5\n","Epoch 1298/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0251 - val_loss: 0.1093\n","\n","Epoch 01298: val_loss improved from 0.10963 to 0.10930, saving model to model_checkpoint.h5\n","Epoch 1299/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0255 - val_loss: 0.1089\n","\n","Epoch 01299: val_loss improved from 0.10930 to 0.10894, saving model to model_checkpoint.h5\n","Epoch 1300/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.1086\n","\n","Epoch 01300: val_loss improved from 0.10894 to 0.10862, saving model to model_checkpoint.h5\n","Epoch 1301/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.1083\n","\n","Epoch 01301: val_loss improved from 0.10862 to 0.10827, saving model to model_checkpoint.h5\n","Epoch 1302/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.1079\n","\n","Epoch 01302: val_loss improved from 0.10827 to 0.10794, saving model to model_checkpoint.h5\n","Epoch 1303/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0269 - val_loss: 0.1076\n","\n","Epoch 01303: val_loss improved from 0.10794 to 0.10759, saving model to model_checkpoint.h5\n","Epoch 1304/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.1073\n","\n","Epoch 01304: val_loss improved from 0.10759 to 0.10727, saving model to model_checkpoint.h5\n","Epoch 1305/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0240 - val_loss: 0.1070\n","\n","Epoch 01305: val_loss improved from 0.10727 to 0.10696, saving model to model_checkpoint.h5\n","Epoch 1306/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0256 - val_loss: 0.1066\n","\n","Epoch 01306: val_loss improved from 0.10696 to 0.10662, saving model to model_checkpoint.h5\n","Epoch 1307/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0269 - val_loss: 0.1063\n","\n","Epoch 01307: val_loss improved from 0.10662 to 0.10631, saving model to model_checkpoint.h5\n","Epoch 1308/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0253 - val_loss: 0.1060\n","\n","Epoch 01308: val_loss improved from 0.10631 to 0.10599, saving model to model_checkpoint.h5\n","Epoch 1309/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0239 - val_loss: 0.1057\n","\n","Epoch 01309: val_loss improved from 0.10599 to 0.10566, saving model to model_checkpoint.h5\n","Epoch 1310/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.1053\n","\n","Epoch 01310: val_loss improved from 0.10566 to 0.10533, saving model to model_checkpoint.h5\n","Epoch 1311/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.1050\n","\n","Epoch 01311: val_loss improved from 0.10533 to 0.10502, saving model to model_checkpoint.h5\n","Epoch 1312/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0240 - val_loss: 0.1047\n","\n","Epoch 01312: val_loss improved from 0.10502 to 0.10470, saving model to model_checkpoint.h5\n","Epoch 1313/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0262 - val_loss: 0.1044\n","\n","Epoch 01313: val_loss improved from 0.10470 to 0.10439, saving model to model_checkpoint.h5\n","Epoch 1314/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0229 - val_loss: 0.1041\n","\n","Epoch 01314: val_loss improved from 0.10439 to 0.10407, saving model to model_checkpoint.h5\n","Epoch 1315/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0242 - val_loss: 0.1038\n","\n","Epoch 01315: val_loss improved from 0.10407 to 0.10376, saving model to model_checkpoint.h5\n","Epoch 1316/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0267 - val_loss: 0.1034\n","\n","Epoch 01316: val_loss improved from 0.10376 to 0.10343, saving model to model_checkpoint.h5\n","Epoch 1317/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.1031\n","\n","Epoch 01317: val_loss improved from 0.10343 to 0.10313, saving model to model_checkpoint.h5\n","Epoch 1318/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.1028\n","\n","Epoch 01318: val_loss improved from 0.10313 to 0.10282, saving model to model_checkpoint.h5\n","Epoch 1319/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0251 - val_loss: 0.1025\n","\n","Epoch 01319: val_loss improved from 0.10282 to 0.10251, saving model to model_checkpoint.h5\n","Epoch 1320/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0222 - val_loss: 0.1022\n","\n","Epoch 01320: val_loss improved from 0.10251 to 0.10219, saving model to model_checkpoint.h5\n","Epoch 1321/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.1019\n","\n","Epoch 01321: val_loss improved from 0.10219 to 0.10186, saving model to model_checkpoint.h5\n","Epoch 1322/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.1016\n","\n","Epoch 01322: val_loss improved from 0.10186 to 0.10157, saving model to model_checkpoint.h5\n","Epoch 1323/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0259 - val_loss: 0.1012\n","\n","Epoch 01323: val_loss improved from 0.10157 to 0.10124, saving model to model_checkpoint.h5\n","Epoch 1324/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0241 - val_loss: 0.1009\n","\n","Epoch 01324: val_loss improved from 0.10124 to 0.10093, saving model to model_checkpoint.h5\n","Epoch 1325/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.1006\n","\n","Epoch 01325: val_loss improved from 0.10093 to 0.10063, saving model to model_checkpoint.h5\n","Epoch 1326/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0257 - val_loss: 0.1003\n","\n","Epoch 01326: val_loss improved from 0.10063 to 0.10033, saving model to model_checkpoint.h5\n","Epoch 1327/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0244 - val_loss: 0.1000\n","\n","Epoch 01327: val_loss improved from 0.10033 to 0.10003, saving model to model_checkpoint.h5\n","Epoch 1328/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0252 - val_loss: 0.0997\n","\n","Epoch 01328: val_loss improved from 0.10003 to 0.09972, saving model to model_checkpoint.h5\n","Epoch 1329/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0244 - val_loss: 0.0994\n","\n","Epoch 01329: val_loss improved from 0.09972 to 0.09940, saving model to model_checkpoint.h5\n","Epoch 1330/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0239 - val_loss: 0.0991\n","\n","Epoch 01330: val_loss improved from 0.09940 to 0.09908, saving model to model_checkpoint.h5\n","Epoch 1331/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0988\n","\n","Epoch 01331: val_loss improved from 0.09908 to 0.09878, saving model to model_checkpoint.h5\n","Epoch 1332/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0984\n","\n","Epoch 01332: val_loss improved from 0.09878 to 0.09844, saving model to model_checkpoint.h5\n","Epoch 1333/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0234 - val_loss: 0.0981\n","\n","Epoch 01333: val_loss improved from 0.09844 to 0.09814, saving model to model_checkpoint.h5\n","Epoch 1334/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0231 - val_loss: 0.0978\n","\n","Epoch 01334: val_loss improved from 0.09814 to 0.09784, saving model to model_checkpoint.h5\n","Epoch 1335/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0219 - val_loss: 0.0975\n","\n","Epoch 01335: val_loss improved from 0.09784 to 0.09753, saving model to model_checkpoint.h5\n","Epoch 1336/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0252 - val_loss: 0.0972\n","\n","Epoch 01336: val_loss improved from 0.09753 to 0.09721, saving model to model_checkpoint.h5\n","Epoch 1337/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0233 - val_loss: 0.0969\n","\n","Epoch 01337: val_loss improved from 0.09721 to 0.09690, saving model to model_checkpoint.h5\n","Epoch 1338/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0231 - val_loss: 0.0966\n","\n","Epoch 01338: val_loss improved from 0.09690 to 0.09660, saving model to model_checkpoint.h5\n","Epoch 1339/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0229 - val_loss: 0.0963\n","\n","Epoch 01339: val_loss improved from 0.09660 to 0.09631, saving model to model_checkpoint.h5\n","Epoch 1340/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0212 - val_loss: 0.0960\n","\n","Epoch 01340: val_loss improved from 0.09631 to 0.09602, saving model to model_checkpoint.h5\n","Epoch 1341/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0243 - val_loss: 0.0957\n","\n","Epoch 01341: val_loss improved from 0.09602 to 0.09573, saving model to model_checkpoint.h5\n","Epoch 1342/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0235 - val_loss: 0.0954\n","\n","Epoch 01342: val_loss improved from 0.09573 to 0.09544, saving model to model_checkpoint.h5\n","Epoch 1343/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0952\n","\n","Epoch 01343: val_loss improved from 0.09544 to 0.09516, saving model to model_checkpoint.h5\n","Epoch 1344/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0205 - val_loss: 0.0949\n","\n","Epoch 01344: val_loss improved from 0.09516 to 0.09487, saving model to model_checkpoint.h5\n","Epoch 1345/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0211 - val_loss: 0.0946\n","\n","Epoch 01345: val_loss improved from 0.09487 to 0.09457, saving model to model_checkpoint.h5\n","Epoch 1346/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0243 - val_loss: 0.0943\n","\n","Epoch 01346: val_loss improved from 0.09457 to 0.09426, saving model to model_checkpoint.h5\n","Epoch 1347/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0238 - val_loss: 0.0940\n","\n","Epoch 01347: val_loss improved from 0.09426 to 0.09396, saving model to model_checkpoint.h5\n","Epoch 1348/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0224 - val_loss: 0.0937\n","\n","Epoch 01348: val_loss improved from 0.09396 to 0.09365, saving model to model_checkpoint.h5\n","Epoch 1349/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0934\n","\n","Epoch 01349: val_loss improved from 0.09365 to 0.09336, saving model to model_checkpoint.h5\n","Epoch 1350/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0227 - val_loss: 0.0931\n","\n","Epoch 01350: val_loss improved from 0.09336 to 0.09306, saving model to model_checkpoint.h5\n","Epoch 1351/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0248 - val_loss: 0.0928\n","\n","Epoch 01351: val_loss improved from 0.09306 to 0.09276, saving model to model_checkpoint.h5\n","Epoch 1352/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0925\n","\n","Epoch 01352: val_loss improved from 0.09276 to 0.09247, saving model to model_checkpoint.h5\n","Epoch 1353/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0220 - val_loss: 0.0922\n","\n","Epoch 01353: val_loss improved from 0.09247 to 0.09219, saving model to model_checkpoint.h5\n","Epoch 1354/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0247 - val_loss: 0.0919\n","\n","Epoch 01354: val_loss improved from 0.09219 to 0.09190, saving model to model_checkpoint.h5\n","Epoch 1355/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0217 - val_loss: 0.0916\n","\n","Epoch 01355: val_loss improved from 0.09190 to 0.09159, saving model to model_checkpoint.h5\n","Epoch 1356/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0241 - val_loss: 0.0913\n","\n","Epoch 01356: val_loss improved from 0.09159 to 0.09128, saving model to model_checkpoint.h5\n","Epoch 1357/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0237 - val_loss: 0.0910\n","\n","Epoch 01357: val_loss improved from 0.09128 to 0.09099, saving model to model_checkpoint.h5\n","Epoch 1358/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0210 - val_loss: 0.0907\n","\n","Epoch 01358: val_loss improved from 0.09099 to 0.09069, saving model to model_checkpoint.h5\n","Epoch 1359/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0232 - val_loss: 0.0904\n","\n","Epoch 01359: val_loss improved from 0.09069 to 0.09039, saving model to model_checkpoint.h5\n","Epoch 1360/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0230 - val_loss: 0.0901\n","\n","Epoch 01360: val_loss improved from 0.09039 to 0.09009, saving model to model_checkpoint.h5\n","Epoch 1361/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0230 - val_loss: 0.0898\n","\n","Epoch 01361: val_loss improved from 0.09009 to 0.08978, saving model to model_checkpoint.h5\n","Epoch 1362/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0236 - val_loss: 0.0895\n","\n","Epoch 01362: val_loss improved from 0.08978 to 0.08949, saving model to model_checkpoint.h5\n","Epoch 1363/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.0892\n","\n","Epoch 01363: val_loss improved from 0.08949 to 0.08922, saving model to model_checkpoint.h5\n","Epoch 1364/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0231 - val_loss: 0.0889\n","\n","Epoch 01364: val_loss improved from 0.08922 to 0.08891, saving model to model_checkpoint.h5\n","Epoch 1365/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0227 - val_loss: 0.0886\n","\n","Epoch 01365: val_loss improved from 0.08891 to 0.08861, saving model to model_checkpoint.h5\n","Epoch 1366/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0883\n","\n","Epoch 01366: val_loss improved from 0.08861 to 0.08831, saving model to model_checkpoint.h5\n","Epoch 1367/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0226 - val_loss: 0.0880\n","\n","Epoch 01367: val_loss improved from 0.08831 to 0.08804, saving model to model_checkpoint.h5\n","Epoch 1368/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0878\n","\n","Epoch 01368: val_loss improved from 0.08804 to 0.08776, saving model to model_checkpoint.h5\n","Epoch 1369/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0246 - val_loss: 0.0875\n","\n","Epoch 01369: val_loss improved from 0.08776 to 0.08749, saving model to model_checkpoint.h5\n","Epoch 1370/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0194 - val_loss: 0.0872\n","\n","Epoch 01370: val_loss improved from 0.08749 to 0.08724, saving model to model_checkpoint.h5\n","Epoch 1371/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0204 - val_loss: 0.0870\n","\n","Epoch 01371: val_loss improved from 0.08724 to 0.08695, saving model to model_checkpoint.h5\n","Epoch 1372/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0224 - val_loss: 0.0867\n","\n","Epoch 01372: val_loss improved from 0.08695 to 0.08666, saving model to model_checkpoint.h5\n","Epoch 1373/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0864\n","\n","Epoch 01373: val_loss improved from 0.08666 to 0.08640, saving model to model_checkpoint.h5\n","Epoch 1374/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0225 - val_loss: 0.0861\n","\n","Epoch 01374: val_loss improved from 0.08640 to 0.08612, saving model to model_checkpoint.h5\n","Epoch 1375/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0220 - val_loss: 0.0859\n","\n","Epoch 01375: val_loss improved from 0.08612 to 0.08585, saving model to model_checkpoint.h5\n","Epoch 1376/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0219 - val_loss: 0.0856\n","\n","Epoch 01376: val_loss improved from 0.08585 to 0.08560, saving model to model_checkpoint.h5\n","Epoch 1377/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0213 - val_loss: 0.0853\n","\n","Epoch 01377: val_loss improved from 0.08560 to 0.08534, saving model to model_checkpoint.h5\n","Epoch 1378/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0200 - val_loss: 0.0851\n","\n","Epoch 01378: val_loss improved from 0.08534 to 0.08507, saving model to model_checkpoint.h5\n","Epoch 1379/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0848\n","\n","Epoch 01379: val_loss improved from 0.08507 to 0.08479, saving model to model_checkpoint.h5\n","Epoch 1380/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0210 - val_loss: 0.0845\n","\n","Epoch 01380: val_loss improved from 0.08479 to 0.08452, saving model to model_checkpoint.h5\n","Epoch 1381/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0220 - val_loss: 0.0842\n","\n","Epoch 01381: val_loss improved from 0.08452 to 0.08425, saving model to model_checkpoint.h5\n","Epoch 1382/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.0840\n","\n","Epoch 01382: val_loss improved from 0.08425 to 0.08398, saving model to model_checkpoint.h5\n","Epoch 1383/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0204 - val_loss: 0.0837\n","\n","Epoch 01383: val_loss improved from 0.08398 to 0.08370, saving model to model_checkpoint.h5\n","Epoch 1384/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0834\n","\n","Epoch 01384: val_loss improved from 0.08370 to 0.08342, saving model to model_checkpoint.h5\n","Epoch 1385/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0229 - val_loss: 0.0832\n","\n","Epoch 01385: val_loss improved from 0.08342 to 0.08315, saving model to model_checkpoint.h5\n","Epoch 1386/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0829\n","\n","Epoch 01386: val_loss improved from 0.08315 to 0.08291, saving model to model_checkpoint.h5\n","Epoch 1387/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0218 - val_loss: 0.0826\n","\n","Epoch 01387: val_loss improved from 0.08291 to 0.08264, saving model to model_checkpoint.h5\n","Epoch 1388/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0824\n","\n","Epoch 01388: val_loss improved from 0.08264 to 0.08239, saving model to model_checkpoint.h5\n","Epoch 1389/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0198 - val_loss: 0.0821\n","\n","Epoch 01389: val_loss improved from 0.08239 to 0.08212, saving model to model_checkpoint.h5\n","Epoch 1390/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0819\n","\n","Epoch 01390: val_loss improved from 0.08212 to 0.08185, saving model to model_checkpoint.h5\n","Epoch 1391/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0213 - val_loss: 0.0816\n","\n","Epoch 01391: val_loss improved from 0.08185 to 0.08160, saving model to model_checkpoint.h5\n","Epoch 1392/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0200 - val_loss: 0.0813\n","\n","Epoch 01392: val_loss improved from 0.08160 to 0.08134, saving model to model_checkpoint.h5\n","Epoch 1393/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0222 - val_loss: 0.0811\n","\n","Epoch 01393: val_loss improved from 0.08134 to 0.08106, saving model to model_checkpoint.h5\n","Epoch 1394/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0203 - val_loss: 0.0808\n","\n","Epoch 01394: val_loss improved from 0.08106 to 0.08081, saving model to model_checkpoint.h5\n","Epoch 1395/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0805\n","\n","Epoch 01395: val_loss improved from 0.08081 to 0.08054, saving model to model_checkpoint.h5\n","Epoch 1396/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0193 - val_loss: 0.0803\n","\n","Epoch 01396: val_loss improved from 0.08054 to 0.08028, saving model to model_checkpoint.h5\n","Epoch 1397/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0207 - val_loss: 0.0800\n","\n","Epoch 01397: val_loss improved from 0.08028 to 0.08002, saving model to model_checkpoint.h5\n","Epoch 1398/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0798\n","\n","Epoch 01398: val_loss improved from 0.08002 to 0.07976, saving model to model_checkpoint.h5\n","Epoch 1399/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0223 - val_loss: 0.0795\n","\n","Epoch 01399: val_loss improved from 0.07976 to 0.07950, saving model to model_checkpoint.h5\n","Epoch 1400/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0792\n","\n","Epoch 01400: val_loss improved from 0.07950 to 0.07925, saving model to model_checkpoint.h5\n","Epoch 1401/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0790\n","\n","Epoch 01401: val_loss improved from 0.07925 to 0.07899, saving model to model_checkpoint.h5\n","Epoch 1402/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0239 - val_loss: 0.0787\n","\n","Epoch 01402: val_loss improved from 0.07899 to 0.07872, saving model to model_checkpoint.h5\n","Epoch 1403/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0207 - val_loss: 0.0785\n","\n","Epoch 01403: val_loss improved from 0.07872 to 0.07847, saving model to model_checkpoint.h5\n","Epoch 1404/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0782\n","\n","Epoch 01404: val_loss improved from 0.07847 to 0.07823, saving model to model_checkpoint.h5\n","Epoch 1405/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0202 - val_loss: 0.0780\n","\n","Epoch 01405: val_loss improved from 0.07823 to 0.07798, saving model to model_checkpoint.h5\n","Epoch 1406/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0777\n","\n","Epoch 01406: val_loss improved from 0.07798 to 0.07773, saving model to model_checkpoint.h5\n","Epoch 1407/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0199 - val_loss: 0.0775\n","\n","Epoch 01407: val_loss improved from 0.07773 to 0.07750, saving model to model_checkpoint.h5\n","Epoch 1408/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0217 - val_loss: 0.0772\n","\n","Epoch 01408: val_loss improved from 0.07750 to 0.07722, saving model to model_checkpoint.h5\n","Epoch 1409/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0215 - val_loss: 0.0770\n","\n","Epoch 01409: val_loss improved from 0.07722 to 0.07698, saving model to model_checkpoint.h5\n","Epoch 1410/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0767\n","\n","Epoch 01410: val_loss improved from 0.07698 to 0.07673, saving model to model_checkpoint.h5\n","Epoch 1411/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0765\n","\n","Epoch 01411: val_loss improved from 0.07673 to 0.07647, saving model to model_checkpoint.h5\n","Epoch 1412/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0762\n","\n","Epoch 01412: val_loss improved from 0.07647 to 0.07624, saving model to model_checkpoint.h5\n","Epoch 1413/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0213 - val_loss: 0.0760\n","\n","Epoch 01413: val_loss improved from 0.07624 to 0.07598, saving model to model_checkpoint.h5\n","Epoch 1414/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0758\n","\n","Epoch 01414: val_loss improved from 0.07598 to 0.07575, saving model to model_checkpoint.h5\n","Epoch 1415/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0201 - val_loss: 0.0755\n","\n","Epoch 01415: val_loss improved from 0.07575 to 0.07551, saving model to model_checkpoint.h5\n","Epoch 1416/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0205 - val_loss: 0.0753\n","\n","Epoch 01416: val_loss improved from 0.07551 to 0.07527, saving model to model_checkpoint.h5\n","Epoch 1417/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0750\n","\n","Epoch 01417: val_loss improved from 0.07527 to 0.07502, saving model to model_checkpoint.h5\n","Epoch 1418/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0188 - val_loss: 0.0748\n","\n","Epoch 01418: val_loss improved from 0.07502 to 0.07480, saving model to model_checkpoint.h5\n","Epoch 1419/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0196 - val_loss: 0.0746\n","\n","Epoch 01419: val_loss improved from 0.07480 to 0.07457, saving model to model_checkpoint.h5\n","Epoch 1420/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0208 - val_loss: 0.0743\n","\n","Epoch 01420: val_loss improved from 0.07457 to 0.07433, saving model to model_checkpoint.h5\n","Epoch 1421/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0741\n","\n","Epoch 01421: val_loss improved from 0.07433 to 0.07409, saving model to model_checkpoint.h5\n","Epoch 1422/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0739\n","\n","Epoch 01422: val_loss improved from 0.07409 to 0.07385, saving model to model_checkpoint.h5\n","Epoch 1423/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0203 - val_loss: 0.0736\n","\n","Epoch 01423: val_loss improved from 0.07385 to 0.07361, saving model to model_checkpoint.h5\n","Epoch 1424/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0169 - val_loss: 0.0734\n","\n","Epoch 01424: val_loss improved from 0.07361 to 0.07339, saving model to model_checkpoint.h5\n","Epoch 1425/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0731\n","\n","Epoch 01425: val_loss improved from 0.07339 to 0.07313, saving model to model_checkpoint.h5\n","Epoch 1426/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0729\n","\n","Epoch 01426: val_loss improved from 0.07313 to 0.07289, saving model to model_checkpoint.h5\n","Epoch 1427/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0726\n","\n","Epoch 01427: val_loss improved from 0.07289 to 0.07265, saving model to model_checkpoint.h5\n","Epoch 1428/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.0724\n","\n","Epoch 01428: val_loss improved from 0.07265 to 0.07241, saving model to model_checkpoint.h5\n","Epoch 1429/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0722\n","\n","Epoch 01429: val_loss improved from 0.07241 to 0.07218, saving model to model_checkpoint.h5\n","Epoch 1430/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0720\n","\n","Epoch 01430: val_loss improved from 0.07218 to 0.07195, saving model to model_checkpoint.h5\n","Epoch 1431/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0214 - val_loss: 0.0717\n","\n","Epoch 01431: val_loss improved from 0.07195 to 0.07171, saving model to model_checkpoint.h5\n","Epoch 1432/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0193 - val_loss: 0.0715\n","\n","Epoch 01432: val_loss improved from 0.07171 to 0.07150, saving model to model_checkpoint.h5\n","Epoch 1433/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0204 - val_loss: 0.0713\n","\n","Epoch 01433: val_loss improved from 0.07150 to 0.07127, saving model to model_checkpoint.h5\n","Epoch 1434/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0710\n","\n","Epoch 01434: val_loss improved from 0.07127 to 0.07104, saving model to model_checkpoint.h5\n","Epoch 1435/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0708\n","\n","Epoch 01435: val_loss improved from 0.07104 to 0.07082, saving model to model_checkpoint.h5\n","Epoch 1436/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0706\n","\n","Epoch 01436: val_loss improved from 0.07082 to 0.07058, saving model to model_checkpoint.h5\n","Epoch 1437/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0703\n","\n","Epoch 01437: val_loss improved from 0.07058 to 0.07035, saving model to model_checkpoint.h5\n","Epoch 1438/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0209 - val_loss: 0.0701\n","\n","Epoch 01438: val_loss improved from 0.07035 to 0.07011, saving model to model_checkpoint.h5\n","Epoch 1439/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0189 - val_loss: 0.0699\n","\n","Epoch 01439: val_loss improved from 0.07011 to 0.06989, saving model to model_checkpoint.h5\n","Epoch 1440/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0697\n","\n","Epoch 01440: val_loss improved from 0.06989 to 0.06967, saving model to model_checkpoint.h5\n","Epoch 1441/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.0694\n","\n","Epoch 01441: val_loss improved from 0.06967 to 0.06944, saving model to model_checkpoint.h5\n","Epoch 1442/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0190 - val_loss: 0.0692\n","\n","Epoch 01442: val_loss improved from 0.06944 to 0.06923, saving model to model_checkpoint.h5\n","Epoch 1443/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0690\n","\n","Epoch 01443: val_loss improved from 0.06923 to 0.06900, saving model to model_checkpoint.h5\n","Epoch 1444/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0195 - val_loss: 0.0688\n","\n","Epoch 01444: val_loss improved from 0.06900 to 0.06878, saving model to model_checkpoint.h5\n","Epoch 1445/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0202 - val_loss: 0.0686\n","\n","Epoch 01445: val_loss improved from 0.06878 to 0.06856, saving model to model_checkpoint.h5\n","Epoch 1446/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0206 - val_loss: 0.0683\n","\n","Epoch 01446: val_loss improved from 0.06856 to 0.06832, saving model to model_checkpoint.h5\n","Epoch 1447/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0681\n","\n","Epoch 01447: val_loss improved from 0.06832 to 0.06810, saving model to model_checkpoint.h5\n","Epoch 1448/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0679\n","\n","Epoch 01448: val_loss improved from 0.06810 to 0.06788, saving model to model_checkpoint.h5\n","Epoch 1449/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0184 - val_loss: 0.0676\n","\n","Epoch 01449: val_loss improved from 0.06788 to 0.06765, saving model to model_checkpoint.h5\n","Epoch 1450/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0674\n","\n","Epoch 01450: val_loss improved from 0.06765 to 0.06743, saving model to model_checkpoint.h5\n","Epoch 1451/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0188 - val_loss: 0.0672\n","\n","Epoch 01451: val_loss improved from 0.06743 to 0.06720, saving model to model_checkpoint.h5\n","Epoch 1452/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0173 - val_loss: 0.0670\n","\n","Epoch 01452: val_loss improved from 0.06720 to 0.06700, saving model to model_checkpoint.h5\n","Epoch 1453/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0668\n","\n","Epoch 01453: val_loss improved from 0.06700 to 0.06677, saving model to model_checkpoint.h5\n","Epoch 1454/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0196 - val_loss: 0.0665\n","\n","Epoch 01454: val_loss improved from 0.06677 to 0.06652, saving model to model_checkpoint.h5\n","Epoch 1455/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0663\n","\n","Epoch 01455: val_loss improved from 0.06652 to 0.06631, saving model to model_checkpoint.h5\n","Epoch 1456/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0215 - val_loss: 0.0661\n","\n","Epoch 01456: val_loss improved from 0.06631 to 0.06608, saving model to model_checkpoint.h5\n","Epoch 1457/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0181 - val_loss: 0.0658\n","\n","Epoch 01457: val_loss improved from 0.06608 to 0.06585, saving model to model_checkpoint.h5\n","Epoch 1458/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0167 - val_loss: 0.0656\n","\n","Epoch 01458: val_loss improved from 0.06585 to 0.06564, saving model to model_checkpoint.h5\n","Epoch 1459/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0654\n","\n","Epoch 01459: val_loss improved from 0.06564 to 0.06542, saving model to model_checkpoint.h5\n","Epoch 1460/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0652\n","\n","Epoch 01460: val_loss improved from 0.06542 to 0.06520, saving model to model_checkpoint.h5\n","Epoch 1461/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0650\n","\n","Epoch 01461: val_loss improved from 0.06520 to 0.06499, saving model to model_checkpoint.h5\n","Epoch 1462/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.0648\n","\n","Epoch 01462: val_loss improved from 0.06499 to 0.06478, saving model to model_checkpoint.h5\n","Epoch 1463/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0183 - val_loss: 0.0646\n","\n","Epoch 01463: val_loss improved from 0.06478 to 0.06456, saving model to model_checkpoint.h5\n","Epoch 1464/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0643\n","\n","Epoch 01464: val_loss improved from 0.06456 to 0.06435, saving model to model_checkpoint.h5\n","Epoch 1465/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0184 - val_loss: 0.0641\n","\n","Epoch 01465: val_loss improved from 0.06435 to 0.06412, saving model to model_checkpoint.h5\n","Epoch 1466/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0191 - val_loss: 0.0639\n","\n","Epoch 01466: val_loss improved from 0.06412 to 0.06390, saving model to model_checkpoint.h5\n","Epoch 1467/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0637\n","\n","Epoch 01467: val_loss improved from 0.06390 to 0.06368, saving model to model_checkpoint.h5\n","Epoch 1468/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0635\n","\n","Epoch 01468: val_loss improved from 0.06368 to 0.06347, saving model to model_checkpoint.h5\n","Epoch 1469/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0633\n","\n","Epoch 01469: val_loss improved from 0.06347 to 0.06325, saving model to model_checkpoint.h5\n","Epoch 1470/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0630\n","\n","Epoch 01470: val_loss improved from 0.06325 to 0.06305, saving model to model_checkpoint.h5\n","Epoch 1471/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0629\n","\n","Epoch 01471: val_loss improved from 0.06305 to 0.06285, saving model to model_checkpoint.h5\n","Epoch 1472/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0627\n","\n","Epoch 01472: val_loss improved from 0.06285 to 0.06266, saving model to model_checkpoint.h5\n","Epoch 1473/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0625\n","\n","Epoch 01473: val_loss improved from 0.06266 to 0.06246, saving model to model_checkpoint.h5\n","Epoch 1474/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0177 - val_loss: 0.0622\n","\n","Epoch 01474: val_loss improved from 0.06246 to 0.06224, saving model to model_checkpoint.h5\n","Epoch 1475/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0620\n","\n","Epoch 01475: val_loss improved from 0.06224 to 0.06204, saving model to model_checkpoint.h5\n","Epoch 1476/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.0618\n","\n","Epoch 01476: val_loss improved from 0.06204 to 0.06183, saving model to model_checkpoint.h5\n","Epoch 1477/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0616\n","\n","Epoch 01477: val_loss improved from 0.06183 to 0.06163, saving model to model_checkpoint.h5\n","Epoch 1478/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0183 - val_loss: 0.0614\n","\n","Epoch 01478: val_loss improved from 0.06163 to 0.06143, saving model to model_checkpoint.h5\n","Epoch 1479/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.0612\n","\n","Epoch 01479: val_loss improved from 0.06143 to 0.06122, saving model to model_checkpoint.h5\n","Epoch 1480/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0184 - val_loss: 0.0610\n","\n","Epoch 01480: val_loss improved from 0.06122 to 0.06101, saving model to model_checkpoint.h5\n","Epoch 1481/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0176 - val_loss: 0.0608\n","\n","Epoch 01481: val_loss improved from 0.06101 to 0.06082, saving model to model_checkpoint.h5\n","Epoch 1482/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0606\n","\n","Epoch 01482: val_loss improved from 0.06082 to 0.06061, saving model to model_checkpoint.h5\n","Epoch 1483/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0604\n","\n","Epoch 01483: val_loss improved from 0.06061 to 0.06041, saving model to model_checkpoint.h5\n","Epoch 1484/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0602\n","\n","Epoch 01484: val_loss improved from 0.06041 to 0.06022, saving model to model_checkpoint.h5\n","Epoch 1485/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0206 - val_loss: 0.0600\n","\n","Epoch 01485: val_loss improved from 0.06022 to 0.06002, saving model to model_checkpoint.h5\n","Epoch 1486/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0179 - val_loss: 0.0598\n","\n","Epoch 01486: val_loss improved from 0.06002 to 0.05982, saving model to model_checkpoint.h5\n","Epoch 1487/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0596\n","\n","Epoch 01487: val_loss improved from 0.05982 to 0.05963, saving model to model_checkpoint.h5\n","Epoch 1488/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0165 - val_loss: 0.0594\n","\n","Epoch 01488: val_loss improved from 0.05963 to 0.05943, saving model to model_checkpoint.h5\n","Epoch 1489/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0175 - val_loss: 0.0592\n","\n","Epoch 01489: val_loss improved from 0.05943 to 0.05920, saving model to model_checkpoint.h5\n","Epoch 1490/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0590\n","\n","Epoch 01490: val_loss improved from 0.05920 to 0.05900, saving model to model_checkpoint.h5\n","Epoch 1491/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0588\n","\n","Epoch 01491: val_loss improved from 0.05900 to 0.05881, saving model to model_checkpoint.h5\n","Epoch 1492/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0180 - val_loss: 0.0586\n","\n","Epoch 01492: val_loss improved from 0.05881 to 0.05862, saving model to model_checkpoint.h5\n","Epoch 1493/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0584\n","\n","Epoch 01493: val_loss improved from 0.05862 to 0.05842, saving model to model_checkpoint.h5\n","Epoch 1494/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0169 - val_loss: 0.0582\n","\n","Epoch 01494: val_loss improved from 0.05842 to 0.05824, saving model to model_checkpoint.h5\n","Epoch 1495/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0580\n","\n","Epoch 01495: val_loss improved from 0.05824 to 0.05805, saving model to model_checkpoint.h5\n","Epoch 1496/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0176 - val_loss: 0.0579\n","\n","Epoch 01496: val_loss improved from 0.05805 to 0.05785, saving model to model_checkpoint.h5\n","Epoch 1497/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0189 - val_loss: 0.0576\n","\n","Epoch 01497: val_loss improved from 0.05785 to 0.05765, saving model to model_checkpoint.h5\n","Epoch 1498/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0575\n","\n","Epoch 01498: val_loss improved from 0.05765 to 0.05746, saving model to model_checkpoint.h5\n","Epoch 1499/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0174 - val_loss: 0.0573\n","\n","Epoch 01499: val_loss improved from 0.05746 to 0.05728, saving model to model_checkpoint.h5\n","Epoch 1500/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0571\n","\n","Epoch 01500: val_loss improved from 0.05728 to 0.05710, saving model to model_checkpoint.h5\n","Epoch 1501/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0160 - val_loss: 0.0569\n","\n","Epoch 01501: val_loss improved from 0.05710 to 0.05693, saving model to model_checkpoint.h5\n","Epoch 1502/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0567\n","\n","Epoch 01502: val_loss improved from 0.05693 to 0.05674, saving model to model_checkpoint.h5\n","Epoch 1503/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0566\n","\n","Epoch 01503: val_loss improved from 0.05674 to 0.05656, saving model to model_checkpoint.h5\n","Epoch 1504/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0564\n","\n","Epoch 01504: val_loss improved from 0.05656 to 0.05639, saving model to model_checkpoint.h5\n","Epoch 1505/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0186 - val_loss: 0.0562\n","\n","Epoch 01505: val_loss improved from 0.05639 to 0.05620, saving model to model_checkpoint.h5\n","Epoch 1506/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0169 - val_loss: 0.0560\n","\n","Epoch 01506: val_loss improved from 0.05620 to 0.05602, saving model to model_checkpoint.h5\n","Epoch 1507/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0558\n","\n","Epoch 01507: val_loss improved from 0.05602 to 0.05584, saving model to model_checkpoint.h5\n","Epoch 1508/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0167 - val_loss: 0.0557\n","\n","Epoch 01508: val_loss improved from 0.05584 to 0.05566, saving model to model_checkpoint.h5\n","Epoch 1509/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0185 - val_loss: 0.0555\n","\n","Epoch 01509: val_loss improved from 0.05566 to 0.05549, saving model to model_checkpoint.h5\n","Epoch 1510/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0182 - val_loss: 0.0553\n","\n","Epoch 01510: val_loss improved from 0.05549 to 0.05532, saving model to model_checkpoint.h5\n","Epoch 1511/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0191 - val_loss: 0.0551\n","\n","Epoch 01511: val_loss improved from 0.05532 to 0.05513, saving model to model_checkpoint.h5\n","Epoch 1512/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0550\n","\n","Epoch 01512: val_loss improved from 0.05513 to 0.05497, saving model to model_checkpoint.h5\n","Epoch 1513/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0548\n","\n","Epoch 01513: val_loss improved from 0.05497 to 0.05480, saving model to model_checkpoint.h5\n","Epoch 1514/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0173 - val_loss: 0.0546\n","\n","Epoch 01514: val_loss improved from 0.05480 to 0.05462, saving model to model_checkpoint.h5\n","Epoch 1515/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0157 - val_loss: 0.0545\n","\n","Epoch 01515: val_loss improved from 0.05462 to 0.05445, saving model to model_checkpoint.h5\n","Epoch 1516/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0543\n","\n","Epoch 01516: val_loss improved from 0.05445 to 0.05428, saving model to model_checkpoint.h5\n","Epoch 1517/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0541\n","\n","Epoch 01517: val_loss improved from 0.05428 to 0.05411, saving model to model_checkpoint.h5\n","Epoch 1518/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0539\n","\n","Epoch 01518: val_loss improved from 0.05411 to 0.05392, saving model to model_checkpoint.h5\n","Epoch 1519/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0537\n","\n","Epoch 01519: val_loss improved from 0.05392 to 0.05375, saving model to model_checkpoint.h5\n","Epoch 1520/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0536\n","\n","Epoch 01520: val_loss improved from 0.05375 to 0.05356, saving model to model_checkpoint.h5\n","Epoch 1521/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0171 - val_loss: 0.0534\n","\n","Epoch 01521: val_loss improved from 0.05356 to 0.05337, saving model to model_checkpoint.h5\n","Epoch 1522/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0532\n","\n","Epoch 01522: val_loss improved from 0.05337 to 0.05319, saving model to model_checkpoint.h5\n","Epoch 1523/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0530\n","\n","Epoch 01523: val_loss improved from 0.05319 to 0.05301, saving model to model_checkpoint.h5\n","Epoch 1524/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0172 - val_loss: 0.0528\n","\n","Epoch 01524: val_loss improved from 0.05301 to 0.05283, saving model to model_checkpoint.h5\n","Epoch 1525/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0527\n","\n","Epoch 01525: val_loss improved from 0.05283 to 0.05265, saving model to model_checkpoint.h5\n","Epoch 1526/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0180 - val_loss: 0.0525\n","\n","Epoch 01526: val_loss improved from 0.05265 to 0.05247, saving model to model_checkpoint.h5\n","Epoch 1527/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0523\n","\n","Epoch 01527: val_loss improved from 0.05247 to 0.05230, saving model to model_checkpoint.h5\n","Epoch 1528/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0521\n","\n","Epoch 01528: val_loss improved from 0.05230 to 0.05213, saving model to model_checkpoint.h5\n","Epoch 1529/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0181 - val_loss: 0.0519\n","\n","Epoch 01529: val_loss improved from 0.05213 to 0.05194, saving model to model_checkpoint.h5\n","Epoch 1530/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0159 - val_loss: 0.0518\n","\n","Epoch 01530: val_loss improved from 0.05194 to 0.05177, saving model to model_checkpoint.h5\n","Epoch 1531/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0152 - val_loss: 0.0516\n","\n","Epoch 01531: val_loss improved from 0.05177 to 0.05160, saving model to model_checkpoint.h5\n","Epoch 1532/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0514\n","\n","Epoch 01532: val_loss improved from 0.05160 to 0.05143, saving model to model_checkpoint.h5\n","Epoch 1533/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0513\n","\n","Epoch 01533: val_loss improved from 0.05143 to 0.05125, saving model to model_checkpoint.h5\n","Epoch 1534/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0177 - val_loss: 0.0511\n","\n","Epoch 01534: val_loss improved from 0.05125 to 0.05106, saving model to model_checkpoint.h5\n","Epoch 1535/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0148 - val_loss: 0.0509\n","\n","Epoch 01535: val_loss improved from 0.05106 to 0.05090, saving model to model_checkpoint.h5\n","Epoch 1536/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0197 - val_loss: 0.0507\n","\n","Epoch 01536: val_loss improved from 0.05090 to 0.05070, saving model to model_checkpoint.h5\n","Epoch 1537/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0161 - val_loss: 0.0505\n","\n","Epoch 01537: val_loss improved from 0.05070 to 0.05054, saving model to model_checkpoint.h5\n","Epoch 1538/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0504\n","\n","Epoch 01538: val_loss improved from 0.05054 to 0.05038, saving model to model_checkpoint.h5\n","Epoch 1539/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0162 - val_loss: 0.0502\n","\n","Epoch 01539: val_loss improved from 0.05038 to 0.05021, saving model to model_checkpoint.h5\n","Epoch 1540/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0155 - val_loss: 0.0501\n","\n","Epoch 01540: val_loss improved from 0.05021 to 0.05005, saving model to model_checkpoint.h5\n","Epoch 1541/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0168 - val_loss: 0.0499\n","\n","Epoch 01541: val_loss improved from 0.05005 to 0.04989, saving model to model_checkpoint.h5\n","Epoch 1542/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0497\n","\n","Epoch 01542: val_loss improved from 0.04989 to 0.04973, saving model to model_checkpoint.h5\n","Epoch 1543/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0168 - val_loss: 0.0496\n","\n","Epoch 01543: val_loss improved from 0.04973 to 0.04957, saving model to model_checkpoint.h5\n","Epoch 1544/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0494\n","\n","Epoch 01544: val_loss improved from 0.04957 to 0.04941, saving model to model_checkpoint.h5\n","Epoch 1545/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0177 - val_loss: 0.0492\n","\n","Epoch 01545: val_loss improved from 0.04941 to 0.04924, saving model to model_checkpoint.h5\n","Epoch 1546/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0161 - val_loss: 0.0491\n","\n","Epoch 01546: val_loss improved from 0.04924 to 0.04909, saving model to model_checkpoint.h5\n","Epoch 1547/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0156 - val_loss: 0.0489\n","\n","Epoch 01547: val_loss improved from 0.04909 to 0.04893, saving model to model_checkpoint.h5\n","Epoch 1548/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0190 - val_loss: 0.0488\n","\n","Epoch 01548: val_loss improved from 0.04893 to 0.04876, saving model to model_checkpoint.h5\n","Epoch 1549/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0176 - val_loss: 0.0486\n","\n","Epoch 01549: val_loss improved from 0.04876 to 0.04860, saving model to model_checkpoint.h5\n","Epoch 1550/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0148 - val_loss: 0.0484\n","\n","Epoch 01550: val_loss improved from 0.04860 to 0.04845, saving model to model_checkpoint.h5\n","Epoch 1551/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0483\n","\n","Epoch 01551: val_loss improved from 0.04845 to 0.04829, saving model to model_checkpoint.h5\n","Epoch 1552/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0481\n","\n","Epoch 01552: val_loss improved from 0.04829 to 0.04811, saving model to model_checkpoint.h5\n","Epoch 1553/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0153 - val_loss: 0.0480\n","\n","Epoch 01553: val_loss improved from 0.04811 to 0.04796, saving model to model_checkpoint.h5\n","Epoch 1554/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0478\n","\n","Epoch 01554: val_loss improved from 0.04796 to 0.04781, saving model to model_checkpoint.h5\n","Epoch 1555/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0174 - val_loss: 0.0476\n","\n","Epoch 01555: val_loss improved from 0.04781 to 0.04764, saving model to model_checkpoint.h5\n","Epoch 1556/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0155 - val_loss: 0.0475\n","\n","Epoch 01556: val_loss improved from 0.04764 to 0.04747, saving model to model_checkpoint.h5\n","Epoch 1557/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0473\n","\n","Epoch 01557: val_loss improved from 0.04747 to 0.04732, saving model to model_checkpoint.h5\n","Epoch 1558/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0166 - val_loss: 0.0471\n","\n","Epoch 01558: val_loss improved from 0.04732 to 0.04713, saving model to model_checkpoint.h5\n","Epoch 1559/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0142 - val_loss: 0.0470\n","\n","Epoch 01559: val_loss improved from 0.04713 to 0.04697, saving model to model_checkpoint.h5\n","Epoch 1560/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0165 - val_loss: 0.0468\n","\n","Epoch 01560: val_loss improved from 0.04697 to 0.04680, saving model to model_checkpoint.h5\n","Epoch 1561/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0466\n","\n","Epoch 01561: val_loss improved from 0.04680 to 0.04665, saving model to model_checkpoint.h5\n","Epoch 1562/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0465\n","\n","Epoch 01562: val_loss improved from 0.04665 to 0.04649, saving model to model_checkpoint.h5\n","Epoch 1563/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0147 - val_loss: 0.0463\n","\n","Epoch 01563: val_loss improved from 0.04649 to 0.04633, saving model to model_checkpoint.h5\n","Epoch 1564/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0462\n","\n","Epoch 01564: val_loss improved from 0.04633 to 0.04618, saving model to model_checkpoint.h5\n","Epoch 1565/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0148 - val_loss: 0.0460\n","\n","Epoch 01565: val_loss improved from 0.04618 to 0.04603, saving model to model_checkpoint.h5\n","Epoch 1566/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0141 - val_loss: 0.0459\n","\n","Epoch 01566: val_loss improved from 0.04603 to 0.04589, saving model to model_checkpoint.h5\n","Epoch 1567/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0167 - val_loss: 0.0457\n","\n","Epoch 01567: val_loss improved from 0.04589 to 0.04574, saving model to model_checkpoint.h5\n","Epoch 1568/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0154 - val_loss: 0.0456\n","\n","Epoch 01568: val_loss improved from 0.04574 to 0.04559, saving model to model_checkpoint.h5\n","Epoch 1569/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0454\n","\n","Epoch 01569: val_loss improved from 0.04559 to 0.04544, saving model to model_checkpoint.h5\n","Epoch 1570/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0171 - val_loss: 0.0453\n","\n","Epoch 01570: val_loss improved from 0.04544 to 0.04527, saving model to model_checkpoint.h5\n","Epoch 1571/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0451\n","\n","Epoch 01571: val_loss improved from 0.04527 to 0.04513, saving model to model_checkpoint.h5\n","Epoch 1572/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0450\n","\n","Epoch 01572: val_loss improved from 0.04513 to 0.04497, saving model to model_checkpoint.h5\n","Epoch 1573/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0448\n","\n","Epoch 01573: val_loss improved from 0.04497 to 0.04482, saving model to model_checkpoint.h5\n","Epoch 1574/50000\n","9/9 [==============================] - 0s 11ms/step - loss: 0.0141 - val_loss: 0.0447\n","\n","Epoch 01574: val_loss improved from 0.04482 to 0.04467, saving model to model_checkpoint.h5\n","Epoch 1575/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0143 - val_loss: 0.0445\n","\n","Epoch 01575: val_loss improved from 0.04467 to 0.04450, saving model to model_checkpoint.h5\n","Epoch 1576/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0151 - val_loss: 0.0443\n","\n","Epoch 01576: val_loss improved from 0.04450 to 0.04433, saving model to model_checkpoint.h5\n","Epoch 1577/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0442\n","\n","Epoch 01577: val_loss improved from 0.04433 to 0.04417, saving model to model_checkpoint.h5\n","Epoch 1578/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0170 - val_loss: 0.0440\n","\n","Epoch 01578: val_loss improved from 0.04417 to 0.04401, saving model to model_checkpoint.h5\n","Epoch 1579/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0164 - val_loss: 0.0439\n","\n","Epoch 01579: val_loss improved from 0.04401 to 0.04386, saving model to model_checkpoint.h5\n","Epoch 1580/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0131 - val_loss: 0.0437\n","\n","Epoch 01580: val_loss improved from 0.04386 to 0.04372, saving model to model_checkpoint.h5\n","Epoch 1581/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0150 - val_loss: 0.0435\n","\n","Epoch 01581: val_loss improved from 0.04372 to 0.04354, saving model to model_checkpoint.h5\n","Epoch 1582/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0434\n","\n","Epoch 01582: val_loss improved from 0.04354 to 0.04338, saving model to model_checkpoint.h5\n","Epoch 1583/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0432\n","\n","Epoch 01583: val_loss improved from 0.04338 to 0.04324, saving model to model_checkpoint.h5\n","Epoch 1584/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0431\n","\n","Epoch 01584: val_loss improved from 0.04324 to 0.04309, saving model to model_checkpoint.h5\n","Epoch 1585/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0429\n","\n","Epoch 01585: val_loss improved from 0.04309 to 0.04294, saving model to model_checkpoint.h5\n","Epoch 1586/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0143 - val_loss: 0.0428\n","\n","Epoch 01586: val_loss improved from 0.04294 to 0.04280, saving model to model_checkpoint.h5\n","Epoch 1587/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0152 - val_loss: 0.0427\n","\n","Epoch 01587: val_loss improved from 0.04280 to 0.04266, saving model to model_checkpoint.h5\n","Epoch 1588/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 0.0425\n","\n","Epoch 01588: val_loss improved from 0.04266 to 0.04253, saving model to model_checkpoint.h5\n","Epoch 1589/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0424\n","\n","Epoch 01589: val_loss improved from 0.04253 to 0.04240, saving model to model_checkpoint.h5\n","Epoch 1590/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0145 - val_loss: 0.0423\n","\n","Epoch 01590: val_loss improved from 0.04240 to 0.04227, saving model to model_checkpoint.h5\n","Epoch 1591/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0140 - val_loss: 0.0421\n","\n","Epoch 01591: val_loss improved from 0.04227 to 0.04213, saving model to model_checkpoint.h5\n","Epoch 1592/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0151 - val_loss: 0.0420\n","\n","Epoch 01592: val_loss improved from 0.04213 to 0.04199, saving model to model_checkpoint.h5\n","Epoch 1593/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0141 - val_loss: 0.0418\n","\n","Epoch 01593: val_loss improved from 0.04199 to 0.04184, saving model to model_checkpoint.h5\n","Epoch 1594/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0417\n","\n","Epoch 01594: val_loss improved from 0.04184 to 0.04168, saving model to model_checkpoint.h5\n","Epoch 1595/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0158 - val_loss: 0.0415\n","\n","Epoch 01595: val_loss improved from 0.04168 to 0.04155, saving model to model_checkpoint.h5\n","Epoch 1596/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0144 - val_loss: 0.0414\n","\n","Epoch 01596: val_loss improved from 0.04155 to 0.04139, saving model to model_checkpoint.h5\n","Epoch 1597/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0153 - val_loss: 0.0412\n","\n","Epoch 01597: val_loss improved from 0.04139 to 0.04125, saving model to model_checkpoint.h5\n","Epoch 1598/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0142 - val_loss: 0.0411\n","\n","Epoch 01598: val_loss improved from 0.04125 to 0.04111, saving model to model_checkpoint.h5\n","Epoch 1599/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0410\n","\n","Epoch 01599: val_loss improved from 0.04111 to 0.04098, saving model to model_checkpoint.h5\n","Epoch 1600/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0408\n","\n","Epoch 01600: val_loss improved from 0.04098 to 0.04082, saving model to model_checkpoint.h5\n","Epoch 1601/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0146 - val_loss: 0.0407\n","\n","Epoch 01601: val_loss improved from 0.04082 to 0.04068, saving model to model_checkpoint.h5\n","Epoch 1602/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0132 - val_loss: 0.0405\n","\n","Epoch 01602: val_loss improved from 0.04068 to 0.04053, saving model to model_checkpoint.h5\n","Epoch 1603/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0404\n","\n","Epoch 01603: val_loss improved from 0.04053 to 0.04038, saving model to model_checkpoint.h5\n","Epoch 1604/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0402\n","\n","Epoch 01604: val_loss improved from 0.04038 to 0.04021, saving model to model_checkpoint.h5\n","Epoch 1605/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0401\n","\n","Epoch 01605: val_loss improved from 0.04021 to 0.04007, saving model to model_checkpoint.h5\n","Epoch 1606/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0136 - val_loss: 0.0399\n","\n","Epoch 01606: val_loss improved from 0.04007 to 0.03994, saving model to model_checkpoint.h5\n","Epoch 1607/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0121 - val_loss: 0.0398\n","\n","Epoch 01607: val_loss improved from 0.03994 to 0.03981, saving model to model_checkpoint.h5\n","Epoch 1608/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0145 - val_loss: 0.0397\n","\n","Epoch 01608: val_loss improved from 0.03981 to 0.03967, saving model to model_checkpoint.h5\n","Epoch 1609/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0395\n","\n","Epoch 01609: val_loss improved from 0.03967 to 0.03951, saving model to model_checkpoint.h5\n","Epoch 1610/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0394\n","\n","Epoch 01610: val_loss improved from 0.03951 to 0.03940, saving model to model_checkpoint.h5\n","Epoch 1611/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0393\n","\n","Epoch 01611: val_loss improved from 0.03940 to 0.03926, saving model to model_checkpoint.h5\n","Epoch 1612/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0144 - val_loss: 0.0391\n","\n","Epoch 01612: val_loss improved from 0.03926 to 0.03913, saving model to model_checkpoint.h5\n","Epoch 1613/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0137 - val_loss: 0.0390\n","\n","Epoch 01613: val_loss improved from 0.03913 to 0.03900, saving model to model_checkpoint.h5\n","Epoch 1614/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0135 - val_loss: 0.0389\n","\n","Epoch 01614: val_loss improved from 0.03900 to 0.03888, saving model to model_checkpoint.h5\n","Epoch 1615/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0388\n","\n","Epoch 01615: val_loss improved from 0.03888 to 0.03876, saving model to model_checkpoint.h5\n","Epoch 1616/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0386\n","\n","Epoch 01616: val_loss improved from 0.03876 to 0.03863, saving model to model_checkpoint.h5\n","Epoch 1617/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0385\n","\n","Epoch 01617: val_loss improved from 0.03863 to 0.03849, saving model to model_checkpoint.h5\n","Epoch 1618/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0384\n","\n","Epoch 01618: val_loss improved from 0.03849 to 0.03837, saving model to model_checkpoint.h5\n","Epoch 1619/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.0382\n","\n","Epoch 01619: val_loss improved from 0.03837 to 0.03820, saving model to model_checkpoint.h5\n","Epoch 1620/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0381\n","\n","Epoch 01620: val_loss improved from 0.03820 to 0.03806, saving model to model_checkpoint.h5\n","Epoch 1621/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0379\n","\n","Epoch 01621: val_loss improved from 0.03806 to 0.03792, saving model to model_checkpoint.h5\n","Epoch 1622/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0378\n","\n","Epoch 01622: val_loss improved from 0.03792 to 0.03780, saving model to model_checkpoint.h5\n","Epoch 1623/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0377\n","\n","Epoch 01623: val_loss improved from 0.03780 to 0.03768, saving model to model_checkpoint.h5\n","Epoch 1624/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0376\n","\n","Epoch 01624: val_loss improved from 0.03768 to 0.03756, saving model to model_checkpoint.h5\n","Epoch 1625/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0374\n","\n","Epoch 01625: val_loss improved from 0.03756 to 0.03744, saving model to model_checkpoint.h5\n","Epoch 1626/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0140 - val_loss: 0.0373\n","\n","Epoch 01626: val_loss improved from 0.03744 to 0.03729, saving model to model_checkpoint.h5\n","Epoch 1627/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0372\n","\n","Epoch 01627: val_loss improved from 0.03729 to 0.03716, saving model to model_checkpoint.h5\n","Epoch 1628/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0119 - val_loss: 0.0370\n","\n","Epoch 01628: val_loss improved from 0.03716 to 0.03701, saving model to model_checkpoint.h5\n","Epoch 1629/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0147 - val_loss: 0.0369\n","\n","Epoch 01629: val_loss improved from 0.03701 to 0.03687, saving model to model_checkpoint.h5\n","Epoch 1630/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0367\n","\n","Epoch 01630: val_loss improved from 0.03687 to 0.03673, saving model to model_checkpoint.h5\n","Epoch 1631/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0129 - val_loss: 0.0366\n","\n","Epoch 01631: val_loss improved from 0.03673 to 0.03662, saving model to model_checkpoint.h5\n","Epoch 1632/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0365\n","\n","Epoch 01632: val_loss improved from 0.03662 to 0.03648, saving model to model_checkpoint.h5\n","Epoch 1633/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0138 - val_loss: 0.0364\n","\n","Epoch 01633: val_loss improved from 0.03648 to 0.03636, saving model to model_checkpoint.h5\n","Epoch 1634/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0362\n","\n","Epoch 01634: val_loss improved from 0.03636 to 0.03624, saving model to model_checkpoint.h5\n","Epoch 1635/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0361\n","\n","Epoch 01635: val_loss improved from 0.03624 to 0.03611, saving model to model_checkpoint.h5\n","Epoch 1636/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0360\n","\n","Epoch 01636: val_loss improved from 0.03611 to 0.03600, saving model to model_checkpoint.h5\n","Epoch 1637/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0359\n","\n","Epoch 01637: val_loss improved from 0.03600 to 0.03587, saving model to model_checkpoint.h5\n","Epoch 1638/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0152 - val_loss: 0.0357\n","\n","Epoch 01638: val_loss improved from 0.03587 to 0.03574, saving model to model_checkpoint.h5\n","Epoch 1639/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0356\n","\n","Epoch 01639: val_loss improved from 0.03574 to 0.03561, saving model to model_checkpoint.h5\n","Epoch 1640/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0355\n","\n","Epoch 01640: val_loss improved from 0.03561 to 0.03550, saving model to model_checkpoint.h5\n","Epoch 1641/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0354\n","\n","Epoch 01641: val_loss improved from 0.03550 to 0.03539, saving model to model_checkpoint.h5\n","Epoch 1642/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0353\n","\n","Epoch 01642: val_loss improved from 0.03539 to 0.03527, saving model to model_checkpoint.h5\n","Epoch 1643/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0352\n","\n","Epoch 01643: val_loss improved from 0.03527 to 0.03516, saving model to model_checkpoint.h5\n","Epoch 1644/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0350\n","\n","Epoch 01644: val_loss improved from 0.03516 to 0.03504, saving model to model_checkpoint.h5\n","Epoch 1645/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0349\n","\n","Epoch 01645: val_loss improved from 0.03504 to 0.03492, saving model to model_checkpoint.h5\n","Epoch 1646/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0348\n","\n","Epoch 01646: val_loss improved from 0.03492 to 0.03480, saving model to model_checkpoint.h5\n","Epoch 1647/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0347\n","\n","Epoch 01647: val_loss improved from 0.03480 to 0.03469, saving model to model_checkpoint.h5\n","Epoch 1648/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0346\n","\n","Epoch 01648: val_loss improved from 0.03469 to 0.03458, saving model to model_checkpoint.h5\n","Epoch 1649/50000\n","9/9 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0345\n","\n","Epoch 01649: val_loss improved from 0.03458 to 0.03447, saving model to model_checkpoint.h5\n","Epoch 1650/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0344\n","\n","Epoch 01650: val_loss improved from 0.03447 to 0.03437, saving model to model_checkpoint.h5\n","Epoch 1651/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0342\n","\n","Epoch 01651: val_loss improved from 0.03437 to 0.03423, saving model to model_checkpoint.h5\n","Epoch 1652/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0108 - val_loss: 0.0341\n","\n","Epoch 01652: val_loss improved from 0.03423 to 0.03412, saving model to model_checkpoint.h5\n","Epoch 1653/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0129 - val_loss: 0.0340\n","\n","Epoch 01653: val_loss improved from 0.03412 to 0.03399, saving model to model_checkpoint.h5\n","Epoch 1654/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.0339\n","\n","Epoch 01654: val_loss improved from 0.03399 to 0.03388, saving model to model_checkpoint.h5\n","Epoch 1655/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0139 - val_loss: 0.0338\n","\n","Epoch 01655: val_loss improved from 0.03388 to 0.03377, saving model to model_checkpoint.h5\n","Epoch 1656/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.0337\n","\n","Epoch 01656: val_loss improved from 0.03377 to 0.03366, saving model to model_checkpoint.h5\n","Epoch 1657/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0125 - val_loss: 0.0336\n","\n","Epoch 01657: val_loss improved from 0.03366 to 0.03355, saving model to model_checkpoint.h5\n","Epoch 1658/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0334\n","\n","Epoch 01658: val_loss improved from 0.03355 to 0.03344, saving model to model_checkpoint.h5\n","Epoch 1659/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0333\n","\n","Epoch 01659: val_loss improved from 0.03344 to 0.03333, saving model to model_checkpoint.h5\n","Epoch 1660/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0127 - val_loss: 0.0332\n","\n","Epoch 01660: val_loss improved from 0.03333 to 0.03322, saving model to model_checkpoint.h5\n","Epoch 1661/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0135 - val_loss: 0.0331\n","\n","Epoch 01661: val_loss improved from 0.03322 to 0.03312, saving model to model_checkpoint.h5\n","Epoch 1662/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0330\n","\n","Epoch 01662: val_loss improved from 0.03312 to 0.03302, saving model to model_checkpoint.h5\n","Epoch 1663/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0329\n","\n","Epoch 01663: val_loss improved from 0.03302 to 0.03292, saving model to model_checkpoint.h5\n","Epoch 1664/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0126 - val_loss: 0.0328\n","\n","Epoch 01664: val_loss improved from 0.03292 to 0.03281, saving model to model_checkpoint.h5\n","Epoch 1665/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0327\n","\n","Epoch 01665: val_loss improved from 0.03281 to 0.03269, saving model to model_checkpoint.h5\n","Epoch 1666/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0326\n","\n","Epoch 01666: val_loss improved from 0.03269 to 0.03258, saving model to model_checkpoint.h5\n","Epoch 1667/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0325\n","\n","Epoch 01667: val_loss improved from 0.03258 to 0.03248, saving model to model_checkpoint.h5\n","Epoch 1668/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0324\n","\n","Epoch 01668: val_loss improved from 0.03248 to 0.03237, saving model to model_checkpoint.h5\n","Epoch 1669/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0127 - val_loss: 0.0323\n","\n","Epoch 01669: val_loss improved from 0.03237 to 0.03226, saving model to model_checkpoint.h5\n","Epoch 1670/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0322\n","\n","Epoch 01670: val_loss improved from 0.03226 to 0.03216, saving model to model_checkpoint.h5\n","Epoch 1671/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0138 - val_loss: 0.0320\n","\n","Epoch 01671: val_loss improved from 0.03216 to 0.03205, saving model to model_checkpoint.h5\n","Epoch 1672/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0319\n","\n","Epoch 01672: val_loss improved from 0.03205 to 0.03195, saving model to model_checkpoint.h5\n","Epoch 1673/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0318\n","\n","Epoch 01673: val_loss improved from 0.03195 to 0.03184, saving model to model_checkpoint.h5\n","Epoch 1674/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0317\n","\n","Epoch 01674: val_loss improved from 0.03184 to 0.03173, saving model to model_checkpoint.h5\n","Epoch 1675/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0133 - val_loss: 0.0316\n","\n","Epoch 01675: val_loss improved from 0.03173 to 0.03161, saving model to model_checkpoint.h5\n","Epoch 1676/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0115 - val_loss: 0.0315\n","\n","Epoch 01676: val_loss improved from 0.03161 to 0.03151, saving model to model_checkpoint.h5\n","Epoch 1677/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0314\n","\n","Epoch 01677: val_loss improved from 0.03151 to 0.03139, saving model to model_checkpoint.h5\n","Epoch 1678/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0117 - val_loss: 0.0313\n","\n","Epoch 01678: val_loss improved from 0.03139 to 0.03129, saving model to model_checkpoint.h5\n","Epoch 1679/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0123 - val_loss: 0.0312\n","\n","Epoch 01679: val_loss improved from 0.03129 to 0.03119, saving model to model_checkpoint.h5\n","Epoch 1680/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0136 - val_loss: 0.0311\n","\n","Epoch 01680: val_loss improved from 0.03119 to 0.03106, saving model to model_checkpoint.h5\n","Epoch 1681/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0310\n","\n","Epoch 01681: val_loss improved from 0.03106 to 0.03096, saving model to model_checkpoint.h5\n","Epoch 1682/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0128 - val_loss: 0.0308\n","\n","Epoch 01682: val_loss improved from 0.03096 to 0.03085, saving model to model_checkpoint.h5\n","Epoch 1683/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0127 - val_loss: 0.0307\n","\n","Epoch 01683: val_loss improved from 0.03085 to 0.03074, saving model to model_checkpoint.h5\n","Epoch 1684/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0125 - val_loss: 0.0306\n","\n","Epoch 01684: val_loss improved from 0.03074 to 0.03062, saving model to model_checkpoint.h5\n","Epoch 1685/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0305\n","\n","Epoch 01685: val_loss improved from 0.03062 to 0.03051, saving model to model_checkpoint.h5\n","Epoch 1686/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0122 - val_loss: 0.0304\n","\n","Epoch 01686: val_loss improved from 0.03051 to 0.03041, saving model to model_checkpoint.h5\n","Epoch 1687/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0124 - val_loss: 0.0303\n","\n","Epoch 01687: val_loss improved from 0.03041 to 0.03029, saving model to model_checkpoint.h5\n","Epoch 1688/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0302\n","\n","Epoch 01688: val_loss improved from 0.03029 to 0.03018, saving model to model_checkpoint.h5\n","Epoch 1689/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0301\n","\n","Epoch 01689: val_loss improved from 0.03018 to 0.03007, saving model to model_checkpoint.h5\n","Epoch 1690/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0146 - val_loss: 0.0300\n","\n","Epoch 01690: val_loss improved from 0.03007 to 0.02997, saving model to model_checkpoint.h5\n","Epoch 1691/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0299\n","\n","Epoch 01691: val_loss improved from 0.02997 to 0.02986, saving model to model_checkpoint.h5\n","Epoch 1692/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0298\n","\n","Epoch 01692: val_loss improved from 0.02986 to 0.02975, saving model to model_checkpoint.h5\n","Epoch 1693/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0297\n","\n","Epoch 01693: val_loss improved from 0.02975 to 0.02966, saving model to model_checkpoint.h5\n","Epoch 1694/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0296\n","\n","Epoch 01694: val_loss improved from 0.02966 to 0.02956, saving model to model_checkpoint.h5\n","Epoch 1695/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0295\n","\n","Epoch 01695: val_loss improved from 0.02956 to 0.02946, saving model to model_checkpoint.h5\n","Epoch 1696/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0115 - val_loss: 0.0294\n","\n","Epoch 01696: val_loss improved from 0.02946 to 0.02936, saving model to model_checkpoint.h5\n","Epoch 1697/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0293\n","\n","Epoch 01697: val_loss improved from 0.02936 to 0.02926, saving model to model_checkpoint.h5\n","Epoch 1698/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0292\n","\n","Epoch 01698: val_loss improved from 0.02926 to 0.02916, saving model to model_checkpoint.h5\n","Epoch 1699/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0134 - val_loss: 0.0291\n","\n","Epoch 01699: val_loss improved from 0.02916 to 0.02906, saving model to model_checkpoint.h5\n","Epoch 1700/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0290\n","\n","Epoch 01700: val_loss improved from 0.02906 to 0.02896, saving model to model_checkpoint.h5\n","Epoch 1701/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0114 - val_loss: 0.0289\n","\n","Epoch 01701: val_loss improved from 0.02896 to 0.02886, saving model to model_checkpoint.h5\n","Epoch 1702/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0287\n","\n","Epoch 01702: val_loss improved from 0.02886 to 0.02875, saving model to model_checkpoint.h5\n","Epoch 1703/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0286\n","\n","Epoch 01703: val_loss improved from 0.02875 to 0.02865, saving model to model_checkpoint.h5\n","Epoch 1704/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0286\n","\n","Epoch 01704: val_loss improved from 0.02865 to 0.02855, saving model to model_checkpoint.h5\n","Epoch 1705/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0285\n","\n","Epoch 01705: val_loss improved from 0.02855 to 0.02846, saving model to model_checkpoint.h5\n","Epoch 1706/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0132 - val_loss: 0.0284\n","\n","Epoch 01706: val_loss improved from 0.02846 to 0.02835, saving model to model_checkpoint.h5\n","Epoch 1707/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0283\n","\n","Epoch 01707: val_loss improved from 0.02835 to 0.02827, saving model to model_checkpoint.h5\n","Epoch 1708/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0126 - val_loss: 0.0282\n","\n","Epoch 01708: val_loss improved from 0.02827 to 0.02817, saving model to model_checkpoint.h5\n","Epoch 1709/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0108 - val_loss: 0.0281\n","\n","Epoch 01709: val_loss improved from 0.02817 to 0.02808, saving model to model_checkpoint.h5\n","Epoch 1710/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0280\n","\n","Epoch 01710: val_loss improved from 0.02808 to 0.02799, saving model to model_checkpoint.h5\n","Epoch 1711/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0121 - val_loss: 0.0279\n","\n","Epoch 01711: val_loss improved from 0.02799 to 0.02789, saving model to model_checkpoint.h5\n","Epoch 1712/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0109 - val_loss: 0.0278\n","\n","Epoch 01712: val_loss improved from 0.02789 to 0.02779, saving model to model_checkpoint.h5\n","Epoch 1713/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0109 - val_loss: 0.0277\n","\n","Epoch 01713: val_loss improved from 0.02779 to 0.02770, saving model to model_checkpoint.h5\n","Epoch 1714/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0111 - val_loss: 0.0276\n","\n","Epoch 01714: val_loss improved from 0.02770 to 0.02762, saving model to model_checkpoint.h5\n","Epoch 1715/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0275\n","\n","Epoch 01715: val_loss improved from 0.02762 to 0.02751, saving model to model_checkpoint.h5\n","Epoch 1716/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0274\n","\n","Epoch 01716: val_loss improved from 0.02751 to 0.02741, saving model to model_checkpoint.h5\n","Epoch 1717/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0273\n","\n","Epoch 01717: val_loss improved from 0.02741 to 0.02732, saving model to model_checkpoint.h5\n","Epoch 1718/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 0.0272\n","\n","Epoch 01718: val_loss improved from 0.02732 to 0.02723, saving model to model_checkpoint.h5\n","Epoch 1719/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0271\n","\n","Epoch 01719: val_loss improved from 0.02723 to 0.02713, saving model to model_checkpoint.h5\n","Epoch 1720/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0270\n","\n","Epoch 01720: val_loss improved from 0.02713 to 0.02704, saving model to model_checkpoint.h5\n","Epoch 1721/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0118 - val_loss: 0.0269\n","\n","Epoch 01721: val_loss improved from 0.02704 to 0.02694, saving model to model_checkpoint.h5\n","Epoch 1722/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0268\n","\n","Epoch 01722: val_loss improved from 0.02694 to 0.02684, saving model to model_checkpoint.h5\n","Epoch 1723/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0128 - val_loss: 0.0267\n","\n","Epoch 01723: val_loss improved from 0.02684 to 0.02674, saving model to model_checkpoint.h5\n","Epoch 1724/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0267\n","\n","Epoch 01724: val_loss improved from 0.02674 to 0.02666, saving model to model_checkpoint.h5\n","Epoch 1725/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0121 - val_loss: 0.0266\n","\n","Epoch 01725: val_loss improved from 0.02666 to 0.02656, saving model to model_checkpoint.h5\n","Epoch 1726/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0265\n","\n","Epoch 01726: val_loss improved from 0.02656 to 0.02646, saving model to model_checkpoint.h5\n","Epoch 1727/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0130 - val_loss: 0.0264\n","\n","Epoch 01727: val_loss improved from 0.02646 to 0.02638, saving model to model_checkpoint.h5\n","Epoch 1728/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0263\n","\n","Epoch 01728: val_loss improved from 0.02638 to 0.02629, saving model to model_checkpoint.h5\n","Epoch 1729/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0117 - val_loss: 0.0262\n","\n","Epoch 01729: val_loss improved from 0.02629 to 0.02621, saving model to model_checkpoint.h5\n","Epoch 1730/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0261\n","\n","Epoch 01730: val_loss improved from 0.02621 to 0.02611, saving model to model_checkpoint.h5\n","Epoch 1731/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0260\n","\n","Epoch 01731: val_loss improved from 0.02611 to 0.02603, saving model to model_checkpoint.h5\n","Epoch 1732/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0118 - val_loss: 0.0259\n","\n","Epoch 01732: val_loss improved from 0.02603 to 0.02593, saving model to model_checkpoint.h5\n","Epoch 1733/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0107 - val_loss: 0.0258\n","\n","Epoch 01733: val_loss improved from 0.02593 to 0.02584, saving model to model_checkpoint.h5\n","Epoch 1734/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0114 - val_loss: 0.0257\n","\n","Epoch 01734: val_loss improved from 0.02584 to 0.02575, saving model to model_checkpoint.h5\n","Epoch 1735/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0124 - val_loss: 0.0257\n","\n","Epoch 01735: val_loss improved from 0.02575 to 0.02566, saving model to model_checkpoint.h5\n","Epoch 1736/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.0256\n","\n","Epoch 01736: val_loss improved from 0.02566 to 0.02556, saving model to model_checkpoint.h5\n","Epoch 1737/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0255\n","\n","Epoch 01737: val_loss improved from 0.02556 to 0.02548, saving model to model_checkpoint.h5\n","Epoch 1738/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0122 - val_loss: 0.0254\n","\n","Epoch 01738: val_loss improved from 0.02548 to 0.02539, saving model to model_checkpoint.h5\n","Epoch 1739/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0112 - val_loss: 0.0253\n","\n","Epoch 01739: val_loss improved from 0.02539 to 0.02531, saving model to model_checkpoint.h5\n","Epoch 1740/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0252\n","\n","Epoch 01740: val_loss improved from 0.02531 to 0.02523, saving model to model_checkpoint.h5\n","Epoch 1741/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0251\n","\n","Epoch 01741: val_loss improved from 0.02523 to 0.02514, saving model to model_checkpoint.h5\n","Epoch 1742/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0116 - val_loss: 0.0251\n","\n","Epoch 01742: val_loss improved from 0.02514 to 0.02506, saving model to model_checkpoint.h5\n","Epoch 1743/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0113 - val_loss: 0.0250\n","\n","Epoch 01743: val_loss improved from 0.02506 to 0.02498, saving model to model_checkpoint.h5\n","Epoch 1744/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0119 - val_loss: 0.0249\n","\n","Epoch 01744: val_loss improved from 0.02498 to 0.02489, saving model to model_checkpoint.h5\n","Epoch 1745/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0248\n","\n","Epoch 01745: val_loss improved from 0.02489 to 0.02480, saving model to model_checkpoint.h5\n","Epoch 1746/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0247\n","\n","Epoch 01746: val_loss improved from 0.02480 to 0.02472, saving model to model_checkpoint.h5\n","Epoch 1747/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0102 - val_loss: 0.0246\n","\n","Epoch 01747: val_loss improved from 0.02472 to 0.02464, saving model to model_checkpoint.h5\n","Epoch 1748/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0245\n","\n","Epoch 01748: val_loss improved from 0.02464 to 0.02454, saving model to model_checkpoint.h5\n","Epoch 1749/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0244\n","\n","Epoch 01749: val_loss improved from 0.02454 to 0.02445, saving model to model_checkpoint.h5\n","Epoch 1750/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0124 - val_loss: 0.0244\n","\n","Epoch 01750: val_loss improved from 0.02445 to 0.02436, saving model to model_checkpoint.h5\n","Epoch 1751/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0116 - val_loss: 0.0243\n","\n","Epoch 01751: val_loss improved from 0.02436 to 0.02427, saving model to model_checkpoint.h5\n","Epoch 1752/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0242\n","\n","Epoch 01752: val_loss improved from 0.02427 to 0.02419, saving model to model_checkpoint.h5\n","Epoch 1753/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0241\n","\n","Epoch 01753: val_loss improved from 0.02419 to 0.02411, saving model to model_checkpoint.h5\n","Epoch 1754/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0104 - val_loss: 0.0240\n","\n","Epoch 01754: val_loss improved from 0.02411 to 0.02402, saving model to model_checkpoint.h5\n","Epoch 1755/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0105 - val_loss: 0.0239\n","\n","Epoch 01755: val_loss improved from 0.02402 to 0.02393, saving model to model_checkpoint.h5\n","Epoch 1756/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0108 - val_loss: 0.0239\n","\n","Epoch 01756: val_loss improved from 0.02393 to 0.02386, saving model to model_checkpoint.h5\n","Epoch 1757/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0238\n","\n","Epoch 01757: val_loss improved from 0.02386 to 0.02378, saving model to model_checkpoint.h5\n","Epoch 1758/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0112 - val_loss: 0.0237\n","\n","Epoch 01758: val_loss improved from 0.02378 to 0.02368, saving model to model_checkpoint.h5\n","Epoch 1759/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0236\n","\n","Epoch 01759: val_loss improved from 0.02368 to 0.02361, saving model to model_checkpoint.h5\n","Epoch 1760/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0235\n","\n","Epoch 01760: val_loss improved from 0.02361 to 0.02352, saving model to model_checkpoint.h5\n","Epoch 1761/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0101 - val_loss: 0.0234\n","\n","Epoch 01761: val_loss improved from 0.02352 to 0.02343, saving model to model_checkpoint.h5\n","Epoch 1762/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0106 - val_loss: 0.0233\n","\n","Epoch 01762: val_loss improved from 0.02343 to 0.02334, saving model to model_checkpoint.h5\n","Epoch 1763/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0233\n","\n","Epoch 01763: val_loss improved from 0.02334 to 0.02326, saving model to model_checkpoint.h5\n","Epoch 1764/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0232\n","\n","Epoch 01764: val_loss improved from 0.02326 to 0.02319, saving model to model_checkpoint.h5\n","Epoch 1765/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0231\n","\n","Epoch 01765: val_loss improved from 0.02319 to 0.02309, saving model to model_checkpoint.h5\n","Epoch 1766/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0112 - val_loss: 0.0230\n","\n","Epoch 01766: val_loss improved from 0.02309 to 0.02300, saving model to model_checkpoint.h5\n","Epoch 1767/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0229\n","\n","Epoch 01767: val_loss improved from 0.02300 to 0.02292, saving model to model_checkpoint.h5\n","Epoch 1768/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0229\n","\n","Epoch 01768: val_loss improved from 0.02292 to 0.02286, saving model to model_checkpoint.h5\n","Epoch 1769/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0228\n","\n","Epoch 01769: val_loss improved from 0.02286 to 0.02279, saving model to model_checkpoint.h5\n","Epoch 1770/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0227\n","\n","Epoch 01770: val_loss improved from 0.02279 to 0.02270, saving model to model_checkpoint.h5\n","Epoch 1771/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0110 - val_loss: 0.0226\n","\n","Epoch 01771: val_loss improved from 0.02270 to 0.02260, saving model to model_checkpoint.h5\n","Epoch 1772/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0225\n","\n","Epoch 01772: val_loss improved from 0.02260 to 0.02252, saving model to model_checkpoint.h5\n","Epoch 1773/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0088 - val_loss: 0.0224\n","\n","Epoch 01773: val_loss improved from 0.02252 to 0.02243, saving model to model_checkpoint.h5\n","Epoch 1774/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0224\n","\n","Epoch 01774: val_loss improved from 0.02243 to 0.02236, saving model to model_checkpoint.h5\n","Epoch 1775/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0223\n","\n","Epoch 01775: val_loss improved from 0.02236 to 0.02229, saving model to model_checkpoint.h5\n","Epoch 1776/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0222\n","\n","Epoch 01776: val_loss improved from 0.02229 to 0.02221, saving model to model_checkpoint.h5\n","Epoch 1777/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0096 - val_loss: 0.0221\n","\n","Epoch 01777: val_loss improved from 0.02221 to 0.02213, saving model to model_checkpoint.h5\n","Epoch 1778/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0221\n","\n","Epoch 01778: val_loss improved from 0.02213 to 0.02206, saving model to model_checkpoint.h5\n","Epoch 1779/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0220\n","\n","Epoch 01779: val_loss improved from 0.02206 to 0.02198, saving model to model_checkpoint.h5\n","Epoch 1780/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0102 - val_loss: 0.0219\n","\n","Epoch 01780: val_loss improved from 0.02198 to 0.02191, saving model to model_checkpoint.h5\n","Epoch 1781/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0106 - val_loss: 0.0218\n","\n","Epoch 01781: val_loss improved from 0.02191 to 0.02184, saving model to model_checkpoint.h5\n","Epoch 1782/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0119 - val_loss: 0.0218\n","\n","Epoch 01782: val_loss improved from 0.02184 to 0.02176, saving model to model_checkpoint.h5\n","Epoch 1783/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0110 - val_loss: 0.0217\n","\n","Epoch 01783: val_loss improved from 0.02176 to 0.02169, saving model to model_checkpoint.h5\n","Epoch 1784/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0216\n","\n","Epoch 01784: val_loss improved from 0.02169 to 0.02162, saving model to model_checkpoint.h5\n","Epoch 1785/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0105 - val_loss: 0.0216\n","\n","Epoch 01785: val_loss improved from 0.02162 to 0.02156, saving model to model_checkpoint.h5\n","Epoch 1786/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0215\n","\n","Epoch 01786: val_loss improved from 0.02156 to 0.02149, saving model to model_checkpoint.h5\n","Epoch 1787/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0116 - val_loss: 0.0214\n","\n","Epoch 01787: val_loss improved from 0.02149 to 0.02142, saving model to model_checkpoint.h5\n","Epoch 1788/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0214\n","\n","Epoch 01788: val_loss improved from 0.02142 to 0.02136, saving model to model_checkpoint.h5\n","Epoch 1789/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0103 - val_loss: 0.0213\n","\n","Epoch 01789: val_loss improved from 0.02136 to 0.02129, saving model to model_checkpoint.h5\n","Epoch 1790/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0212\n","\n","Epoch 01790: val_loss improved from 0.02129 to 0.02121, saving model to model_checkpoint.h5\n","Epoch 1791/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0211\n","\n","Epoch 01791: val_loss improved from 0.02121 to 0.02113, saving model to model_checkpoint.h5\n","Epoch 1792/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0099 - val_loss: 0.0211\n","\n","Epoch 01792: val_loss improved from 0.02113 to 0.02106, saving model to model_checkpoint.h5\n","Epoch 1793/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0103 - val_loss: 0.0210\n","\n","Epoch 01793: val_loss improved from 0.02106 to 0.02098, saving model to model_checkpoint.h5\n","Epoch 1794/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0209\n","\n","Epoch 01794: val_loss improved from 0.02098 to 0.02092, saving model to model_checkpoint.h5\n","Epoch 1795/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0209\n","\n","Epoch 01795: val_loss improved from 0.02092 to 0.02085, saving model to model_checkpoint.h5\n","Epoch 1796/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0106 - val_loss: 0.0208\n","\n","Epoch 01796: val_loss improved from 0.02085 to 0.02077, saving model to model_checkpoint.h5\n","Epoch 1797/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0092 - val_loss: 0.0207\n","\n","Epoch 01797: val_loss improved from 0.02077 to 0.02071, saving model to model_checkpoint.h5\n","Epoch 1798/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0206\n","\n","Epoch 01798: val_loss improved from 0.02071 to 0.02065, saving model to model_checkpoint.h5\n","Epoch 1799/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.0206\n","\n","Epoch 01799: val_loss improved from 0.02065 to 0.02057, saving model to model_checkpoint.h5\n","Epoch 1800/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0097 - val_loss: 0.0205\n","\n","Epoch 01800: val_loss improved from 0.02057 to 0.02051, saving model to model_checkpoint.h5\n","Epoch 1801/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0204\n","\n","Epoch 01801: val_loss improved from 0.02051 to 0.02044, saving model to model_checkpoint.h5\n","Epoch 1802/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0109 - val_loss: 0.0204\n","\n","Epoch 01802: val_loss improved from 0.02044 to 0.02037, saving model to model_checkpoint.h5\n","Epoch 1803/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0203\n","\n","Epoch 01803: val_loss improved from 0.02037 to 0.02030, saving model to model_checkpoint.h5\n","Epoch 1804/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.0202\n","\n","Epoch 01804: val_loss improved from 0.02030 to 0.02023, saving model to model_checkpoint.h5\n","Epoch 1805/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0202\n","\n","Epoch 01805: val_loss improved from 0.02023 to 0.02017, saving model to model_checkpoint.h5\n","Epoch 1806/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0201\n","\n","Epoch 01806: val_loss improved from 0.02017 to 0.02009, saving model to model_checkpoint.h5\n","Epoch 1807/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0200\n","\n","Epoch 01807: val_loss improved from 0.02009 to 0.02003, saving model to model_checkpoint.h5\n","Epoch 1808/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0200\n","\n","Epoch 01808: val_loss improved from 0.02003 to 0.01997, saving model to model_checkpoint.h5\n","Epoch 1809/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0199\n","\n","Epoch 01809: val_loss improved from 0.01997 to 0.01988, saving model to model_checkpoint.h5\n","Epoch 1810/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0198\n","\n","Epoch 01810: val_loss improved from 0.01988 to 0.01982, saving model to model_checkpoint.h5\n","Epoch 1811/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0095 - val_loss: 0.0197\n","\n","Epoch 01811: val_loss improved from 0.01982 to 0.01975, saving model to model_checkpoint.h5\n","Epoch 1812/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0197\n","\n","Epoch 01812: val_loss improved from 0.01975 to 0.01968, saving model to model_checkpoint.h5\n","Epoch 1813/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0101 - val_loss: 0.0196\n","\n","Epoch 01813: val_loss improved from 0.01968 to 0.01961, saving model to model_checkpoint.h5\n","Epoch 1814/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0195\n","\n","Epoch 01814: val_loss improved from 0.01961 to 0.01955, saving model to model_checkpoint.h5\n","Epoch 1815/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0088 - val_loss: 0.0195\n","\n","Epoch 01815: val_loss improved from 0.01955 to 0.01948, saving model to model_checkpoint.h5\n","Epoch 1816/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0194\n","\n","Epoch 01816: val_loss improved from 0.01948 to 0.01940, saving model to model_checkpoint.h5\n","Epoch 1817/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0193\n","\n","Epoch 01817: val_loss improved from 0.01940 to 0.01933, saving model to model_checkpoint.h5\n","Epoch 1818/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0193\n","\n","Epoch 01818: val_loss improved from 0.01933 to 0.01928, saving model to model_checkpoint.h5\n","Epoch 1819/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0107 - val_loss: 0.0192\n","\n","Epoch 01819: val_loss improved from 0.01928 to 0.01921, saving model to model_checkpoint.h5\n","Epoch 1820/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0191\n","\n","Epoch 01820: val_loss improved from 0.01921 to 0.01914, saving model to model_checkpoint.h5\n","Epoch 1821/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0191\n","\n","Epoch 01821: val_loss improved from 0.01914 to 0.01907, saving model to model_checkpoint.h5\n","Epoch 1822/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0190\n","\n","Epoch 01822: val_loss improved from 0.01907 to 0.01901, saving model to model_checkpoint.h5\n","Epoch 1823/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0189\n","\n","Epoch 01823: val_loss improved from 0.01901 to 0.01894, saving model to model_checkpoint.h5\n","Epoch 1824/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0189\n","\n","Epoch 01824: val_loss improved from 0.01894 to 0.01888, saving model to model_checkpoint.h5\n","Epoch 1825/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0188\n","\n","Epoch 01825: val_loss improved from 0.01888 to 0.01882, saving model to model_checkpoint.h5\n","Epoch 1826/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0093 - val_loss: 0.0188\n","\n","Epoch 01826: val_loss improved from 0.01882 to 0.01876, saving model to model_checkpoint.h5\n","Epoch 1827/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0187\n","\n","Epoch 01827: val_loss improved from 0.01876 to 0.01870, saving model to model_checkpoint.h5\n","Epoch 1828/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0093 - val_loss: 0.0186\n","\n","Epoch 01828: val_loss improved from 0.01870 to 0.01863, saving model to model_checkpoint.h5\n","Epoch 1829/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0186\n","\n","Epoch 01829: val_loss improved from 0.01863 to 0.01856, saving model to model_checkpoint.h5\n","Epoch 1830/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0185\n","\n","Epoch 01830: val_loss improved from 0.01856 to 0.01848, saving model to model_checkpoint.h5\n","Epoch 1831/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0103 - val_loss: 0.0184\n","\n","Epoch 01831: val_loss improved from 0.01848 to 0.01841, saving model to model_checkpoint.h5\n","Epoch 1832/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0184\n","\n","Epoch 01832: val_loss improved from 0.01841 to 0.01836, saving model to model_checkpoint.h5\n","Epoch 1833/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0183\n","\n","Epoch 01833: val_loss improved from 0.01836 to 0.01830, saving model to model_checkpoint.h5\n","Epoch 1834/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0182\n","\n","Epoch 01834: val_loss improved from 0.01830 to 0.01824, saving model to model_checkpoint.h5\n","Epoch 1835/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0094 - val_loss: 0.0182\n","\n","Epoch 01835: val_loss improved from 0.01824 to 0.01817, saving model to model_checkpoint.h5\n","Epoch 1836/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0100 - val_loss: 0.0181\n","\n","Epoch 01836: val_loss improved from 0.01817 to 0.01810, saving model to model_checkpoint.h5\n","Epoch 1837/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0180\n","\n","Epoch 01837: val_loss improved from 0.01810 to 0.01803, saving model to model_checkpoint.h5\n","Epoch 1838/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0099 - val_loss: 0.0180\n","\n","Epoch 01838: val_loss improved from 0.01803 to 0.01798, saving model to model_checkpoint.h5\n","Epoch 1839/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0179\n","\n","Epoch 01839: val_loss improved from 0.01798 to 0.01792, saving model to model_checkpoint.h5\n","Epoch 1840/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0178\n","\n","Epoch 01840: val_loss improved from 0.01792 to 0.01785, saving model to model_checkpoint.h5\n","Epoch 1841/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0178\n","\n","Epoch 01841: val_loss improved from 0.01785 to 0.01780, saving model to model_checkpoint.h5\n","Epoch 1842/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0177\n","\n","Epoch 01842: val_loss improved from 0.01780 to 0.01774, saving model to model_checkpoint.h5\n","Epoch 1843/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0102 - val_loss: 0.0177\n","\n","Epoch 01843: val_loss improved from 0.01774 to 0.01768, saving model to model_checkpoint.h5\n","Epoch 1844/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0176\n","\n","Epoch 01844: val_loss improved from 0.01768 to 0.01762, saving model to model_checkpoint.h5\n","Epoch 1845/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0176\n","\n","Epoch 01845: val_loss improved from 0.01762 to 0.01756, saving model to model_checkpoint.h5\n","Epoch 1846/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0098 - val_loss: 0.0175\n","\n","Epoch 01846: val_loss improved from 0.01756 to 0.01750, saving model to model_checkpoint.h5\n","Epoch 1847/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0090 - val_loss: 0.0174\n","\n","Epoch 01847: val_loss improved from 0.01750 to 0.01745, saving model to model_checkpoint.h5\n","Epoch 1848/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0174\n","\n","Epoch 01848: val_loss improved from 0.01745 to 0.01738, saving model to model_checkpoint.h5\n","Epoch 1849/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0095 - val_loss: 0.0173\n","\n","Epoch 01849: val_loss improved from 0.01738 to 0.01734, saving model to model_checkpoint.h5\n","Epoch 1850/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0097 - val_loss: 0.0173\n","\n","Epoch 01850: val_loss improved from 0.01734 to 0.01729, saving model to model_checkpoint.h5\n","Epoch 1851/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0086 - val_loss: 0.0172\n","\n","Epoch 01851: val_loss improved from 0.01729 to 0.01723, saving model to model_checkpoint.h5\n","Epoch 1852/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0172\n","\n","Epoch 01852: val_loss improved from 0.01723 to 0.01718, saving model to model_checkpoint.h5\n","Epoch 1853/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.0171\n","\n","Epoch 01853: val_loss improved from 0.01718 to 0.01714, saving model to model_checkpoint.h5\n","Epoch 1854/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0091 - val_loss: 0.0171\n","\n","Epoch 01854: val_loss improved from 0.01714 to 0.01708, saving model to model_checkpoint.h5\n","Epoch 1855/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0170\n","\n","Epoch 01855: val_loss improved from 0.01708 to 0.01703, saving model to model_checkpoint.h5\n","Epoch 1856/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0170\n","\n","Epoch 01856: val_loss improved from 0.01703 to 0.01697, saving model to model_checkpoint.h5\n","Epoch 1857/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0169\n","\n","Epoch 01857: val_loss improved from 0.01697 to 0.01692, saving model to model_checkpoint.h5\n","Epoch 1858/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0169\n","\n","Epoch 01858: val_loss improved from 0.01692 to 0.01687, saving model to model_checkpoint.h5\n","Epoch 1859/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0168\n","\n","Epoch 01859: val_loss improved from 0.01687 to 0.01680, saving model to model_checkpoint.h5\n","Epoch 1860/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0096 - val_loss: 0.0167\n","\n","Epoch 01860: val_loss improved from 0.01680 to 0.01674, saving model to model_checkpoint.h5\n","Epoch 1861/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0167\n","\n","Epoch 01861: val_loss improved from 0.01674 to 0.01669, saving model to model_checkpoint.h5\n","Epoch 1862/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0166\n","\n","Epoch 01862: val_loss improved from 0.01669 to 0.01664, saving model to model_checkpoint.h5\n","Epoch 1863/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0091 - val_loss: 0.0166\n","\n","Epoch 01863: val_loss improved from 0.01664 to 0.01659, saving model to model_checkpoint.h5\n","Epoch 1864/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0089 - val_loss: 0.0165\n","\n","Epoch 01864: val_loss improved from 0.01659 to 0.01653, saving model to model_checkpoint.h5\n","Epoch 1865/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0165\n","\n","Epoch 01865: val_loss improved from 0.01653 to 0.01648, saving model to model_checkpoint.h5\n","Epoch 1866/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0164\n","\n","Epoch 01866: val_loss improved from 0.01648 to 0.01641, saving model to model_checkpoint.h5\n","Epoch 1867/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0163\n","\n","Epoch 01867: val_loss improved from 0.01641 to 0.01634, saving model to model_checkpoint.h5\n","Epoch 1868/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0163\n","\n","Epoch 01868: val_loss improved from 0.01634 to 0.01629, saving model to model_checkpoint.h5\n","Epoch 1869/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0162\n","\n","Epoch 01869: val_loss improved from 0.01629 to 0.01623, saving model to model_checkpoint.h5\n","Epoch 1870/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0162\n","\n","Epoch 01870: val_loss improved from 0.01623 to 0.01617, saving model to model_checkpoint.h5\n","Epoch 1871/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0161\n","\n","Epoch 01871: val_loss improved from 0.01617 to 0.01611, saving model to model_checkpoint.h5\n","Epoch 1872/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0087 - val_loss: 0.0160\n","\n","Epoch 01872: val_loss improved from 0.01611 to 0.01605, saving model to model_checkpoint.h5\n","Epoch 1873/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0160\n","\n","Epoch 01873: val_loss improved from 0.01605 to 0.01598, saving model to model_checkpoint.h5\n","Epoch 1874/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0159\n","\n","Epoch 01874: val_loss improved from 0.01598 to 0.01591, saving model to model_checkpoint.h5\n","Epoch 1875/50000\n","9/9 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0159\n","\n","Epoch 01875: val_loss improved from 0.01591 to 0.01585, saving model to model_checkpoint.h5\n","Epoch 1876/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0098 - val_loss: 0.0158\n","\n","Epoch 01876: val_loss improved from 0.01585 to 0.01579, saving model to model_checkpoint.h5\n","Epoch 1877/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0157\n","\n","Epoch 01877: val_loss improved from 0.01579 to 0.01574, saving model to model_checkpoint.h5\n","Epoch 1878/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0157\n","\n","Epoch 01878: val_loss improved from 0.01574 to 0.01569, saving model to model_checkpoint.h5\n","Epoch 1879/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0087 - val_loss: 0.0156\n","\n","Epoch 01879: val_loss improved from 0.01569 to 0.01564, saving model to model_checkpoint.h5\n","Epoch 1880/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0156\n","\n","Epoch 01880: val_loss improved from 0.01564 to 0.01558, saving model to model_checkpoint.h5\n","Epoch 1881/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0155\n","\n","Epoch 01881: val_loss improved from 0.01558 to 0.01553, saving model to model_checkpoint.h5\n","Epoch 1882/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0155\n","\n","Epoch 01882: val_loss improved from 0.01553 to 0.01549, saving model to model_checkpoint.h5\n","Epoch 1883/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0154\n","\n","Epoch 01883: val_loss improved from 0.01549 to 0.01544, saving model to model_checkpoint.h5\n","Epoch 1884/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0154\n","\n","Epoch 01884: val_loss improved from 0.01544 to 0.01538, saving model to model_checkpoint.h5\n","Epoch 1885/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0153\n","\n","Epoch 01885: val_loss improved from 0.01538 to 0.01532, saving model to model_checkpoint.h5\n","Epoch 1886/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0082 - val_loss: 0.0153\n","\n","Epoch 01886: val_loss improved from 0.01532 to 0.01528, saving model to model_checkpoint.h5\n","Epoch 1887/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0152\n","\n","Epoch 01887: val_loss improved from 0.01528 to 0.01523, saving model to model_checkpoint.h5\n","Epoch 1888/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0152\n","\n","Epoch 01888: val_loss improved from 0.01523 to 0.01518, saving model to model_checkpoint.h5\n","Epoch 1889/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0096 - val_loss: 0.0151\n","\n","Epoch 01889: val_loss improved from 0.01518 to 0.01512, saving model to model_checkpoint.h5\n","Epoch 1890/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0151\n","\n","Epoch 01890: val_loss improved from 0.01512 to 0.01508, saving model to model_checkpoint.h5\n","Epoch 1891/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0091 - val_loss: 0.0150\n","\n","Epoch 01891: val_loss improved from 0.01508 to 0.01503, saving model to model_checkpoint.h5\n","Epoch 1892/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0081 - val_loss: 0.0150\n","\n","Epoch 01892: val_loss improved from 0.01503 to 0.01499, saving model to model_checkpoint.h5\n","Epoch 1893/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0149\n","\n","Epoch 01893: val_loss improved from 0.01499 to 0.01494, saving model to model_checkpoint.h5\n","Epoch 1894/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0149\n","\n","Epoch 01894: val_loss improved from 0.01494 to 0.01489, saving model to model_checkpoint.h5\n","Epoch 1895/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0082 - val_loss: 0.0148\n","\n","Epoch 01895: val_loss improved from 0.01489 to 0.01485, saving model to model_checkpoint.h5\n","Epoch 1896/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0148\n","\n","Epoch 01896: val_loss improved from 0.01485 to 0.01479, saving model to model_checkpoint.h5\n","Epoch 1897/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0147\n","\n","Epoch 01897: val_loss improved from 0.01479 to 0.01474, saving model to model_checkpoint.h5\n","Epoch 1898/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0072 - val_loss: 0.0147\n","\n","Epoch 01898: val_loss improved from 0.01474 to 0.01470, saving model to model_checkpoint.h5\n","Epoch 1899/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0147\n","\n","Epoch 01899: val_loss improved from 0.01470 to 0.01466, saving model to model_checkpoint.h5\n","Epoch 1900/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0092 - val_loss: 0.0146\n","\n","Epoch 01900: val_loss improved from 0.01466 to 0.01460, saving model to model_checkpoint.h5\n","Epoch 1901/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0095 - val_loss: 0.0145\n","\n","Epoch 01901: val_loss improved from 0.01460 to 0.01455, saving model to model_checkpoint.h5\n","Epoch 1902/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0145\n","\n","Epoch 01902: val_loss improved from 0.01455 to 0.01451, saving model to model_checkpoint.h5\n","Epoch 1903/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0145\n","\n","Epoch 01903: val_loss improved from 0.01451 to 0.01447, saving model to model_checkpoint.h5\n","Epoch 1904/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0144\n","\n","Epoch 01904: val_loss improved from 0.01447 to 0.01442, saving model to model_checkpoint.h5\n","Epoch 1905/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0144\n","\n","Epoch 01905: val_loss improved from 0.01442 to 0.01438, saving model to model_checkpoint.h5\n","Epoch 1906/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0143\n","\n","Epoch 01906: val_loss improved from 0.01438 to 0.01433, saving model to model_checkpoint.h5\n","Epoch 1907/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0143\n","\n","Epoch 01907: val_loss improved from 0.01433 to 0.01429, saving model to model_checkpoint.h5\n","Epoch 1908/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0142\n","\n","Epoch 01908: val_loss improved from 0.01429 to 0.01424, saving model to model_checkpoint.h5\n","Epoch 1909/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0085 - val_loss: 0.0142\n","\n","Epoch 01909: val_loss improved from 0.01424 to 0.01418, saving model to model_checkpoint.h5\n","Epoch 1910/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 0.0141\n","\n","Epoch 01910: val_loss improved from 0.01418 to 0.01413, saving model to model_checkpoint.h5\n","Epoch 1911/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0141\n","\n","Epoch 01911: val_loss improved from 0.01413 to 0.01409, saving model to model_checkpoint.h5\n","Epoch 1912/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0140\n","\n","Epoch 01912: val_loss improved from 0.01409 to 0.01403, saving model to model_checkpoint.h5\n","Epoch 1913/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0079 - val_loss: 0.0140\n","\n","Epoch 01913: val_loss improved from 0.01403 to 0.01399, saving model to model_checkpoint.h5\n","Epoch 1914/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0086 - val_loss: 0.0139\n","\n","Epoch 01914: val_loss improved from 0.01399 to 0.01394, saving model to model_checkpoint.h5\n","Epoch 1915/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0139\n","\n","Epoch 01915: val_loss improved from 0.01394 to 0.01390, saving model to model_checkpoint.h5\n","Epoch 1916/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0138\n","\n","Epoch 01916: val_loss improved from 0.01390 to 0.01385, saving model to model_checkpoint.h5\n","Epoch 1917/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0138\n","\n","Epoch 01917: val_loss improved from 0.01385 to 0.01382, saving model to model_checkpoint.h5\n","Epoch 1918/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0138\n","\n","Epoch 01918: val_loss improved from 0.01382 to 0.01377, saving model to model_checkpoint.h5\n","Epoch 1919/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0081 - val_loss: 0.0137\n","\n","Epoch 01919: val_loss improved from 0.01377 to 0.01372, saving model to model_checkpoint.h5\n","Epoch 1920/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0137\n","\n","Epoch 01920: val_loss improved from 0.01372 to 0.01368, saving model to model_checkpoint.h5\n","Epoch 1921/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0088 - val_loss: 0.0136\n","\n","Epoch 01921: val_loss improved from 0.01368 to 0.01363, saving model to model_checkpoint.h5\n","Epoch 1922/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0136\n","\n","Epoch 01922: val_loss improved from 0.01363 to 0.01358, saving model to model_checkpoint.h5\n","Epoch 1923/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0135\n","\n","Epoch 01923: val_loss improved from 0.01358 to 0.01354, saving model to model_checkpoint.h5\n","Epoch 1924/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0135\n","\n","Epoch 01924: val_loss improved from 0.01354 to 0.01348, saving model to model_checkpoint.h5\n","Epoch 1925/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0134\n","\n","Epoch 01925: val_loss improved from 0.01348 to 0.01342, saving model to model_checkpoint.h5\n","Epoch 1926/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0086 - val_loss: 0.0134\n","\n","Epoch 01926: val_loss improved from 0.01342 to 0.01338, saving model to model_checkpoint.h5\n","Epoch 1927/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0133\n","\n","Epoch 01927: val_loss improved from 0.01338 to 0.01332, saving model to model_checkpoint.h5\n","Epoch 1928/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0133\n","\n","Epoch 01928: val_loss improved from 0.01332 to 0.01327, saving model to model_checkpoint.h5\n","Epoch 1929/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0132\n","\n","Epoch 01929: val_loss improved from 0.01327 to 0.01322, saving model to model_checkpoint.h5\n","Epoch 1930/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0132\n","\n","Epoch 01930: val_loss improved from 0.01322 to 0.01317, saving model to model_checkpoint.h5\n","Epoch 1931/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0131\n","\n","Epoch 01931: val_loss improved from 0.01317 to 0.01312, saving model to model_checkpoint.h5\n","Epoch 1932/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0131\n","\n","Epoch 01932: val_loss improved from 0.01312 to 0.01308, saving model to model_checkpoint.h5\n","Epoch 1933/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0130\n","\n","Epoch 01933: val_loss improved from 0.01308 to 0.01304, saving model to model_checkpoint.h5\n","Epoch 1934/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0130\n","\n","Epoch 01934: val_loss improved from 0.01304 to 0.01300, saving model to model_checkpoint.h5\n","Epoch 1935/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0129\n","\n","Epoch 01935: val_loss improved from 0.01300 to 0.01295, saving model to model_checkpoint.h5\n","Epoch 1936/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.0129\n","\n","Epoch 01936: val_loss improved from 0.01295 to 0.01290, saving model to model_checkpoint.h5\n","Epoch 1937/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0076 - val_loss: 0.0129\n","\n","Epoch 01937: val_loss improved from 0.01290 to 0.01286, saving model to model_checkpoint.h5\n","Epoch 1938/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0081 - val_loss: 0.0128\n","\n","Epoch 01938: val_loss improved from 0.01286 to 0.01281, saving model to model_checkpoint.h5\n","Epoch 1939/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0128\n","\n","Epoch 01939: val_loss improved from 0.01281 to 0.01277, saving model to model_checkpoint.h5\n","Epoch 1940/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0127\n","\n","Epoch 01940: val_loss improved from 0.01277 to 0.01273, saving model to model_checkpoint.h5\n","Epoch 1941/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0127\n","\n","Epoch 01941: val_loss improved from 0.01273 to 0.01269, saving model to model_checkpoint.h5\n","Epoch 1942/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0078 - val_loss: 0.0126\n","\n","Epoch 01942: val_loss improved from 0.01269 to 0.01265, saving model to model_checkpoint.h5\n","Epoch 1943/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0126\n","\n","Epoch 01943: val_loss improved from 0.01265 to 0.01261, saving model to model_checkpoint.h5\n","Epoch 1944/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0126\n","\n","Epoch 01944: val_loss improved from 0.01261 to 0.01257, saving model to model_checkpoint.h5\n","Epoch 1945/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0084 - val_loss: 0.0125\n","\n","Epoch 01945: val_loss improved from 0.01257 to 0.01253, saving model to model_checkpoint.h5\n","Epoch 1946/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0125\n","\n","Epoch 01946: val_loss improved from 0.01253 to 0.01249, saving model to model_checkpoint.h5\n","Epoch 1947/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0124\n","\n","Epoch 01947: val_loss improved from 0.01249 to 0.01245, saving model to model_checkpoint.h5\n","Epoch 1948/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0071 - val_loss: 0.0124\n","\n","Epoch 01948: val_loss improved from 0.01245 to 0.01241, saving model to model_checkpoint.h5\n","Epoch 1949/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0077 - val_loss: 0.0124\n","\n","Epoch 01949: val_loss improved from 0.01241 to 0.01237, saving model to model_checkpoint.h5\n","Epoch 1950/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0123\n","\n","Epoch 01950: val_loss improved from 0.01237 to 0.01234, saving model to model_checkpoint.h5\n","Epoch 1951/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0123\n","\n","Epoch 01951: val_loss improved from 0.01234 to 0.01230, saving model to model_checkpoint.h5\n","Epoch 1952/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0123\n","\n","Epoch 01952: val_loss improved from 0.01230 to 0.01227, saving model to model_checkpoint.h5\n","Epoch 1953/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0122\n","\n","Epoch 01953: val_loss improved from 0.01227 to 0.01223, saving model to model_checkpoint.h5\n","Epoch 1954/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.0122\n","\n","Epoch 01954: val_loss improved from 0.01223 to 0.01219, saving model to model_checkpoint.h5\n","Epoch 1955/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0121\n","\n","Epoch 01955: val_loss improved from 0.01219 to 0.01215, saving model to model_checkpoint.h5\n","Epoch 1956/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0121\n","\n","Epoch 01956: val_loss improved from 0.01215 to 0.01212, saving model to model_checkpoint.h5\n","Epoch 1957/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0121\n","\n","Epoch 01957: val_loss improved from 0.01212 to 0.01209, saving model to model_checkpoint.h5\n","Epoch 1958/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0084 - val_loss: 0.0120\n","\n","Epoch 01958: val_loss improved from 0.01209 to 0.01205, saving model to model_checkpoint.h5\n","Epoch 1959/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0075 - val_loss: 0.0120\n","\n","Epoch 01959: val_loss improved from 0.01205 to 0.01201, saving model to model_checkpoint.h5\n","Epoch 1960/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0077 - val_loss: 0.0120\n","\n","Epoch 01960: val_loss improved from 0.01201 to 0.01197, saving model to model_checkpoint.h5\n","Epoch 1961/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0119\n","\n","Epoch 01961: val_loss improved from 0.01197 to 0.01193, saving model to model_checkpoint.h5\n","Epoch 1962/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0119\n","\n","Epoch 01962: val_loss improved from 0.01193 to 0.01190, saving model to model_checkpoint.h5\n","Epoch 1963/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0119\n","\n","Epoch 01963: val_loss improved from 0.01190 to 0.01186, saving model to model_checkpoint.h5\n","Epoch 1964/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0083 - val_loss: 0.0118\n","\n","Epoch 01964: val_loss improved from 0.01186 to 0.01180, saving model to model_checkpoint.h5\n","Epoch 1965/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0118\n","\n","Epoch 01965: val_loss improved from 0.01180 to 0.01176, saving model to model_checkpoint.h5\n","Epoch 1966/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0117\n","\n","Epoch 01966: val_loss improved from 0.01176 to 0.01172, saving model to model_checkpoint.h5\n","Epoch 1967/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0117\n","\n","Epoch 01967: val_loss improved from 0.01172 to 0.01169, saving model to model_checkpoint.h5\n","Epoch 1968/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0117\n","\n","Epoch 01968: val_loss improved from 0.01169 to 0.01166, saving model to model_checkpoint.h5\n","Epoch 1969/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0116\n","\n","Epoch 01969: val_loss improved from 0.01166 to 0.01162, saving model to model_checkpoint.h5\n","Epoch 1970/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.0116\n","\n","Epoch 01970: val_loss improved from 0.01162 to 0.01158, saving model to model_checkpoint.h5\n","Epoch 1971/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0083 - val_loss: 0.0115\n","\n","Epoch 01971: val_loss improved from 0.01158 to 0.01154, saving model to model_checkpoint.h5\n","Epoch 1972/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0115\n","\n","Epoch 01972: val_loss improved from 0.01154 to 0.01150, saving model to model_checkpoint.h5\n","Epoch 1973/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0115\n","\n","Epoch 01973: val_loss improved from 0.01150 to 0.01148, saving model to model_checkpoint.h5\n","Epoch 1974/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0115\n","\n","Epoch 01974: val_loss improved from 0.01148 to 0.01145, saving model to model_checkpoint.h5\n","Epoch 1975/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0085 - val_loss: 0.0114\n","\n","Epoch 01975: val_loss improved from 0.01145 to 0.01141, saving model to model_checkpoint.h5\n","Epoch 1976/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0071 - val_loss: 0.0114\n","\n","Epoch 01976: val_loss improved from 0.01141 to 0.01138, saving model to model_checkpoint.h5\n","Epoch 1977/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0113\n","\n","Epoch 01977: val_loss improved from 0.01138 to 0.01134, saving model to model_checkpoint.h5\n","Epoch 1978/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0113\n","\n","Epoch 01978: val_loss improved from 0.01134 to 0.01131, saving model to model_checkpoint.h5\n","Epoch 1979/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0113\n","\n","Epoch 01979: val_loss improved from 0.01131 to 0.01128, saving model to model_checkpoint.h5\n","Epoch 1980/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0080 - val_loss: 0.0112\n","\n","Epoch 01980: val_loss improved from 0.01128 to 0.01124, saving model to model_checkpoint.h5\n","Epoch 1981/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0077 - val_loss: 0.0112\n","\n","Epoch 01981: val_loss improved from 0.01124 to 0.01121, saving model to model_checkpoint.h5\n","Epoch 1982/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0075 - val_loss: 0.0112\n","\n","Epoch 01982: val_loss improved from 0.01121 to 0.01118, saving model to model_checkpoint.h5\n","Epoch 1983/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0111\n","\n","Epoch 01983: val_loss improved from 0.01118 to 0.01115, saving model to model_checkpoint.h5\n","Epoch 1984/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0111\n","\n","Epoch 01984: val_loss improved from 0.01115 to 0.01112, saving model to model_checkpoint.h5\n","Epoch 1985/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0081 - val_loss: 0.0111\n","\n","Epoch 01985: val_loss improved from 0.01112 to 0.01109, saving model to model_checkpoint.h5\n","Epoch 1986/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0111\n","\n","Epoch 01986: val_loss improved from 0.01109 to 0.01106, saving model to model_checkpoint.h5\n","Epoch 1987/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0110\n","\n","Epoch 01987: val_loss improved from 0.01106 to 0.01103, saving model to model_checkpoint.h5\n","Epoch 1988/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0110\n","\n","Epoch 01988: val_loss improved from 0.01103 to 0.01100, saving model to model_checkpoint.h5\n","Epoch 1989/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0110\n","\n","Epoch 01989: val_loss improved from 0.01100 to 0.01097, saving model to model_checkpoint.h5\n","Epoch 1990/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0109\n","\n","Epoch 01990: val_loss improved from 0.01097 to 0.01094, saving model to model_checkpoint.h5\n","Epoch 1991/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.0109\n","\n","Epoch 01991: val_loss improved from 0.01094 to 0.01091, saving model to model_checkpoint.h5\n","Epoch 1992/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0109\n","\n","Epoch 01992: val_loss improved from 0.01091 to 0.01089, saving model to model_checkpoint.h5\n","Epoch 1993/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0109\n","\n","Epoch 01993: val_loss improved from 0.01089 to 0.01086, saving model to model_checkpoint.h5\n","Epoch 1994/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0108\n","\n","Epoch 01994: val_loss improved from 0.01086 to 0.01083, saving model to model_checkpoint.h5\n","Epoch 1995/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0071 - val_loss: 0.0108\n","\n","Epoch 01995: val_loss improved from 0.01083 to 0.01080, saving model to model_checkpoint.h5\n","Epoch 1996/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0108\n","\n","Epoch 01996: val_loss improved from 0.01080 to 0.01077, saving model to model_checkpoint.h5\n","Epoch 1997/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0107\n","\n","Epoch 01997: val_loss improved from 0.01077 to 0.01074, saving model to model_checkpoint.h5\n","Epoch 1998/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0079 - val_loss: 0.0107\n","\n","Epoch 01998: val_loss improved from 0.01074 to 0.01070, saving model to model_checkpoint.h5\n","Epoch 1999/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0068 - val_loss: 0.0107\n","\n","Epoch 01999: val_loss improved from 0.01070 to 0.01067, saving model to model_checkpoint.h5\n","Epoch 2000/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0074 - val_loss: 0.0106\n","\n","Epoch 02000: val_loss improved from 0.01067 to 0.01064, saving model to model_checkpoint.h5\n","Epoch 2001/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0106\n","\n","Epoch 02001: val_loss improved from 0.01064 to 0.01062, saving model to model_checkpoint.h5\n","Epoch 2002/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0106\n","\n","Epoch 02002: val_loss improved from 0.01062 to 0.01059, saving model to model_checkpoint.h5\n","Epoch 2003/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0105\n","\n","Epoch 02003: val_loss improved from 0.01059 to 0.01054, saving model to model_checkpoint.h5\n","Epoch 2004/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0105\n","\n","Epoch 02004: val_loss improved from 0.01054 to 0.01051, saving model to model_checkpoint.h5\n","Epoch 2005/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0105\n","\n","Epoch 02005: val_loss improved from 0.01051 to 0.01048, saving model to model_checkpoint.h5\n","Epoch 2006/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0105\n","\n","Epoch 02006: val_loss improved from 0.01048 to 0.01046, saving model to model_checkpoint.h5\n","Epoch 2007/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0104\n","\n","Epoch 02007: val_loss improved from 0.01046 to 0.01044, saving model to model_checkpoint.h5\n","Epoch 2008/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0104\n","\n","Epoch 02008: val_loss improved from 0.01044 to 0.01040, saving model to model_checkpoint.h5\n","Epoch 2009/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0104\n","\n","Epoch 02009: val_loss improved from 0.01040 to 0.01037, saving model to model_checkpoint.h5\n","Epoch 2010/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0103\n","\n","Epoch 02010: val_loss improved from 0.01037 to 0.01034, saving model to model_checkpoint.h5\n","Epoch 2011/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0079 - val_loss: 0.0103\n","\n","Epoch 02011: val_loss improved from 0.01034 to 0.01031, saving model to model_checkpoint.h5\n","Epoch 2012/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0077 - val_loss: 0.0103\n","\n","Epoch 02012: val_loss improved from 0.01031 to 0.01029, saving model to model_checkpoint.h5\n","Epoch 2013/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0070 - val_loss: 0.0103\n","\n","Epoch 02013: val_loss improved from 0.01029 to 0.01026, saving model to model_checkpoint.h5\n","Epoch 2014/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0067 - val_loss: 0.0102\n","\n","Epoch 02014: val_loss improved from 0.01026 to 0.01022, saving model to model_checkpoint.h5\n","Epoch 2015/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.0102\n","\n","Epoch 02015: val_loss improved from 0.01022 to 0.01019, saving model to model_checkpoint.h5\n","Epoch 2016/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0102\n","\n","Epoch 02016: val_loss improved from 0.01019 to 0.01016, saving model to model_checkpoint.h5\n","Epoch 2017/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0071 - val_loss: 0.0101\n","\n","Epoch 02017: val_loss improved from 0.01016 to 0.01014, saving model to model_checkpoint.h5\n","Epoch 2018/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0066 - val_loss: 0.0101\n","\n","Epoch 02018: val_loss improved from 0.01014 to 0.01011, saving model to model_checkpoint.h5\n","Epoch 2019/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0101\n","\n","Epoch 02019: val_loss improved from 0.01011 to 0.01007, saving model to model_checkpoint.h5\n","Epoch 2020/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0100\n","\n","Epoch 02020: val_loss improved from 0.01007 to 0.01005, saving model to model_checkpoint.h5\n","Epoch 2021/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0100\n","\n","Epoch 02021: val_loss improved from 0.01005 to 0.01002, saving model to model_checkpoint.h5\n","Epoch 2022/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0062 - val_loss: 0.0100\n","\n","Epoch 02022: val_loss improved from 0.01002 to 0.00999, saving model to model_checkpoint.h5\n","Epoch 2023/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0100\n","\n","Epoch 02023: val_loss improved from 0.00999 to 0.00997, saving model to model_checkpoint.h5\n","Epoch 2024/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0099\n","\n","Epoch 02024: val_loss improved from 0.00997 to 0.00993, saving model to model_checkpoint.h5\n","Epoch 2025/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0099\n","\n","Epoch 02025: val_loss improved from 0.00993 to 0.00989, saving model to model_checkpoint.h5\n","Epoch 2026/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0063 - val_loss: 0.0099\n","\n","Epoch 02026: val_loss improved from 0.00989 to 0.00986, saving model to model_checkpoint.h5\n","Epoch 2027/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0098\n","\n","Epoch 02027: val_loss improved from 0.00986 to 0.00983, saving model to model_checkpoint.h5\n","Epoch 2028/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0072 - val_loss: 0.0098\n","\n","Epoch 02028: val_loss improved from 0.00983 to 0.00980, saving model to model_checkpoint.h5\n","Epoch 2029/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0098\n","\n","Epoch 02029: val_loss improved from 0.00980 to 0.00977, saving model to model_checkpoint.h5\n","Epoch 2030/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0097\n","\n","Epoch 02030: val_loss improved from 0.00977 to 0.00974, saving model to model_checkpoint.h5\n","Epoch 2031/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0097\n","\n","Epoch 02031: val_loss improved from 0.00974 to 0.00971, saving model to model_checkpoint.h5\n","Epoch 2032/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0097\n","\n","Epoch 02032: val_loss improved from 0.00971 to 0.00969, saving model to model_checkpoint.h5\n","Epoch 2033/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0097\n","\n","Epoch 02033: val_loss improved from 0.00969 to 0.00966, saving model to model_checkpoint.h5\n","Epoch 2034/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0072 - val_loss: 0.0096\n","\n","Epoch 02034: val_loss improved from 0.00966 to 0.00963, saving model to model_checkpoint.h5\n","Epoch 2035/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0096\n","\n","Epoch 02035: val_loss improved from 0.00963 to 0.00961, saving model to model_checkpoint.h5\n","Epoch 2036/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0096\n","\n","Epoch 02036: val_loss improved from 0.00961 to 0.00958, saving model to model_checkpoint.h5\n","Epoch 2037/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0096\n","\n","Epoch 02037: val_loss improved from 0.00958 to 0.00956, saving model to model_checkpoint.h5\n","Epoch 2038/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0067 - val_loss: 0.0095\n","\n","Epoch 02038: val_loss improved from 0.00956 to 0.00954, saving model to model_checkpoint.h5\n","Epoch 2039/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0095\n","\n","Epoch 02039: val_loss improved from 0.00954 to 0.00951, saving model to model_checkpoint.h5\n","Epoch 2040/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0095\n","\n","Epoch 02040: val_loss improved from 0.00951 to 0.00948, saving model to model_checkpoint.h5\n","Epoch 2041/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0064 - val_loss: 0.0094\n","\n","Epoch 02041: val_loss improved from 0.00948 to 0.00944, saving model to model_checkpoint.h5\n","Epoch 2042/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0068 - val_loss: 0.0094\n","\n","Epoch 02042: val_loss improved from 0.00944 to 0.00941, saving model to model_checkpoint.h5\n","Epoch 2043/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0094\n","\n","Epoch 02043: val_loss improved from 0.00941 to 0.00938, saving model to model_checkpoint.h5\n","Epoch 2044/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0094\n","\n","Epoch 02044: val_loss improved from 0.00938 to 0.00935, saving model to model_checkpoint.h5\n","Epoch 2045/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0093\n","\n","Epoch 02045: val_loss improved from 0.00935 to 0.00932, saving model to model_checkpoint.h5\n","Epoch 2046/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0064 - val_loss: 0.0093\n","\n","Epoch 02046: val_loss improved from 0.00932 to 0.00929, saving model to model_checkpoint.h5\n","Epoch 2047/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0093\n","\n","Epoch 02047: val_loss improved from 0.00929 to 0.00925, saving model to model_checkpoint.h5\n","Epoch 2048/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0092\n","\n","Epoch 02048: val_loss improved from 0.00925 to 0.00922, saving model to model_checkpoint.h5\n","Epoch 2049/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0092\n","\n","Epoch 02049: val_loss improved from 0.00922 to 0.00919, saving model to model_checkpoint.h5\n","Epoch 2050/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0092\n","\n","Epoch 02050: val_loss improved from 0.00919 to 0.00916, saving model to model_checkpoint.h5\n","Epoch 2051/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0091\n","\n","Epoch 02051: val_loss improved from 0.00916 to 0.00913, saving model to model_checkpoint.h5\n","Epoch 2052/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0091\n","\n","Epoch 02052: val_loss improved from 0.00913 to 0.00910, saving model to model_checkpoint.h5\n","Epoch 2053/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0091\n","\n","Epoch 02053: val_loss improved from 0.00910 to 0.00908, saving model to model_checkpoint.h5\n","Epoch 2054/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0070 - val_loss: 0.0091\n","\n","Epoch 02054: val_loss improved from 0.00908 to 0.00905, saving model to model_checkpoint.h5\n","Epoch 2055/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0090\n","\n","Epoch 02055: val_loss improved from 0.00905 to 0.00903, saving model to model_checkpoint.h5\n","Epoch 2056/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0090\n","\n","Epoch 02056: val_loss improved from 0.00903 to 0.00900, saving model to model_checkpoint.h5\n","Epoch 2057/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0073 - val_loss: 0.0090\n","\n","Epoch 02057: val_loss improved from 0.00900 to 0.00898, saving model to model_checkpoint.h5\n","Epoch 2058/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0090\n","\n","Epoch 02058: val_loss improved from 0.00898 to 0.00896, saving model to model_checkpoint.h5\n","Epoch 2059/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0089\n","\n","Epoch 02059: val_loss improved from 0.00896 to 0.00894, saving model to model_checkpoint.h5\n","Epoch 2060/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0065 - val_loss: 0.0089\n","\n","Epoch 02060: val_loss improved from 0.00894 to 0.00892, saving model to model_checkpoint.h5\n","Epoch 2061/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0089\n","\n","Epoch 02061: val_loss improved from 0.00892 to 0.00889, saving model to model_checkpoint.h5\n","Epoch 2062/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0089\n","\n","Epoch 02062: val_loss improved from 0.00889 to 0.00888, saving model to model_checkpoint.h5\n","Epoch 2063/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0069 - val_loss: 0.0089\n","\n","Epoch 02063: val_loss improved from 0.00888 to 0.00886, saving model to model_checkpoint.h5\n","Epoch 2064/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0088\n","\n","Epoch 02064: val_loss improved from 0.00886 to 0.00883, saving model to model_checkpoint.h5\n","Epoch 2065/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0088\n","\n","Epoch 02065: val_loss improved from 0.00883 to 0.00881, saving model to model_checkpoint.h5\n","Epoch 2066/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0088\n","\n","Epoch 02066: val_loss improved from 0.00881 to 0.00879, saving model to model_checkpoint.h5\n","Epoch 2067/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0088\n","\n","Epoch 02067: val_loss improved from 0.00879 to 0.00876, saving model to model_checkpoint.h5\n","Epoch 2068/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0066 - val_loss: 0.0087\n","\n","Epoch 02068: val_loss improved from 0.00876 to 0.00873, saving model to model_checkpoint.h5\n","Epoch 2069/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0087\n","\n","Epoch 02069: val_loss improved from 0.00873 to 0.00871, saving model to model_checkpoint.h5\n","Epoch 2070/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0087\n","\n","Epoch 02070: val_loss improved from 0.00871 to 0.00868, saving model to model_checkpoint.h5\n","Epoch 2071/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0087\n","\n","Epoch 02071: val_loss improved from 0.00868 to 0.00866, saving model to model_checkpoint.h5\n","Epoch 2072/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0086\n","\n","Epoch 02072: val_loss improved from 0.00866 to 0.00863, saving model to model_checkpoint.h5\n","Epoch 2073/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0086\n","\n","Epoch 02073: val_loss improved from 0.00863 to 0.00862, saving model to model_checkpoint.h5\n","Epoch 2074/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0061 - val_loss: 0.0086\n","\n","Epoch 02074: val_loss improved from 0.00862 to 0.00860, saving model to model_checkpoint.h5\n","Epoch 2075/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0086\n","\n","Epoch 02075: val_loss improved from 0.00860 to 0.00858, saving model to model_checkpoint.h5\n","Epoch 2076/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0086\n","\n","Epoch 02076: val_loss improved from 0.00858 to 0.00855, saving model to model_checkpoint.h5\n","Epoch 2077/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0085\n","\n","Epoch 02077: val_loss improved from 0.00855 to 0.00853, saving model to model_checkpoint.h5\n","Epoch 2078/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0085\n","\n","Epoch 02078: val_loss improved from 0.00853 to 0.00851, saving model to model_checkpoint.h5\n","Epoch 2079/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0085\n","\n","Epoch 02079: val_loss improved from 0.00851 to 0.00849, saving model to model_checkpoint.h5\n","Epoch 2080/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 0.0085\n","\n","Epoch 02080: val_loss improved from 0.00849 to 0.00847, saving model to model_checkpoint.h5\n","Epoch 2081/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.0084\n","\n","Epoch 02081: val_loss improved from 0.00847 to 0.00845, saving model to model_checkpoint.h5\n","Epoch 2082/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0069 - val_loss: 0.0084\n","\n","Epoch 02082: val_loss improved from 0.00845 to 0.00843, saving model to model_checkpoint.h5\n","Epoch 2083/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0084\n","\n","Epoch 02083: val_loss improved from 0.00843 to 0.00840, saving model to model_checkpoint.h5\n","Epoch 2084/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0084\n","\n","Epoch 02084: val_loss improved from 0.00840 to 0.00837, saving model to model_checkpoint.h5\n","Epoch 2085/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0083\n","\n","Epoch 02085: val_loss improved from 0.00837 to 0.00834, saving model to model_checkpoint.h5\n","Epoch 2086/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0083\n","\n","Epoch 02086: val_loss improved from 0.00834 to 0.00833, saving model to model_checkpoint.h5\n","Epoch 2087/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0083\n","\n","Epoch 02087: val_loss improved from 0.00833 to 0.00830, saving model to model_checkpoint.h5\n","Epoch 2088/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0074 - val_loss: 0.0083\n","\n","Epoch 02088: val_loss improved from 0.00830 to 0.00828, saving model to model_checkpoint.h5\n","Epoch 2089/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.0083\n","\n","Epoch 02089: val_loss improved from 0.00828 to 0.00826, saving model to model_checkpoint.h5\n","Epoch 2090/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0052 - val_loss: 0.0082\n","\n","Epoch 02090: val_loss improved from 0.00826 to 0.00824, saving model to model_checkpoint.h5\n","Epoch 2091/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0082\n","\n","Epoch 02091: val_loss improved from 0.00824 to 0.00822, saving model to model_checkpoint.h5\n","Epoch 2092/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0082\n","\n","Epoch 02092: val_loss improved from 0.00822 to 0.00819, saving model to model_checkpoint.h5\n","Epoch 2093/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0082\n","\n","Epoch 02093: val_loss improved from 0.00819 to 0.00817, saving model to model_checkpoint.h5\n","Epoch 2094/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0082\n","\n","Epoch 02094: val_loss improved from 0.00817 to 0.00815, saving model to model_checkpoint.h5\n","Epoch 2095/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0081\n","\n","Epoch 02095: val_loss improved from 0.00815 to 0.00815, saving model to model_checkpoint.h5\n","Epoch 2096/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0081\n","\n","Epoch 02096: val_loss improved from 0.00815 to 0.00812, saving model to model_checkpoint.h5\n","Epoch 2097/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0081\n","\n","Epoch 02097: val_loss improved from 0.00812 to 0.00810, saving model to model_checkpoint.h5\n","Epoch 2098/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0081\n","\n","Epoch 02098: val_loss improved from 0.00810 to 0.00808, saving model to model_checkpoint.h5\n","Epoch 2099/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0081\n","\n","Epoch 02099: val_loss improved from 0.00808 to 0.00807, saving model to model_checkpoint.h5\n","Epoch 2100/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0081\n","\n","Epoch 02100: val_loss improved from 0.00807 to 0.00805, saving model to model_checkpoint.h5\n","Epoch 2101/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0064 - val_loss: 0.0080\n","\n","Epoch 02101: val_loss improved from 0.00805 to 0.00803, saving model to model_checkpoint.h5\n","Epoch 2102/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0080\n","\n","Epoch 02102: val_loss improved from 0.00803 to 0.00802, saving model to model_checkpoint.h5\n","Epoch 2103/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0080\n","\n","Epoch 02103: val_loss improved from 0.00802 to 0.00800, saving model to model_checkpoint.h5\n","Epoch 2104/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0080\n","\n","Epoch 02104: val_loss improved from 0.00800 to 0.00799, saving model to model_checkpoint.h5\n","Epoch 2105/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0080\n","\n","Epoch 02105: val_loss improved from 0.00799 to 0.00797, saving model to model_checkpoint.h5\n","Epoch 2106/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0080\n","\n","Epoch 02106: val_loss improved from 0.00797 to 0.00795, saving model to model_checkpoint.h5\n","Epoch 2107/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0079\n","\n","Epoch 02107: val_loss improved from 0.00795 to 0.00793, saving model to model_checkpoint.h5\n","Epoch 2108/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0079\n","\n","Epoch 02108: val_loss improved from 0.00793 to 0.00791, saving model to model_checkpoint.h5\n","Epoch 2109/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0079\n","\n","Epoch 02109: val_loss improved from 0.00791 to 0.00789, saving model to model_checkpoint.h5\n","Epoch 2110/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0079\n","\n","Epoch 02110: val_loss improved from 0.00789 to 0.00787, saving model to model_checkpoint.h5\n","Epoch 2111/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0059 - val_loss: 0.0079\n","\n","Epoch 02111: val_loss improved from 0.00787 to 0.00785, saving model to model_checkpoint.h5\n","Epoch 2112/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0078\n","\n","Epoch 02112: val_loss improved from 0.00785 to 0.00783, saving model to model_checkpoint.h5\n","Epoch 2113/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0078\n","\n","Epoch 02113: val_loss improved from 0.00783 to 0.00781, saving model to model_checkpoint.h5\n","Epoch 2114/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0078\n","\n","Epoch 02114: val_loss improved from 0.00781 to 0.00779, saving model to model_checkpoint.h5\n","Epoch 2115/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0078\n","\n","Epoch 02115: val_loss improved from 0.00779 to 0.00777, saving model to model_checkpoint.h5\n","Epoch 2116/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0078\n","\n","Epoch 02116: val_loss improved from 0.00777 to 0.00775, saving model to model_checkpoint.h5\n","Epoch 2117/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0077\n","\n","Epoch 02117: val_loss improved from 0.00775 to 0.00774, saving model to model_checkpoint.h5\n","Epoch 2118/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0077\n","\n","Epoch 02118: val_loss improved from 0.00774 to 0.00772, saving model to model_checkpoint.h5\n","Epoch 2119/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0077\n","\n","Epoch 02119: val_loss improved from 0.00772 to 0.00770, saving model to model_checkpoint.h5\n","Epoch 2120/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0077\n","\n","Epoch 02120: val_loss improved from 0.00770 to 0.00768, saving model to model_checkpoint.h5\n","Epoch 2121/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0077\n","\n","Epoch 02121: val_loss improved from 0.00768 to 0.00766, saving model to model_checkpoint.h5\n","Epoch 2122/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0067 - val_loss: 0.0076\n","\n","Epoch 02122: val_loss improved from 0.00766 to 0.00764, saving model to model_checkpoint.h5\n","Epoch 2123/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0076\n","\n","Epoch 02123: val_loss improved from 0.00764 to 0.00762, saving model to model_checkpoint.h5\n","Epoch 2124/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0063 - val_loss: 0.0076\n","\n","Epoch 02124: val_loss improved from 0.00762 to 0.00760, saving model to model_checkpoint.h5\n","Epoch 2125/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0057 - val_loss: 0.0076\n","\n","Epoch 02125: val_loss improved from 0.00760 to 0.00759, saving model to model_checkpoint.h5\n","Epoch 2126/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0076\n","\n","Epoch 02126: val_loss improved from 0.00759 to 0.00756, saving model to model_checkpoint.h5\n","Epoch 2127/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0076\n","\n","Epoch 02127: val_loss improved from 0.00756 to 0.00755, saving model to model_checkpoint.h5\n","Epoch 2128/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.0075\n","\n","Epoch 02128: val_loss improved from 0.00755 to 0.00753, saving model to model_checkpoint.h5\n","Epoch 2129/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0075\n","\n","Epoch 02129: val_loss improved from 0.00753 to 0.00752, saving model to model_checkpoint.h5\n","Epoch 2130/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0075\n","\n","Epoch 02130: val_loss improved from 0.00752 to 0.00750, saving model to model_checkpoint.h5\n","Epoch 2131/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0075\n","\n","Epoch 02131: val_loss improved from 0.00750 to 0.00748, saving model to model_checkpoint.h5\n","Epoch 2132/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0052 - val_loss: 0.0075\n","\n","Epoch 02132: val_loss improved from 0.00748 to 0.00746, saving model to model_checkpoint.h5\n","Epoch 2133/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0074\n","\n","Epoch 02133: val_loss improved from 0.00746 to 0.00744, saving model to model_checkpoint.h5\n","Epoch 2134/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0074\n","\n","Epoch 02134: val_loss improved from 0.00744 to 0.00743, saving model to model_checkpoint.h5\n","Epoch 2135/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0074\n","\n","Epoch 02135: val_loss improved from 0.00743 to 0.00741, saving model to model_checkpoint.h5\n","Epoch 2136/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0074\n","\n","Epoch 02136: val_loss improved from 0.00741 to 0.00738, saving model to model_checkpoint.h5\n","Epoch 2137/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0061 - val_loss: 0.0074\n","\n","Epoch 02137: val_loss improved from 0.00738 to 0.00736, saving model to model_checkpoint.h5\n","Epoch 2138/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0073\n","\n","Epoch 02138: val_loss improved from 0.00736 to 0.00735, saving model to model_checkpoint.h5\n","Epoch 2139/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0060 - val_loss: 0.0073\n","\n","Epoch 02139: val_loss improved from 0.00735 to 0.00733, saving model to model_checkpoint.h5\n","Epoch 2140/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0073\n","\n","Epoch 02140: val_loss improved from 0.00733 to 0.00731, saving model to model_checkpoint.h5\n","Epoch 2141/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0073\n","\n","Epoch 02141: val_loss improved from 0.00731 to 0.00730, saving model to model_checkpoint.h5\n","Epoch 2142/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0073\n","\n","Epoch 02142: val_loss improved from 0.00730 to 0.00729, saving model to model_checkpoint.h5\n","Epoch 2143/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0073\n","\n","Epoch 02143: val_loss improved from 0.00729 to 0.00727, saving model to model_checkpoint.h5\n","Epoch 2144/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0073\n","\n","Epoch 02144: val_loss improved from 0.00727 to 0.00726, saving model to model_checkpoint.h5\n","Epoch 2145/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0072\n","\n","Epoch 02145: val_loss improved from 0.00726 to 0.00724, saving model to model_checkpoint.h5\n","Epoch 2146/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0072\n","\n","Epoch 02146: val_loss improved from 0.00724 to 0.00722, saving model to model_checkpoint.h5\n","Epoch 2147/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0072\n","\n","Epoch 02147: val_loss improved from 0.00722 to 0.00720, saving model to model_checkpoint.h5\n","Epoch 2148/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0072\n","\n","Epoch 02148: val_loss improved from 0.00720 to 0.00718, saving model to model_checkpoint.h5\n","Epoch 2149/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0053 - val_loss: 0.0072\n","\n","Epoch 02149: val_loss improved from 0.00718 to 0.00717, saving model to model_checkpoint.h5\n","Epoch 2150/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0071\n","\n","Epoch 02150: val_loss improved from 0.00717 to 0.00715, saving model to model_checkpoint.h5\n","Epoch 2151/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0071\n","\n","Epoch 02151: val_loss improved from 0.00715 to 0.00713, saving model to model_checkpoint.h5\n","Epoch 2152/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0071\n","\n","Epoch 02152: val_loss improved from 0.00713 to 0.00711, saving model to model_checkpoint.h5\n","Epoch 2153/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0071\n","\n","Epoch 02153: val_loss improved from 0.00711 to 0.00709, saving model to model_checkpoint.h5\n","Epoch 2154/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0062 - val_loss: 0.0071\n","\n","Epoch 02154: val_loss improved from 0.00709 to 0.00707, saving model to model_checkpoint.h5\n","Epoch 2155/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0071\n","\n","Epoch 02155: val_loss improved from 0.00707 to 0.00705, saving model to model_checkpoint.h5\n","Epoch 2156/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0070\n","\n","Epoch 02156: val_loss improved from 0.00705 to 0.00704, saving model to model_checkpoint.h5\n","Epoch 2157/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0065 - val_loss: 0.0070\n","\n","Epoch 02157: val_loss improved from 0.00704 to 0.00701, saving model to model_checkpoint.h5\n","Epoch 2158/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0063 - val_loss: 0.0070\n","\n","Epoch 02158: val_loss improved from 0.00701 to 0.00699, saving model to model_checkpoint.h5\n","Epoch 2159/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0070\n","\n","Epoch 02159: val_loss improved from 0.00699 to 0.00698, saving model to model_checkpoint.h5\n","Epoch 2160/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.0070\n","\n","Epoch 02160: val_loss improved from 0.00698 to 0.00696, saving model to model_checkpoint.h5\n","Epoch 2161/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0069\n","\n","Epoch 02161: val_loss improved from 0.00696 to 0.00694, saving model to model_checkpoint.h5\n","Epoch 2162/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0069\n","\n","Epoch 02162: val_loss improved from 0.00694 to 0.00693, saving model to model_checkpoint.h5\n","Epoch 2163/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0059 - val_loss: 0.0069\n","\n","Epoch 02163: val_loss improved from 0.00693 to 0.00691, saving model to model_checkpoint.h5\n","Epoch 2164/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0069\n","\n","Epoch 02164: val_loss improved from 0.00691 to 0.00690, saving model to model_checkpoint.h5\n","Epoch 2165/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0069\n","\n","Epoch 02165: val_loss improved from 0.00690 to 0.00689, saving model to model_checkpoint.h5\n","Epoch 2166/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0069\n","\n","Epoch 02166: val_loss improved from 0.00689 to 0.00687, saving model to model_checkpoint.h5\n","Epoch 2167/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0069\n","\n","Epoch 02167: val_loss improved from 0.00687 to 0.00686, saving model to model_checkpoint.h5\n","Epoch 2168/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0055 - val_loss: 0.0068\n","\n","Epoch 02168: val_loss improved from 0.00686 to 0.00684, saving model to model_checkpoint.h5\n","Epoch 2169/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0068\n","\n","Epoch 02169: val_loss improved from 0.00684 to 0.00683, saving model to model_checkpoint.h5\n","Epoch 2170/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0058 - val_loss: 0.0068\n","\n","Epoch 02170: val_loss improved from 0.00683 to 0.00682, saving model to model_checkpoint.h5\n","Epoch 2171/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0068\n","\n","Epoch 02171: val_loss improved from 0.00682 to 0.00681, saving model to model_checkpoint.h5\n","Epoch 2172/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0068\n","\n","Epoch 02172: val_loss improved from 0.00681 to 0.00679, saving model to model_checkpoint.h5\n","Epoch 2173/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0068\n","\n","Epoch 02173: val_loss improved from 0.00679 to 0.00679, saving model to model_checkpoint.h5\n","Epoch 2174/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0068\n","\n","Epoch 02174: val_loss improved from 0.00679 to 0.00677, saving model to model_checkpoint.h5\n","Epoch 2175/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0068\n","\n","Epoch 02175: val_loss improved from 0.00677 to 0.00676, saving model to model_checkpoint.h5\n","Epoch 2176/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0067\n","\n","Epoch 02176: val_loss improved from 0.00676 to 0.00674, saving model to model_checkpoint.h5\n","Epoch 2177/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0067\n","\n","Epoch 02177: val_loss improved from 0.00674 to 0.00673, saving model to model_checkpoint.h5\n","Epoch 2178/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0067\n","\n","Epoch 02178: val_loss improved from 0.00673 to 0.00672, saving model to model_checkpoint.h5\n","Epoch 2179/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0067\n","\n","Epoch 02179: val_loss improved from 0.00672 to 0.00670, saving model to model_checkpoint.h5\n","Epoch 2180/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0067\n","\n","Epoch 02180: val_loss improved from 0.00670 to 0.00669, saving model to model_checkpoint.h5\n","Epoch 2181/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0067\n","\n","Epoch 02181: val_loss improved from 0.00669 to 0.00668, saving model to model_checkpoint.h5\n","Epoch 2182/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.0067\n","\n","Epoch 02182: val_loss improved from 0.00668 to 0.00667, saving model to model_checkpoint.h5\n","Epoch 2183/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0067\n","\n","Epoch 02183: val_loss improved from 0.00667 to 0.00666, saving model to model_checkpoint.h5\n","Epoch 2184/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0066\n","\n","Epoch 02184: val_loss improved from 0.00666 to 0.00664, saving model to model_checkpoint.h5\n","Epoch 2185/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0066\n","\n","Epoch 02185: val_loss improved from 0.00664 to 0.00663, saving model to model_checkpoint.h5\n","Epoch 2186/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0056 - val_loss: 0.0066\n","\n","Epoch 02186: val_loss improved from 0.00663 to 0.00662, saving model to model_checkpoint.h5\n","Epoch 2187/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0066\n","\n","Epoch 02187: val_loss improved from 0.00662 to 0.00661, saving model to model_checkpoint.h5\n","Epoch 2188/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0066\n","\n","Epoch 02188: val_loss improved from 0.00661 to 0.00660, saving model to model_checkpoint.h5\n","Epoch 2189/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0066\n","\n","Epoch 02189: val_loss improved from 0.00660 to 0.00659, saving model to model_checkpoint.h5\n","Epoch 2190/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0066\n","\n","Epoch 02190: val_loss improved from 0.00659 to 0.00657, saving model to model_checkpoint.h5\n","Epoch 2191/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0066\n","\n","Epoch 02191: val_loss improved from 0.00657 to 0.00656, saving model to model_checkpoint.h5\n","Epoch 2192/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0060 - val_loss: 0.0065\n","\n","Epoch 02192: val_loss improved from 0.00656 to 0.00655, saving model to model_checkpoint.h5\n","Epoch 2193/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0065\n","\n","Epoch 02193: val_loss improved from 0.00655 to 0.00654, saving model to model_checkpoint.h5\n","Epoch 2194/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0065\n","\n","Epoch 02194: val_loss improved from 0.00654 to 0.00652, saving model to model_checkpoint.h5\n","Epoch 2195/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0065\n","\n","Epoch 02195: val_loss improved from 0.00652 to 0.00651, saving model to model_checkpoint.h5\n","Epoch 2196/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0065\n","\n","Epoch 02196: val_loss improved from 0.00651 to 0.00651, saving model to model_checkpoint.h5\n","Epoch 2197/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0062 - val_loss: 0.0065\n","\n","Epoch 02197: val_loss improved from 0.00651 to 0.00649, saving model to model_checkpoint.h5\n","Epoch 2198/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0065\n","\n","Epoch 02198: val_loss improved from 0.00649 to 0.00648, saving model to model_checkpoint.h5\n","Epoch 2199/50000\n","9/9 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 0.0065\n","\n","Epoch 02199: val_loss improved from 0.00648 to 0.00646, saving model to model_checkpoint.h5\n","Epoch 2200/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0064\n","\n","Epoch 02200: val_loss improved from 0.00646 to 0.00645, saving model to model_checkpoint.h5\n","Epoch 2201/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0064\n","\n","Epoch 02201: val_loss improved from 0.00645 to 0.00644, saving model to model_checkpoint.h5\n","Epoch 2202/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0064\n","\n","Epoch 02202: val_loss improved from 0.00644 to 0.00642, saving model to model_checkpoint.h5\n","Epoch 2203/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0064\n","\n","Epoch 02203: val_loss improved from 0.00642 to 0.00641, saving model to model_checkpoint.h5\n","Epoch 2204/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0064\n","\n","Epoch 02204: val_loss improved from 0.00641 to 0.00640, saving model to model_checkpoint.h5\n","Epoch 2205/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0064\n","\n","Epoch 02205: val_loss improved from 0.00640 to 0.00639, saving model to model_checkpoint.h5\n","Epoch 2206/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0064\n","\n","Epoch 02206: val_loss improved from 0.00639 to 0.00637, saving model to model_checkpoint.h5\n","Epoch 2207/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0054 - val_loss: 0.0064\n","\n","Epoch 02207: val_loss improved from 0.00637 to 0.00636, saving model to model_checkpoint.h5\n","Epoch 2208/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0063\n","\n","Epoch 02208: val_loss improved from 0.00636 to 0.00634, saving model to model_checkpoint.h5\n","Epoch 2209/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0063\n","\n","Epoch 02209: val_loss improved from 0.00634 to 0.00633, saving model to model_checkpoint.h5\n","Epoch 2210/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0063\n","\n","Epoch 02210: val_loss improved from 0.00633 to 0.00631, saving model to model_checkpoint.h5\n","Epoch 2211/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0055 - val_loss: 0.0063\n","\n","Epoch 02211: val_loss improved from 0.00631 to 0.00629, saving model to model_checkpoint.h5\n","Epoch 2212/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0063\n","\n","Epoch 02212: val_loss improved from 0.00629 to 0.00628, saving model to model_checkpoint.h5\n","Epoch 2213/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0063\n","\n","Epoch 02213: val_loss improved from 0.00628 to 0.00628, saving model to model_checkpoint.h5\n","Epoch 2214/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0063\n","\n","Epoch 02214: val_loss improved from 0.00628 to 0.00627, saving model to model_checkpoint.h5\n","Epoch 2215/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0063\n","\n","Epoch 02215: val_loss improved from 0.00627 to 0.00626, saving model to model_checkpoint.h5\n","Epoch 2216/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0062\n","\n","Epoch 02216: val_loss improved from 0.00626 to 0.00625, saving model to model_checkpoint.h5\n","Epoch 2217/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0062\n","\n","Epoch 02217: val_loss improved from 0.00625 to 0.00624, saving model to model_checkpoint.h5\n","Epoch 2218/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0057 - val_loss: 0.0062\n","\n","Epoch 02218: val_loss improved from 0.00624 to 0.00622, saving model to model_checkpoint.h5\n","Epoch 2219/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0062\n","\n","Epoch 02219: val_loss improved from 0.00622 to 0.00622, saving model to model_checkpoint.h5\n","Epoch 2220/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0062\n","\n","Epoch 02220: val_loss improved from 0.00622 to 0.00621, saving model to model_checkpoint.h5\n","Epoch 2221/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0062\n","\n","Epoch 02221: val_loss improved from 0.00621 to 0.00620, saving model to model_checkpoint.h5\n","Epoch 2222/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0062\n","\n","Epoch 02222: val_loss improved from 0.00620 to 0.00619, saving model to model_checkpoint.h5\n","Epoch 2223/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0062\n","\n","Epoch 02223: val_loss improved from 0.00619 to 0.00617, saving model to model_checkpoint.h5\n","Epoch 2224/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.0062\n","\n","Epoch 02224: val_loss improved from 0.00617 to 0.00617, saving model to model_checkpoint.h5\n","Epoch 2225/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0062\n","\n","Epoch 02225: val_loss improved from 0.00617 to 0.00616, saving model to model_checkpoint.h5\n","Epoch 2226/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0061\n","\n","Epoch 02226: val_loss improved from 0.00616 to 0.00615, saving model to model_checkpoint.h5\n","Epoch 2227/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0061\n","\n","Epoch 02227: val_loss improved from 0.00615 to 0.00614, saving model to model_checkpoint.h5\n","Epoch 2228/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0057 - val_loss: 0.0061\n","\n","Epoch 02228: val_loss improved from 0.00614 to 0.00613, saving model to model_checkpoint.h5\n","Epoch 2229/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0061\n","\n","Epoch 02229: val_loss improved from 0.00613 to 0.00611, saving model to model_checkpoint.h5\n","Epoch 2230/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0061\n","\n","Epoch 02230: val_loss improved from 0.00611 to 0.00609, saving model to model_checkpoint.h5\n","Epoch 2231/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0059 - val_loss: 0.0061\n","\n","Epoch 02231: val_loss improved from 0.00609 to 0.00608, saving model to model_checkpoint.h5\n","Epoch 2232/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0061\n","\n","Epoch 02232: val_loss improved from 0.00608 to 0.00607, saving model to model_checkpoint.h5\n","Epoch 2233/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0061\n","\n","Epoch 02233: val_loss improved from 0.00607 to 0.00606, saving model to model_checkpoint.h5\n","Epoch 2234/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0061\n","\n","Epoch 02234: val_loss improved from 0.00606 to 0.00606, saving model to model_checkpoint.h5\n","Epoch 2235/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0061\n","\n","Epoch 02235: val_loss improved from 0.00606 to 0.00605, saving model to model_checkpoint.h5\n","Epoch 2236/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0060\n","\n","Epoch 02236: val_loss improved from 0.00605 to 0.00604, saving model to model_checkpoint.h5\n","Epoch 2237/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0060\n","\n","Epoch 02237: val_loss improved from 0.00604 to 0.00603, saving model to model_checkpoint.h5\n","Epoch 2238/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0060\n","\n","Epoch 02238: val_loss improved from 0.00603 to 0.00602, saving model to model_checkpoint.h5\n","Epoch 2239/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.0060\n","\n","Epoch 02239: val_loss improved from 0.00602 to 0.00601, saving model to model_checkpoint.h5\n","Epoch 2240/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0060\n","\n","Epoch 02240: val_loss improved from 0.00601 to 0.00600, saving model to model_checkpoint.h5\n","Epoch 2241/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0060\n","\n","Epoch 02241: val_loss improved from 0.00600 to 0.00599, saving model to model_checkpoint.h5\n","Epoch 2242/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0060\n","\n","Epoch 02242: val_loss improved from 0.00599 to 0.00598, saving model to model_checkpoint.h5\n","Epoch 2243/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0060\n","\n","Epoch 02243: val_loss improved from 0.00598 to 0.00597, saving model to model_checkpoint.h5\n","Epoch 2244/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0056 - val_loss: 0.0060\n","\n","Epoch 02244: val_loss improved from 0.00597 to 0.00596, saving model to model_checkpoint.h5\n","Epoch 2245/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0060\n","\n","Epoch 02245: val_loss improved from 0.00596 to 0.00595, saving model to model_checkpoint.h5\n","Epoch 2246/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0054 - val_loss: 0.0059\n","\n","Epoch 02246: val_loss improved from 0.00595 to 0.00595, saving model to model_checkpoint.h5\n","Epoch 2247/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0059\n","\n","Epoch 02247: val_loss improved from 0.00595 to 0.00594, saving model to model_checkpoint.h5\n","Epoch 2248/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0059\n","\n","Epoch 02248: val_loss improved from 0.00594 to 0.00593, saving model to model_checkpoint.h5\n","Epoch 2249/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0059\n","\n","Epoch 02249: val_loss improved from 0.00593 to 0.00592, saving model to model_checkpoint.h5\n","Epoch 2250/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0059\n","\n","Epoch 02250: val_loss improved from 0.00592 to 0.00591, saving model to model_checkpoint.h5\n","Epoch 2251/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0051 - val_loss: 0.0059\n","\n","Epoch 02251: val_loss improved from 0.00591 to 0.00589, saving model to model_checkpoint.h5\n","Epoch 2252/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0050 - val_loss: 0.0059\n","\n","Epoch 02252: val_loss improved from 0.00589 to 0.00588, saving model to model_checkpoint.h5\n","Epoch 2253/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0059\n","\n","Epoch 02253: val_loss improved from 0.00588 to 0.00587, saving model to model_checkpoint.h5\n","Epoch 2254/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0059\n","\n","Epoch 02254: val_loss improved from 0.00587 to 0.00587, saving model to model_checkpoint.h5\n","Epoch 2255/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0059\n","\n","Epoch 02255: val_loss improved from 0.00587 to 0.00586, saving model to model_checkpoint.h5\n","Epoch 2256/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0058\n","\n","Epoch 02256: val_loss improved from 0.00586 to 0.00585, saving model to model_checkpoint.h5\n","Epoch 2257/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0058\n","\n","Epoch 02257: val_loss improved from 0.00585 to 0.00584, saving model to model_checkpoint.h5\n","Epoch 2258/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0058\n","\n","Epoch 02258: val_loss improved from 0.00584 to 0.00583, saving model to model_checkpoint.h5\n","Epoch 2259/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0058\n","\n","Epoch 02259: val_loss improved from 0.00583 to 0.00582, saving model to model_checkpoint.h5\n","Epoch 2260/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0058\n","\n","Epoch 02260: val_loss improved from 0.00582 to 0.00581, saving model to model_checkpoint.h5\n","Epoch 2261/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0058\n","\n","Epoch 02261: val_loss improved from 0.00581 to 0.00580, saving model to model_checkpoint.h5\n","Epoch 2262/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0057 - val_loss: 0.0058\n","\n","Epoch 02262: val_loss improved from 0.00580 to 0.00579, saving model to model_checkpoint.h5\n","Epoch 2263/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0058\n","\n","Epoch 02263: val_loss improved from 0.00579 to 0.00578, saving model to model_checkpoint.h5\n","Epoch 2264/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0058\n","\n","Epoch 02264: val_loss improved from 0.00578 to 0.00578, saving model to model_checkpoint.h5\n","Epoch 2265/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0058\n","\n","Epoch 02265: val_loss improved from 0.00578 to 0.00577, saving model to model_checkpoint.h5\n","Epoch 2266/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0058\n","\n","Epoch 02266: val_loss improved from 0.00577 to 0.00576, saving model to model_checkpoint.h5\n","Epoch 2267/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0057\n","\n","Epoch 02267: val_loss improved from 0.00576 to 0.00575, saving model to model_checkpoint.h5\n","Epoch 2268/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0057\n","\n","Epoch 02268: val_loss improved from 0.00575 to 0.00574, saving model to model_checkpoint.h5\n","Epoch 2269/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0057\n","\n","Epoch 02269: val_loss improved from 0.00574 to 0.00573, saving model to model_checkpoint.h5\n","Epoch 2270/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0057\n","\n","Epoch 02270: val_loss improved from 0.00573 to 0.00572, saving model to model_checkpoint.h5\n","Epoch 2271/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0044 - val_loss: 0.0057\n","\n","Epoch 02271: val_loss improved from 0.00572 to 0.00572, saving model to model_checkpoint.h5\n","Epoch 2272/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0057\n","\n","Epoch 02272: val_loss improved from 0.00572 to 0.00571, saving model to model_checkpoint.h5\n","Epoch 2273/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0057\n","\n","Epoch 02273: val_loss improved from 0.00571 to 0.00570, saving model to model_checkpoint.h5\n","Epoch 2274/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0057\n","\n","Epoch 02274: val_loss improved from 0.00570 to 0.00569, saving model to model_checkpoint.h5\n","Epoch 2275/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0057\n","\n","Epoch 02275: val_loss improved from 0.00569 to 0.00569, saving model to model_checkpoint.h5\n","Epoch 2276/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0057\n","\n","Epoch 02276: val_loss improved from 0.00569 to 0.00568, saving model to model_checkpoint.h5\n","Epoch 2277/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0057\n","\n","Epoch 02277: val_loss improved from 0.00568 to 0.00567, saving model to model_checkpoint.h5\n","Epoch 2278/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0057\n","\n","Epoch 02278: val_loss improved from 0.00567 to 0.00566, saving model to model_checkpoint.h5\n","Epoch 2279/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0057\n","\n","Epoch 02279: val_loss improved from 0.00566 to 0.00565, saving model to model_checkpoint.h5\n","Epoch 2280/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0056\n","\n","Epoch 02280: val_loss improved from 0.00565 to 0.00565, saving model to model_checkpoint.h5\n","Epoch 2281/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0056\n","\n","Epoch 02281: val_loss improved from 0.00565 to 0.00564, saving model to model_checkpoint.h5\n","Epoch 2282/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0056\n","\n","Epoch 02282: val_loss improved from 0.00564 to 0.00563, saving model to model_checkpoint.h5\n","Epoch 2283/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0056\n","\n","Epoch 02283: val_loss improved from 0.00563 to 0.00562, saving model to model_checkpoint.h5\n","Epoch 2284/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0056\n","\n","Epoch 02284: val_loss improved from 0.00562 to 0.00561, saving model to model_checkpoint.h5\n","Epoch 2285/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0056\n","\n","Epoch 02285: val_loss improved from 0.00561 to 0.00561, saving model to model_checkpoint.h5\n","Epoch 2286/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0056\n","\n","Epoch 02286: val_loss improved from 0.00561 to 0.00560, saving model to model_checkpoint.h5\n","Epoch 2287/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.0056\n","\n","Epoch 02287: val_loss improved from 0.00560 to 0.00559, saving model to model_checkpoint.h5\n","Epoch 2288/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0056\n","\n","Epoch 02288: val_loss improved from 0.00559 to 0.00559, saving model to model_checkpoint.h5\n","Epoch 2289/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0056\n","\n","Epoch 02289: val_loss improved from 0.00559 to 0.00558, saving model to model_checkpoint.h5\n","Epoch 2290/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0051 - val_loss: 0.0056\n","\n","Epoch 02290: val_loss improved from 0.00558 to 0.00557, saving model to model_checkpoint.h5\n","Epoch 2291/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0056\n","\n","Epoch 02291: val_loss improved from 0.00557 to 0.00556, saving model to model_checkpoint.h5\n","Epoch 2292/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0056\n","\n","Epoch 02292: val_loss improved from 0.00556 to 0.00556, saving model to model_checkpoint.h5\n","Epoch 2293/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0053 - val_loss: 0.0055\n","\n","Epoch 02293: val_loss improved from 0.00556 to 0.00555, saving model to model_checkpoint.h5\n","Epoch 2294/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0055\n","\n","Epoch 02294: val_loss improved from 0.00555 to 0.00554, saving model to model_checkpoint.h5\n","Epoch 2295/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0055\n","\n","Epoch 02295: val_loss improved from 0.00554 to 0.00553, saving model to model_checkpoint.h5\n","Epoch 2296/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0055\n","\n","Epoch 02296: val_loss improved from 0.00553 to 0.00552, saving model to model_checkpoint.h5\n","Epoch 2297/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0055\n","\n","Epoch 02297: val_loss improved from 0.00552 to 0.00551, saving model to model_checkpoint.h5\n","Epoch 2298/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0055\n","\n","Epoch 02298: val_loss improved from 0.00551 to 0.00550, saving model to model_checkpoint.h5\n","Epoch 2299/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0055\n","\n","Epoch 02299: val_loss improved from 0.00550 to 0.00550, saving model to model_checkpoint.h5\n","Epoch 2300/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0055\n","\n","Epoch 02300: val_loss improved from 0.00550 to 0.00549, saving model to model_checkpoint.h5\n","Epoch 2301/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0055\n","\n","Epoch 02301: val_loss improved from 0.00549 to 0.00549, saving model to model_checkpoint.h5\n","Epoch 2302/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0055\n","\n","Epoch 02302: val_loss improved from 0.00549 to 0.00548, saving model to model_checkpoint.h5\n","Epoch 2303/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0046 - val_loss: 0.0055\n","\n","Epoch 02303: val_loss improved from 0.00548 to 0.00548, saving model to model_checkpoint.h5\n","Epoch 2304/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0051 - val_loss: 0.0055\n","\n","Epoch 02304: val_loss improved from 0.00548 to 0.00547, saving model to model_checkpoint.h5\n","Epoch 2305/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0055\n","\n","Epoch 02305: val_loss improved from 0.00547 to 0.00546, saving model to model_checkpoint.h5\n","Epoch 2306/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0055\n","\n","Epoch 02306: val_loss improved from 0.00546 to 0.00546, saving model to model_checkpoint.h5\n","Epoch 2307/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0054\n","\n","Epoch 02307: val_loss improved from 0.00546 to 0.00545, saving model to model_checkpoint.h5\n","Epoch 2308/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0054\n","\n","Epoch 02308: val_loss improved from 0.00545 to 0.00544, saving model to model_checkpoint.h5\n","Epoch 2309/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0054\n","\n","Epoch 02309: val_loss improved from 0.00544 to 0.00544, saving model to model_checkpoint.h5\n","Epoch 2310/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0054\n","\n","Epoch 02310: val_loss improved from 0.00544 to 0.00543, saving model to model_checkpoint.h5\n","Epoch 2311/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0054\n","\n","Epoch 02311: val_loss improved from 0.00543 to 0.00542, saving model to model_checkpoint.h5\n","Epoch 2312/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0054\n","\n","Epoch 02312: val_loss improved from 0.00542 to 0.00541, saving model to model_checkpoint.h5\n","Epoch 2313/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0054\n","\n","Epoch 02313: val_loss improved from 0.00541 to 0.00541, saving model to model_checkpoint.h5\n","Epoch 2314/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0046 - val_loss: 0.0054\n","\n","Epoch 02314: val_loss improved from 0.00541 to 0.00540, saving model to model_checkpoint.h5\n","Epoch 2315/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0054\n","\n","Epoch 02315: val_loss improved from 0.00540 to 0.00540, saving model to model_checkpoint.h5\n","Epoch 2316/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0054\n","\n","Epoch 02316: val_loss improved from 0.00540 to 0.00539, saving model to model_checkpoint.h5\n","Epoch 2317/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0054\n","\n","Epoch 02317: val_loss improved from 0.00539 to 0.00539, saving model to model_checkpoint.h5\n","Epoch 2318/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0054\n","\n","Epoch 02318: val_loss improved from 0.00539 to 0.00538, saving model to model_checkpoint.h5\n","Epoch 2319/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0054\n","\n","Epoch 02319: val_loss improved from 0.00538 to 0.00537, saving model to model_checkpoint.h5\n","Epoch 2320/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0052 - val_loss: 0.0054\n","\n","Epoch 02320: val_loss improved from 0.00537 to 0.00537, saving model to model_checkpoint.h5\n","Epoch 2321/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0054\n","\n","Epoch 02321: val_loss improved from 0.00537 to 0.00536, saving model to model_checkpoint.h5\n","Epoch 2322/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0054\n","\n","Epoch 02322: val_loss improved from 0.00536 to 0.00535, saving model to model_checkpoint.h5\n","Epoch 2323/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0050 - val_loss: 0.0053\n","\n","Epoch 02323: val_loss improved from 0.00535 to 0.00534, saving model to model_checkpoint.h5\n","Epoch 2324/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0053\n","\n","Epoch 02324: val_loss improved from 0.00534 to 0.00534, saving model to model_checkpoint.h5\n","Epoch 2325/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0053\n","\n","Epoch 02325: val_loss improved from 0.00534 to 0.00533, saving model to model_checkpoint.h5\n","Epoch 2326/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0053\n","\n","Epoch 02326: val_loss improved from 0.00533 to 0.00533, saving model to model_checkpoint.h5\n","Epoch 2327/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0053\n","\n","Epoch 02327: val_loss improved from 0.00533 to 0.00532, saving model to model_checkpoint.h5\n","Epoch 2328/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0053\n","\n","Epoch 02328: val_loss improved from 0.00532 to 0.00532, saving model to model_checkpoint.h5\n","Epoch 2329/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0053\n","\n","Epoch 02329: val_loss improved from 0.00532 to 0.00531, saving model to model_checkpoint.h5\n","Epoch 2330/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0053\n","\n","Epoch 02330: val_loss improved from 0.00531 to 0.00530, saving model to model_checkpoint.h5\n","Epoch 2331/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0053\n","\n","Epoch 02331: val_loss improved from 0.00530 to 0.00530, saving model to model_checkpoint.h5\n","Epoch 2332/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0053\n","\n","Epoch 02332: val_loss improved from 0.00530 to 0.00530, saving model to model_checkpoint.h5\n","Epoch 2333/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0053\n","\n","Epoch 02333: val_loss improved from 0.00530 to 0.00529, saving model to model_checkpoint.h5\n","Epoch 2334/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.0053\n","\n","Epoch 02334: val_loss improved from 0.00529 to 0.00529, saving model to model_checkpoint.h5\n","Epoch 2335/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0053\n","\n","Epoch 02335: val_loss improved from 0.00529 to 0.00528, saving model to model_checkpoint.h5\n","Epoch 2336/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0053\n","\n","Epoch 02336: val_loss improved from 0.00528 to 0.00528, saving model to model_checkpoint.h5\n","Epoch 2337/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0053\n","\n","Epoch 02337: val_loss improved from 0.00528 to 0.00527, saving model to model_checkpoint.h5\n","Epoch 2338/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0053\n","\n","Epoch 02338: val_loss improved from 0.00527 to 0.00526, saving model to model_checkpoint.h5\n","Epoch 2339/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0053\n","\n","Epoch 02339: val_loss improved from 0.00526 to 0.00526, saving model to model_checkpoint.h5\n","Epoch 2340/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0049 - val_loss: 0.0053\n","\n","Epoch 02340: val_loss improved from 0.00526 to 0.00525, saving model to model_checkpoint.h5\n","Epoch 2341/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.0052\n","\n","Epoch 02341: val_loss improved from 0.00525 to 0.00525, saving model to model_checkpoint.h5\n","Epoch 2342/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0052\n","\n","Epoch 02342: val_loss improved from 0.00525 to 0.00524, saving model to model_checkpoint.h5\n","Epoch 2343/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0052\n","\n","Epoch 02343: val_loss improved from 0.00524 to 0.00524, saving model to model_checkpoint.h5\n","Epoch 2344/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0052\n","\n","Epoch 02344: val_loss improved from 0.00524 to 0.00523, saving model to model_checkpoint.h5\n","Epoch 2345/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0052\n","\n","Epoch 02345: val_loss improved from 0.00523 to 0.00523, saving model to model_checkpoint.h5\n","Epoch 2346/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0052\n","\n","Epoch 02346: val_loss improved from 0.00523 to 0.00522, saving model to model_checkpoint.h5\n","Epoch 2347/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0052\n","\n","Epoch 02347: val_loss improved from 0.00522 to 0.00522, saving model to model_checkpoint.h5\n","Epoch 2348/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0052\n","\n","Epoch 02348: val_loss improved from 0.00522 to 0.00521, saving model to model_checkpoint.h5\n","Epoch 2349/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0052\n","\n","Epoch 02349: val_loss improved from 0.00521 to 0.00521, saving model to model_checkpoint.h5\n","Epoch 2350/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0052\n","\n","Epoch 02350: val_loss improved from 0.00521 to 0.00520, saving model to model_checkpoint.h5\n","Epoch 2351/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0052\n","\n","Epoch 02351: val_loss improved from 0.00520 to 0.00519, saving model to model_checkpoint.h5\n","Epoch 2352/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0043 - val_loss: 0.0052\n","\n","Epoch 02352: val_loss improved from 0.00519 to 0.00519, saving model to model_checkpoint.h5\n","Epoch 2353/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0052\n","\n","Epoch 02353: val_loss improved from 0.00519 to 0.00518, saving model to model_checkpoint.h5\n","Epoch 2354/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0052\n","\n","Epoch 02354: val_loss improved from 0.00518 to 0.00518, saving model to model_checkpoint.h5\n","Epoch 2355/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0052\n","\n","Epoch 02355: val_loss improved from 0.00518 to 0.00517, saving model to model_checkpoint.h5\n","Epoch 2356/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0052\n","\n","Epoch 02356: val_loss improved from 0.00517 to 0.00517, saving model to model_checkpoint.h5\n","Epoch 2357/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0052\n","\n","Epoch 02357: val_loss improved from 0.00517 to 0.00517, saving model to model_checkpoint.h5\n","Epoch 2358/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.0052\n","\n","Epoch 02358: val_loss improved from 0.00517 to 0.00516, saving model to model_checkpoint.h5\n","Epoch 2359/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0052\n","\n","Epoch 02359: val_loss improved from 0.00516 to 0.00516, saving model to model_checkpoint.h5\n","Epoch 2360/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0052\n","\n","Epoch 02360: val_loss improved from 0.00516 to 0.00515, saving model to model_checkpoint.h5\n","Epoch 2361/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0051\n","\n","Epoch 02361: val_loss improved from 0.00515 to 0.00515, saving model to model_checkpoint.h5\n","Epoch 2362/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0051\n","\n","Epoch 02362: val_loss improved from 0.00515 to 0.00515, saving model to model_checkpoint.h5\n","Epoch 2363/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0051\n","\n","Epoch 02363: val_loss improved from 0.00515 to 0.00514, saving model to model_checkpoint.h5\n","Epoch 2364/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0051\n","\n","Epoch 02364: val_loss improved from 0.00514 to 0.00514, saving model to model_checkpoint.h5\n","Epoch 2365/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 02365: val_loss improved from 0.00514 to 0.00513, saving model to model_checkpoint.h5\n","Epoch 2366/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0051\n","\n","Epoch 02366: val_loss improved from 0.00513 to 0.00513, saving model to model_checkpoint.h5\n","Epoch 2367/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 02367: val_loss improved from 0.00513 to 0.00513, saving model to model_checkpoint.h5\n","Epoch 2368/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0051\n","\n","Epoch 02368: val_loss improved from 0.00513 to 0.00512, saving model to model_checkpoint.h5\n","Epoch 2369/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0046 - val_loss: 0.0051\n","\n","Epoch 02369: val_loss improved from 0.00512 to 0.00512, saving model to model_checkpoint.h5\n","Epoch 2370/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0051\n","\n","Epoch 02370: val_loss improved from 0.00512 to 0.00512, saving model to model_checkpoint.h5\n","Epoch 2371/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0051\n","\n","Epoch 02371: val_loss improved from 0.00512 to 0.00511, saving model to model_checkpoint.h5\n","Epoch 2372/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 02372: val_loss improved from 0.00511 to 0.00511, saving model to model_checkpoint.h5\n","Epoch 2373/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0051\n","\n","Epoch 02373: val_loss improved from 0.00511 to 0.00510, saving model to model_checkpoint.h5\n","Epoch 2374/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0051\n","\n","Epoch 02374: val_loss improved from 0.00510 to 0.00510, saving model to model_checkpoint.h5\n","Epoch 2375/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0051\n","\n","Epoch 02375: val_loss improved from 0.00510 to 0.00510, saving model to model_checkpoint.h5\n","Epoch 2376/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 02376: val_loss improved from 0.00510 to 0.00509, saving model to model_checkpoint.h5\n","Epoch 2377/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 02377: val_loss improved from 0.00509 to 0.00509, saving model to model_checkpoint.h5\n","Epoch 2378/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0051\n","\n","Epoch 02378: val_loss improved from 0.00509 to 0.00509, saving model to model_checkpoint.h5\n","Epoch 2379/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0051\n","\n","Epoch 02379: val_loss improved from 0.00509 to 0.00508, saving model to model_checkpoint.h5\n","Epoch 2380/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0051\n","\n","Epoch 02380: val_loss improved from 0.00508 to 0.00508, saving model to model_checkpoint.h5\n","Epoch 2381/50000\n","9/9 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 02381: val_loss improved from 0.00508 to 0.00508, saving model to model_checkpoint.h5\n","Epoch 2382/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0051\n","\n","Epoch 02382: val_loss improved from 0.00508 to 0.00507, saving model to model_checkpoint.h5\n","Epoch 2383/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0051\n","\n","Epoch 02383: val_loss improved from 0.00507 to 0.00507, saving model to model_checkpoint.h5\n","Epoch 2384/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0051\n","\n","Epoch 02384: val_loss improved from 0.00507 to 0.00507, saving model to model_checkpoint.h5\n","Epoch 2385/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0051\n","\n","Epoch 02385: val_loss improved from 0.00507 to 0.00506, saving model to model_checkpoint.h5\n","Epoch 2386/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.0051\n","\n","Epoch 02386: val_loss improved from 0.00506 to 0.00506, saving model to model_checkpoint.h5\n","Epoch 2387/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0051\n","\n","Epoch 02387: val_loss improved from 0.00506 to 0.00505, saving model to model_checkpoint.h5\n","Epoch 2388/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0051\n","\n","Epoch 02388: val_loss improved from 0.00505 to 0.00505, saving model to model_checkpoint.h5\n","Epoch 2389/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0050\n","\n","Epoch 02389: val_loss improved from 0.00505 to 0.00505, saving model to model_checkpoint.h5\n","Epoch 2390/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0050\n","\n","Epoch 02390: val_loss improved from 0.00505 to 0.00504, saving model to model_checkpoint.h5\n","Epoch 2391/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0050\n","\n","Epoch 02391: val_loss improved from 0.00504 to 0.00504, saving model to model_checkpoint.h5\n","Epoch 2392/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0049 - val_loss: 0.0050\n","\n","Epoch 02392: val_loss improved from 0.00504 to 0.00504, saving model to model_checkpoint.h5\n","Epoch 2393/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0050\n","\n","Epoch 02393: val_loss improved from 0.00504 to 0.00503, saving model to model_checkpoint.h5\n","Epoch 2394/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0050\n","\n","Epoch 02394: val_loss improved from 0.00503 to 0.00503, saving model to model_checkpoint.h5\n","Epoch 2395/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0050\n","\n","Epoch 02395: val_loss improved from 0.00503 to 0.00503, saving model to model_checkpoint.h5\n","Epoch 2396/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0043 - val_loss: 0.0050\n","\n","Epoch 02396: val_loss improved from 0.00503 to 0.00502, saving model to model_checkpoint.h5\n","Epoch 2397/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0050\n","\n","Epoch 02397: val_loss improved from 0.00502 to 0.00502, saving model to model_checkpoint.h5\n","Epoch 2398/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0050\n","\n","Epoch 02398: val_loss improved from 0.00502 to 0.00502, saving model to model_checkpoint.h5\n","Epoch 2399/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0050\n","\n","Epoch 02399: val_loss improved from 0.00502 to 0.00502, saving model to model_checkpoint.h5\n","Epoch 2400/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0050\n","\n","Epoch 02400: val_loss improved from 0.00502 to 0.00501, saving model to model_checkpoint.h5\n","Epoch 2401/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0050\n","\n","Epoch 02401: val_loss improved from 0.00501 to 0.00501, saving model to model_checkpoint.h5\n","Epoch 2402/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0050\n","\n","Epoch 02402: val_loss improved from 0.00501 to 0.00501, saving model to model_checkpoint.h5\n","Epoch 2403/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0050\n","\n","Epoch 02403: val_loss improved from 0.00501 to 0.00500, saving model to model_checkpoint.h5\n","Epoch 2404/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0050\n","\n","Epoch 02404: val_loss improved from 0.00500 to 0.00500, saving model to model_checkpoint.h5\n","Epoch 2405/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0050\n","\n","Epoch 02405: val_loss improved from 0.00500 to 0.00500, saving model to model_checkpoint.h5\n","Epoch 2406/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0050\n","\n","Epoch 02406: val_loss improved from 0.00500 to 0.00499, saving model to model_checkpoint.h5\n","Epoch 2407/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0050\n","\n","Epoch 02407: val_loss improved from 0.00499 to 0.00499, saving model to model_checkpoint.h5\n","Epoch 2408/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0050\n","\n","Epoch 02408: val_loss improved from 0.00499 to 0.00499, saving model to model_checkpoint.h5\n","Epoch 2409/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0048 - val_loss: 0.0050\n","\n","Epoch 02409: val_loss improved from 0.00499 to 0.00499, saving model to model_checkpoint.h5\n","Epoch 2410/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0050\n","\n","Epoch 02410: val_loss improved from 0.00499 to 0.00498, saving model to model_checkpoint.h5\n","Epoch 2411/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0050\n","\n","Epoch 02411: val_loss improved from 0.00498 to 0.00498, saving model to model_checkpoint.h5\n","Epoch 2412/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n","\n","Epoch 02412: val_loss improved from 0.00498 to 0.00498, saving model to model_checkpoint.h5\n","Epoch 2413/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0050\n","\n","Epoch 02413: val_loss improved from 0.00498 to 0.00497, saving model to model_checkpoint.h5\n","Epoch 2414/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0050\n","\n","Epoch 02414: val_loss improved from 0.00497 to 0.00497, saving model to model_checkpoint.h5\n","Epoch 2415/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0048 - val_loss: 0.0050\n","\n","Epoch 02415: val_loss improved from 0.00497 to 0.00497, saving model to model_checkpoint.h5\n","Epoch 2416/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0050\n","\n","Epoch 02416: val_loss improved from 0.00497 to 0.00497, saving model to model_checkpoint.h5\n","Epoch 2417/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0050\n","\n","Epoch 02417: val_loss improved from 0.00497 to 0.00496, saving model to model_checkpoint.h5\n","Epoch 2418/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0050\n","\n","Epoch 02418: val_loss improved from 0.00496 to 0.00496, saving model to model_checkpoint.h5\n","Epoch 2419/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0050\n","\n","Epoch 02419: val_loss improved from 0.00496 to 0.00496, saving model to model_checkpoint.h5\n","Epoch 2420/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0050\n","\n","Epoch 02420: val_loss improved from 0.00496 to 0.00496, saving model to model_checkpoint.h5\n","Epoch 2421/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0050\n","\n","Epoch 02421: val_loss improved from 0.00496 to 0.00495, saving model to model_checkpoint.h5\n","Epoch 2422/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0047 - val_loss: 0.0050\n","\n","Epoch 02422: val_loss improved from 0.00495 to 0.00495, saving model to model_checkpoint.h5\n","Epoch 2423/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0050\n","\n","Epoch 02423: val_loss improved from 0.00495 to 0.00495, saving model to model_checkpoint.h5\n","Epoch 2424/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0049\n","\n","Epoch 02424: val_loss improved from 0.00495 to 0.00495, saving model to model_checkpoint.h5\n","Epoch 2425/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 02425: val_loss improved from 0.00495 to 0.00495, saving model to model_checkpoint.h5\n","Epoch 2426/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n","\n","Epoch 02426: val_loss improved from 0.00495 to 0.00494, saving model to model_checkpoint.h5\n","Epoch 2427/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0044 - val_loss: 0.0049\n","\n","Epoch 02427: val_loss improved from 0.00494 to 0.00494, saving model to model_checkpoint.h5\n","Epoch 2428/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0049\n","\n","Epoch 02428: val_loss improved from 0.00494 to 0.00494, saving model to model_checkpoint.h5\n","Epoch 2429/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0049\n","\n","Epoch 02429: val_loss improved from 0.00494 to 0.00494, saving model to model_checkpoint.h5\n","Epoch 2430/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0049\n","\n","Epoch 02430: val_loss improved from 0.00494 to 0.00493, saving model to model_checkpoint.h5\n","Epoch 2431/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0042 - val_loss: 0.0049\n","\n","Epoch 02431: val_loss improved from 0.00493 to 0.00493, saving model to model_checkpoint.h5\n","Epoch 2432/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0049\n","\n","Epoch 02432: val_loss improved from 0.00493 to 0.00493, saving model to model_checkpoint.h5\n","Epoch 2433/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0049\n","\n","Epoch 02433: val_loss improved from 0.00493 to 0.00493, saving model to model_checkpoint.h5\n","Epoch 2434/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 02434: val_loss improved from 0.00493 to 0.00493, saving model to model_checkpoint.h5\n","Epoch 2435/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0045 - val_loss: 0.0049\n","\n","Epoch 02435: val_loss improved from 0.00493 to 0.00492, saving model to model_checkpoint.h5\n","Epoch 2436/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0049\n","\n","Epoch 02436: val_loss improved from 0.00492 to 0.00492, saving model to model_checkpoint.h5\n","Epoch 2437/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 02437: val_loss improved from 0.00492 to 0.00492, saving model to model_checkpoint.h5\n","Epoch 2438/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0049\n","\n","Epoch 02438: val_loss improved from 0.00492 to 0.00492, saving model to model_checkpoint.h5\n","Epoch 2439/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 02439: val_loss improved from 0.00492 to 0.00491, saving model to model_checkpoint.h5\n","Epoch 2440/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0049\n","\n","Epoch 02440: val_loss improved from 0.00491 to 0.00491, saving model to model_checkpoint.h5\n","Epoch 2441/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 02441: val_loss improved from 0.00491 to 0.00491, saving model to model_checkpoint.h5\n","Epoch 2442/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0049\n","\n","Epoch 02442: val_loss improved from 0.00491 to 0.00491, saving model to model_checkpoint.h5\n","Epoch 2443/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0049\n","\n","Epoch 02443: val_loss improved from 0.00491 to 0.00491, saving model to model_checkpoint.h5\n","Epoch 2444/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 02444: val_loss improved from 0.00491 to 0.00490, saving model to model_checkpoint.h5\n","Epoch 2445/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0049\n","\n","Epoch 02445: val_loss improved from 0.00490 to 0.00490, saving model to model_checkpoint.h5\n","Epoch 2446/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0049\n","\n","Epoch 02446: val_loss improved from 0.00490 to 0.00490, saving model to model_checkpoint.h5\n","Epoch 2447/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 02447: val_loss improved from 0.00490 to 0.00490, saving model to model_checkpoint.h5\n","Epoch 2448/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0049\n","\n","Epoch 02448: val_loss improved from 0.00490 to 0.00490, saving model to model_checkpoint.h5\n","Epoch 2449/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0049\n","\n","Epoch 02449: val_loss improved from 0.00490 to 0.00490, saving model to model_checkpoint.h5\n","Epoch 2450/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 02450: val_loss improved from 0.00490 to 0.00490, saving model to model_checkpoint.h5\n","Epoch 2451/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 02451: val_loss improved from 0.00490 to 0.00489, saving model to model_checkpoint.h5\n","Epoch 2452/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 02452: val_loss improved from 0.00489 to 0.00489, saving model to model_checkpoint.h5\n","Epoch 2453/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0049\n","\n","Epoch 02453: val_loss improved from 0.00489 to 0.00489, saving model to model_checkpoint.h5\n","Epoch 2454/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0049\n","\n","Epoch 02454: val_loss improved from 0.00489 to 0.00489, saving model to model_checkpoint.h5\n","Epoch 2455/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 02455: val_loss improved from 0.00489 to 0.00489, saving model to model_checkpoint.h5\n","Epoch 2456/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0049\n","\n","Epoch 02456: val_loss improved from 0.00489 to 0.00489, saving model to model_checkpoint.h5\n","Epoch 2457/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0042 - val_loss: 0.0049\n","\n","Epoch 02457: val_loss improved from 0.00489 to 0.00488, saving model to model_checkpoint.h5\n","Epoch 2458/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0040 - val_loss: 0.0049\n","\n","Epoch 02458: val_loss improved from 0.00488 to 0.00488, saving model to model_checkpoint.h5\n","Epoch 2459/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0049\n","\n","Epoch 02459: val_loss improved from 0.00488 to 0.00488, saving model to model_checkpoint.h5\n","Epoch 2460/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 02460: val_loss improved from 0.00488 to 0.00488, saving model to model_checkpoint.h5\n","Epoch 2461/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0049\n","\n","Epoch 02461: val_loss improved from 0.00488 to 0.00488, saving model to model_checkpoint.h5\n","Epoch 2462/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 02462: val_loss improved from 0.00488 to 0.00488, saving model to model_checkpoint.h5\n","Epoch 2463/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0049\n","\n","Epoch 02463: val_loss improved from 0.00488 to 0.00488, saving model to model_checkpoint.h5\n","Epoch 2464/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 02464: val_loss improved from 0.00488 to 0.00488, saving model to model_checkpoint.h5\n","Epoch 2465/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0045 - val_loss: 0.0049\n","\n","Epoch 02465: val_loss improved from 0.00488 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2466/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 02466: val_loss improved from 0.00487 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2467/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 02467: val_loss improved from 0.00487 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2468/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0049\n","\n","Epoch 02468: val_loss improved from 0.00487 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2469/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 02469: val_loss improved from 0.00487 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2470/50000\n","9/9 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 0.0049\n","\n","Epoch 02470: val_loss did not improve from 0.00487\n","Epoch 2471/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 02471: val_loss did not improve from 0.00487\n","Epoch 2472/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0049\n","\n","Epoch 02472: val_loss improved from 0.00487 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2473/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0049\n","\n","Epoch 02473: val_loss improved from 0.00487 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2474/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0049\n","\n","Epoch 02474: val_loss improved from 0.00487 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2475/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0049\n","\n","Epoch 02475: val_loss improved from 0.00487 to 0.00487, saving model to model_checkpoint.h5\n","Epoch 2476/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 02476: val_loss improved from 0.00487 to 0.00486, saving model to model_checkpoint.h5\n","Epoch 2477/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0049\n","\n","Epoch 02477: val_loss improved from 0.00486 to 0.00486, saving model to model_checkpoint.h5\n","Epoch 2478/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0049\n","\n","Epoch 02478: val_loss improved from 0.00486 to 0.00486, saving model to model_checkpoint.h5\n","Epoch 2479/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 02479: val_loss improved from 0.00486 to 0.00486, saving model to model_checkpoint.h5\n","Epoch 2480/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0037 - val_loss: 0.0049\n","\n","Epoch 02480: val_loss did not improve from 0.00486\n","Epoch 2481/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0049\n","\n","Epoch 02481: val_loss improved from 0.00486 to 0.00486, saving model to model_checkpoint.h5\n","Epoch 2482/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0049\n","\n","Epoch 02482: val_loss improved from 0.00486 to 0.00486, saving model to model_checkpoint.h5\n","Epoch 2483/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0049\n","\n","Epoch 02483: val_loss improved from 0.00486 to 0.00486, saving model to model_checkpoint.h5\n","Epoch 2484/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0049\n","\n","Epoch 02484: val_loss improved from 0.00486 to 0.00485, saving model to model_checkpoint.h5\n","Epoch 2485/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0049\n","\n","Epoch 02485: val_loss improved from 0.00485 to 0.00485, saving model to model_checkpoint.h5\n","Epoch 2486/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n","\n","Epoch 02486: val_loss improved from 0.00485 to 0.00485, saving model to model_checkpoint.h5\n","Epoch 2487/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0041 - val_loss: 0.0048\n","\n","Epoch 02487: val_loss improved from 0.00485 to 0.00485, saving model to model_checkpoint.h5\n","Epoch 2488/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0048\n","\n","Epoch 02488: val_loss improved from 0.00485 to 0.00485, saving model to model_checkpoint.h5\n","Epoch 2489/50000\n","9/9 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02489: val_loss improved from 0.00485 to 0.00485, saving model to model_checkpoint.h5\n","Epoch 2490/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0048\n","\n","Epoch 02490: val_loss improved from 0.00485 to 0.00485, saving model to model_checkpoint.h5\n","Epoch 2491/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0048\n","\n","Epoch 02491: val_loss improved from 0.00485 to 0.00485, saving model to model_checkpoint.h5\n","Epoch 2492/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02492: val_loss improved from 0.00485 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2493/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0048\n","\n","Epoch 02493: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2494/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n","\n","Epoch 02494: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2495/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0033 - val_loss: 0.0048\n","\n","Epoch 02495: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2496/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0048\n","\n","Epoch 02496: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2497/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0048\n","\n","Epoch 02497: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2498/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02498: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2499/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0048\n","\n","Epoch 02499: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2500/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0048\n","\n","Epoch 02500: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2501/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0048\n","\n","Epoch 02501: val_loss did not improve from 0.00484\n","Epoch 2502/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02502: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2503/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 02503: val_loss improved from 0.00484 to 0.00484, saving model to model_checkpoint.h5\n","Epoch 2504/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0048\n","\n","Epoch 02504: val_loss improved from 0.00484 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2505/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n","\n","Epoch 02505: val_loss improved from 0.00483 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2506/50000\n","9/9 [==============================] - 0s 10ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 02506: val_loss improved from 0.00483 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2507/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02507: val_loss did not improve from 0.00483\n","Epoch 2508/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0048\n","\n","Epoch 02508: val_loss improved from 0.00483 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2509/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0048\n","\n","Epoch 02509: val_loss improved from 0.00483 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2510/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0048\n","\n","Epoch 02510: val_loss improved from 0.00483 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2511/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 02511: val_loss did not improve from 0.00483\n","Epoch 2512/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0038 - val_loss: 0.0048\n","\n","Epoch 02512: val_loss improved from 0.00483 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2513/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n","\n","Epoch 02513: val_loss did not improve from 0.00483\n","Epoch 2514/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0034 - val_loss: 0.0048\n","\n","Epoch 02514: val_loss did not improve from 0.00483\n","Epoch 2515/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0044 - val_loss: 0.0048\n","\n","Epoch 02515: val_loss improved from 0.00483 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2516/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n","\n","Epoch 02516: val_loss improved from 0.00483 to 0.00483, saving model to model_checkpoint.h5\n","Epoch 2517/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0036 - val_loss: 0.0048\n","\n","Epoch 02517: val_loss did not improve from 0.00483\n","Epoch 2518/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0048\n","\n","Epoch 02518: val_loss did not improve from 0.00483\n","Epoch 2519/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02519: val_loss did not improve from 0.00483\n","Epoch 2520/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0041 - val_loss: 0.0048\n","\n","Epoch 02520: val_loss did not improve from 0.00483\n","Epoch 2521/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0048\n","\n","Epoch 02521: val_loss did not improve from 0.00483\n","Epoch 2522/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0048\n","\n","Epoch 02522: val_loss did not improve from 0.00483\n","Epoch 2523/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02523: val_loss did not improve from 0.00483\n","Epoch 2524/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 02524: val_loss did not improve from 0.00483\n","Epoch 2525/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n","\n","Epoch 02525: val_loss did not improve from 0.00483\n","Epoch 2526/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0036 - val_loss: 0.0048\n","\n","Epoch 02526: val_loss did not improve from 0.00483\n","Epoch 2527/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02527: val_loss did not improve from 0.00483\n","Epoch 2528/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 02528: val_loss did not improve from 0.00483\n","Epoch 2529/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02529: val_loss did not improve from 0.00483\n","Epoch 2530/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0048\n","\n","Epoch 02530: val_loss did not improve from 0.00483\n","Epoch 2531/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0048\n","\n","Epoch 02531: val_loss did not improve from 0.00483\n","Epoch 2532/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0033 - val_loss: 0.0048\n","\n","Epoch 02532: val_loss did not improve from 0.00483\n","Epoch 2533/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0048\n","\n","Epoch 02533: val_loss did not improve from 0.00483\n","Epoch 2534/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0039 - val_loss: 0.0048\n","\n","Epoch 02534: val_loss did not improve from 0.00483\n","Epoch 2535/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0048\n","\n","Epoch 02535: val_loss did not improve from 0.00483\n","Epoch 2536/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 02536: val_loss did not improve from 0.00483\n","Epoch 2537/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0048\n","\n","Epoch 02537: val_loss did not improve from 0.00483\n","Epoch 2538/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0040 - val_loss: 0.0048\n","\n","Epoch 02538: val_loss did not improve from 0.00483\n","Epoch 2539/50000\n","9/9 [==============================] - 0s 8ms/step - loss: 0.0037 - val_loss: 0.0048\n","\n","Epoch 02539: val_loss did not improve from 0.00483\n","Epoch 2540/50000\n","9/9 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.0048\n","\n","Epoch 02540: val_loss did not improve from 0.00483\n","Epoch 2541/50000\n","9/9 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0048\n","\n","Epoch 02541: val_loss did not improve from 0.00483\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"oIn263BQsmfI"},"source":["## Evaluate the model"]},{"cell_type":"code","metadata":{"id":"T5VPp01HHhPn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622388739807,"user_tz":-120,"elapsed":374,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"e6c02508-3b1b-48e5-8540-57e620e11d61"},"source":["# Evaluating the model\n","from numpy import concatenate\n","from math import sqrt\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","\n","# make a prediction\n","yhat = model.predict(x_test)\n","x_test = x_test.reshape((x_test.shape[0], x_test.shape[2]))\n","#print(\"x_test\")\n","#print(x_test)\n","# invert scaling for forecast\n","inv_yhat = concatenate((yhat, x_test[:, 0:]), axis=1)\n","print(inv_yhat)\n","inv_yhat = scaler.inverse_transform(inv_yhat)\n","inv_yhat = inv_yhat[:,0]\n","\n","# invert scaling for actual\n","y_test = y_test.reshape((len(y_test), 1))\n","inv_y = concatenate((y_test, x_test[:, 0:]), axis=1)\n","inv_y = scaler.inverse_transform(inv_y)\n","inv_y = inv_y[:,0]\n","\n","#print(inv_yhat)\n","#print(inv_yhat.shape)\n","#print(inv_y)\n","#print(inv_y.shape)\n","# https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error\n","# Calculate RMSE\n","rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n","print('Test RMSE: %.3f' % rmse)\n","# Calculate MAE\n","mae = mean_absolute_error(inv_y, inv_yhat)\n","print('Test MAE: %.3f' % mae)\n","# r2\n","from sklearn.metrics import r2_score\n","test_r2 = r2_score(inv_y, inv_yhat)\n","print('Test r2: %.3f' % test_r2)\n","\n","y_pred_array=[]\n","y_orig_array=[]\n","y_pred_array.append(inv_yhat) \n","y_orig_array.append(inv_y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["x_test\n","[[0.78261572 0.78228922 0.78364885 ... 0.93854997 0.         0.30666667]\n"," [0.82971653 0.82946078 0.83052582 ... 0.93854997 0.         0.46666667]\n"," [0.85130976 0.85108644 0.85201642 ... 0.91961979 0.         0.42666667]\n"," ...\n"," [0.75859877 0.7582362  0.75974604 ... 0.7279214  0.         0.65333333]\n"," [0.75859877 0.7582362  0.75974604 ... 0.71327777 0.         0.66666667]\n"," [0.75859877 0.7582362  0.75974604 ... 0.71563409 0.         0.6       ]]\n","[[0.95628911 0.78261572 0.78228922 ... 0.93854997 0.         0.30666667]\n"," [0.96578062 0.82971653 0.82946078 ... 0.93854997 0.         0.46666667]\n"," [0.81479669 0.85130976 0.85108644 ... 0.91961979 0.         0.42666667]\n"," ...\n"," [0.78502041 0.75859877 0.7582362  ... 0.7279214  0.         0.65333333]\n"," [0.78837925 0.75859877 0.7582362  ... 0.71327777 0.         0.66666667]\n"," [0.7661671  0.75859877 0.7582362  ... 0.71563409 0.         0.6       ]]\n","Test RMSE: 53.641\n","Test MAE: 43.836\n","Test r2: 0.666\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xV_qfeNPwsBH"},"source":["Checking variables"]},{"cell_type":"code","metadata":{"id":"8Y0Dwp9oUVBa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622388739809,"user_tz":-120,"elapsed":14,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"9ad14c19-049d-4d27-9c64-2cbd867c6ade"},"source":["sz = scaled_data.shape[0]\n","sz"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["357"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"LFhHryuwVFX9"},"source":["sz_train = round(0.75*sz)\n","sz_test = round(0.25*sz)\n","time = time_vector[0:sz_train]\n","y_original = df_ann.iloc[:,-1]\n","y_original = y_original[0:sz_train]\n","# It is the same as y_stocke\n","# y_stocke = df_stocke[\"Close\"]\n","# y_stocke = y_original[0:sz_train]\n","\n","y_orig_test = df_ann.iloc[:,-1]\n","y_orig_test = y_orig_test[sz_train:(sz_train+sz_test)]\n","time_test = time_vector[sz_train:(sz_train+sz_test)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IeDMdXzVwv38"},"source":["## Prediction at the final time"]},{"cell_type":"code","metadata":{"id":"d97uIs-jUDYf","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1622388740097,"user_tz":-120,"elapsed":294,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"9d869f17-2311-44ba-e7f3-83dc9eb28a1a"},"source":["fig = plt.figure()\n","plt.plot(time,y_original,color='green')\n","plt.plot(time_test,y_orig_test,color='red')\n","plt.plot(time_test[-1],inv_yhat[-1],'mo')\n","\n","plt.title(\"Stock Forecasting\")\n","plt.ylabel(\"Stock price\")\n","plt.xlabel(\"Time horizon (days)\")\n","plt.legend([\"Training\",\"Test\",\"Prediction\"], loc =\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"DBFCuRwYw1q3"},"source":["Checking variables"]},{"cell_type":"code","metadata":{"id":"iyE9tgp9Ttb7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622388740097,"user_tz":-120,"elapsed":14,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"cd1ca789-0aac-452a-bf57-8c921738996b"},"source":["inv_y[-1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["677.0860728397089"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ult8tUp5FgrN","executionInfo":{"status":"ok","timestamp":1622388740098,"user_tz":-120,"elapsed":10,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"f0b1cf0d-28bf-4e5c-9c6a-cf9078437f64"},"source":["len(time_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["89"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"o8PcRKbETw_q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622388740099,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"4e635385-08fc-4f73-ae15-12934d391d27"},"source":["inv_yhat[-1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["710.9692591186422"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"Q8jzPbnkw5rb"},"source":["## Plot\n","Real data is in green, the * are compared with the blue o. They are the real data and the predictions for that time of the testing set."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"KQvm0KuPEOH0","executionInfo":{"status":"ok","timestamp":1622388740715,"user_tz":-120,"elapsed":623,"user":{"displayName":"Ivan Jesus Torres Rodriguez","photoUrl":"","userId":"12648103983068035098"}},"outputId":"4289c5fb-0928-4274-d114-8b8c7187d3e4"},"source":["#Image_FORECASTING_LSTM_0_0\n","plt.figure(figsize=(10,8))\n","plt.plot(time,y_original,color='green')\n","plt.plot(time_test,y_orig_test,'g*')\n","plt.plot(time_test,inv_yhat[1:],'c.')\n","plt.plot(time_test[-1],inv_yhat[-1],'mo')\n","\n","plt.title(\"Stock Forecasting\")\n","plt.ylabel(\"Stock price\")\n","plt.xlabel(\"Time horizon (days)\")\n","plt.legend([\"Training\",\"Test\",\"Prediction\"], loc =\"lower right\")\n","plt.xlim([240,360])\n","plt.ylim([500,900])\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}